2021-10-10 19:37:42 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:13163
2021-10-10 19:37:42 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:13163
2021-10-10 19:37:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2021-10-10 19:37:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2021-10-10 19:37:42 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for 2 nodes.
2021-10-10 19:37:42 | INFO | fairseq.distributed.utils | initialized host ironman as rank 0
2021-10-10 19:37:42 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for 2 nodes.
2021-10-10 19:37:42 | INFO | fairseq.distributed.utils | initialized host ironman as rank 1
2021-10-10 19:37:45 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.25, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13163', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 32, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 32, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 500000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints/pretrain/', 'restore_file': 'checkpoints/pretrain/checkpoint_best.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='xdep', activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9,0.98)', adam_eps=1e-06, adaptive_input=False, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='xdep', attention_dropout=0.1, azureml_logging=False, batch_size=32, batch_size_valid='32', best_checkpoint_metric='loss', beta_shift=0.1, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, byte_combine='cnn', checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, code_value_loss_alpha=100.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='xdep', curriculum=0, data='data-bin/pretrain', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_bytes_rate=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=8, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eos=2, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.25, fp16_scale_window=None, fp32_reduce_scatter=False, freq_weighted_replacement=False, fuse_dropout=0.1, fuse_layer=1, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, input_combine='fuse', keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=True, leave_unmasked_prob=0.1, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='json', log_interval=10, lr=[0.0005], lr_scheduler='polynomial_decay', mask_multiple_length=1, mask_prob=0.2, mask_rate_scheduler='epoch', mask_stdev=0.0, max_epoch=0, max_source_positions=512, max_tokens=None, max_tokens_valid=None, max_update=500000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, random_token_prob=0.5, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoints/pretrain/checkpoint_best.pt', sample_break_mode='eos', save_dir='checkpoints/pretrain/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, shorten_data_split_list='', shorten_method='none', simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='xdep', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, total_num_update='500000', tpu=False, train_subset='train', unk=3, untie_weights_xdep=False, update_freq=[16], use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=10000, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'xdep', 'data': 'data-bin/pretrain', 'sample_break_mode': 'eos', 'tokens_per_sample': 512, 'mask_prob': 0.2, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.5, 'freq_weighted_replacement': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 1, 'mask_rate_scheduler': 'epoch', 'code_value_loss_alpha': 100.0, 'drop_bytes_rate': 0.0}, 'criterion': {'_name': 'xdep', 'tpu': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 10000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 500000.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
19 19
2021-10-10 19:37:45 | INFO | fairseq.tasks.xdep | static dictionary: 320 types
2021-10-10 19:37:45 | INFO | fairseq.tasks.xdep | op_pos_emb dictionary: 16 types
2021-10-10 19:37:45 | INFO | fairseq.tasks.xdep | mem_mask dictionary: 8 types
2021-10-10 19:37:45 | INFO | fairseq.tasks.xdep | byte1 dictionary: 264 types
2021-10-10 19:37:45 | INFO | fairseq.tasks.xdep | byte2 dictionary: 264 types
2021-10-10 19:37:45 | INFO | fairseq.tasks.xdep | byte3 dictionary: 264 types
2021-10-10 19:37:45 | INFO | fairseq.tasks.xdep | byte4 dictionary: 264 types
2021-10-10 19:37:45 | INFO | fairseq.tasks.xdep | byte5 dictionary: 264 types
2021-10-10 19:37:45 | INFO | fairseq.tasks.xdep | byte6 dictionary: 264 types
2021-10-10 19:37:45 | INFO | fairseq.tasks.xdep | byte7 dictionary: 264 types
2021-10-10 19:37:45 | INFO | fairseq.tasks.xdep | byte8 dictionary: 264 types
2021-10-10 19:37:45 | INFO | fairseq.tasks.xdep | mem1 dictionary: 264 types
2021-10-10 19:37:45 | INFO | fairseq.tasks.xdep | mem2 dictionary: 264 types
2021-10-10 19:37:45 | INFO | fairseq.tasks.xdep | mem3 dictionary: 264 types
2021-10-10 19:37:45 | INFO | fairseq.tasks.xdep | mem4 dictionary: 264 types
2021-10-10 19:37:45 | INFO | fairseq.tasks.xdep | mem5 dictionary: 264 types
2021-10-10 19:37:45 | INFO | fairseq.tasks.xdep | mem6 dictionary: 264 types
2021-10-10 19:37:45 | INFO | fairseq.tasks.xdep | mem7 dictionary: 264 types
2021-10-10 19:37:45 | INFO | fairseq.tasks.xdep | mem8 dictionary: 264 types
2021-10-10 19:37:46 | INFO | fairseq_cli.train | XdepModel(
  (encoder): Encoder(
    (sentence_encoder): XdepTransformerEncoder(
      (dropout_module): FairseqDropout()
      (embed_tokens): ModuleDict(
        (static): Embedding(321, 768, padding_idx=1)
        (op_pos_emb): Embedding(16, 768, padding_idx=1)
        (mem_mask): Embedding(8, 768, padding_idx=1)
      )
      (byte_combine): ByteCombineCNN(
        (convolutions): ModuleList(
          (0): Conv1d(1, 4, kernel_size=(1,), stride=(1,))
          (1): Conv1d(1, 8, kernel_size=(2,), stride=(1,))
          (2): Conv1d(1, 12, kernel_size=(3,), stride=(1,))
          (3): Conv1d(1, 16, kernel_size=(4,), stride=(1,))
          (4): Conv1d(1, 20, kernel_size=(5,), stride=(1,))
          (5): Conv1d(1, 24, kernel_size=(6,), stride=(1,))
          (6): Conv1d(1, 28, kernel_size=(7,), stride=(1,))
        )
        (highway): Highway(
          (layers): ModuleList(
            (0): Linear(in_features=112, out_features=224, bias=True)
            (1): Linear(in_features=112, out_features=224, bias=True)
          )
          (activation): ReLU()
        )
        (projection): Linear(in_features=112, out_features=768, bias=True)
      )
      (linear_gate_byte): Linear(in_features=1536, out_features=768, bias=True)
      (linear_gate_mem): Linear(in_features=1536, out_features=768, bias=True)
      (linear_byte): Linear(in_features=768, out_features=768, bias=True)
      (linear_mem): Linear(in_features=768, out_features=768, bias=True)
      (fuse_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      (dropout_fuse): FairseqDropout()
      (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        )
        (6): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        )
        (7): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (lm_head_code): XdepLMHeadClassification(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    )
    (lm_head_value): XdepLMHeadRegression(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    )
  )
  (classification_heads): ModuleDict()
)
2021-10-10 19:37:46 | INFO | fairseq_cli.train | task: XdepTask
2021-10-10 19:37:46 | INFO | fairseq_cli.train | model: XdepModel
2021-10-10 19:37:46 | INFO | fairseq_cli.train | criterion: XdepLoss
2021-10-10 19:37:46 | INFO | fairseq_cli.train | num. shared model params: 61,841,833 (num. trained: 61,841,833)
2021-10-10 19:37:46 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2021-10-10 19:37:46 | INFO | fairseq.data.data_utils | loaded 1,000,000 examples from: data-bin/pretrain/static/valid
2021-10-10 19:37:46 | INFO | fairseq.tasks.xdep | loaded 1000000 blocks from: data-bin/pretrain/static/valid
2021-10-10 19:37:47 | INFO | fairseq.data.data_utils | loaded 1,000,000 examples from: data-bin/pretrain/op_pos_emb/valid
2021-10-10 19:37:47 | INFO | fairseq.tasks.xdep | loaded 1000000 blocks from: data-bin/pretrain/op_pos_emb/valid
2021-10-10 19:37:47 | INFO | fairseq.data.data_utils | loaded 1,000,000 examples from: data-bin/pretrain/mem_mask/valid
2021-10-10 19:37:47 | INFO | fairseq.tasks.xdep | loaded 1000000 blocks from: data-bin/pretrain/mem_mask/valid
2021-10-10 19:37:47 | INFO | fairseq.data.data_utils | loaded 1,000,000 examples from: data-bin/pretrain/byte1/valid
2021-10-10 19:37:47 | INFO | fairseq.tasks.xdep | loaded 1000000 blocks from: data-bin/pretrain/byte1/valid
2021-10-10 19:37:47 | INFO | fairseq.data.data_utils | loaded 1,000,000 examples from: data-bin/pretrain/byte2/valid
2021-10-10 19:37:47 | INFO | fairseq.tasks.xdep | loaded 1000000 blocks from: data-bin/pretrain/byte2/valid
2021-10-10 19:37:48 | INFO | fairseq.data.data_utils | loaded 1,000,000 examples from: data-bin/pretrain/byte3/valid
2021-10-10 19:37:48 | INFO | fairseq.tasks.xdep | loaded 1000000 blocks from: data-bin/pretrain/byte3/valid
2021-10-10 19:37:48 | INFO | fairseq.data.data_utils | loaded 1,000,000 examples from: data-bin/pretrain/byte4/valid
2021-10-10 19:37:48 | INFO | fairseq.tasks.xdep | loaded 1000000 blocks from: data-bin/pretrain/byte4/valid
2021-10-10 19:37:48 | INFO | fairseq.data.data_utils | loaded 1,000,000 examples from: data-bin/pretrain/byte5/valid
2021-10-10 19:37:48 | INFO | fairseq.tasks.xdep | loaded 1000000 blocks from: data-bin/pretrain/byte5/valid
2021-10-10 19:37:48 | INFO | fairseq.data.data_utils | loaded 1,000,000 examples from: data-bin/pretrain/byte6/valid
2021-10-10 19:37:48 | INFO | fairseq.tasks.xdep | loaded 1000000 blocks from: data-bin/pretrain/byte6/valid
2021-10-10 19:37:49 | INFO | fairseq.data.data_utils | loaded 1,000,000 examples from: data-bin/pretrain/byte7/valid
2021-10-10 19:37:49 | INFO | fairseq.tasks.xdep | loaded 1000000 blocks from: data-bin/pretrain/byte7/valid
2021-10-10 19:37:49 | INFO | fairseq.data.data_utils | loaded 1,000,000 examples from: data-bin/pretrain/byte8/valid
2021-10-10 19:37:49 | INFO | fairseq.tasks.xdep | loaded 1000000 blocks from: data-bin/pretrain/byte8/valid
2021-10-10 19:37:49 | INFO | fairseq.data.data_utils | loaded 1,000,000 examples from: data-bin/pretrain/mem1/valid
2021-10-10 19:37:49 | INFO | fairseq.tasks.xdep | loaded 1000000 blocks from: data-bin/pretrain/mem1/valid
2021-10-10 19:37:49 | INFO | fairseq.data.data_utils | loaded 1,000,000 examples from: data-bin/pretrain/mem2/valid
2021-10-10 19:37:49 | INFO | fairseq.tasks.xdep | loaded 1000000 blocks from: data-bin/pretrain/mem2/valid
2021-10-10 19:37:49 | INFO | fairseq.data.data_utils | loaded 1,000,000 examples from: data-bin/pretrain/mem3/valid
2021-10-10 19:37:49 | INFO | fairseq.tasks.xdep | loaded 1000000 blocks from: data-bin/pretrain/mem3/valid
2021-10-10 19:37:50 | INFO | fairseq.data.data_utils | loaded 1,000,000 examples from: data-bin/pretrain/mem4/valid
2021-10-10 19:37:50 | INFO | fairseq.tasks.xdep | loaded 1000000 blocks from: data-bin/pretrain/mem4/valid
2021-10-10 19:37:50 | INFO | fairseq.data.data_utils | loaded 1,000,000 examples from: data-bin/pretrain/mem5/valid
2021-10-10 19:37:50 | INFO | fairseq.tasks.xdep | loaded 1000000 blocks from: data-bin/pretrain/mem5/valid
2021-10-10 19:37:50 | INFO | fairseq.data.data_utils | loaded 1,000,000 examples from: data-bin/pretrain/mem6/valid
2021-10-10 19:37:50 | INFO | fairseq.tasks.xdep | loaded 1000000 blocks from: data-bin/pretrain/mem6/valid
2021-10-10 19:37:50 | INFO | fairseq.data.data_utils | loaded 1,000,000 examples from: data-bin/pretrain/mem7/valid
2021-10-10 19:37:50 | INFO | fairseq.tasks.xdep | loaded 1000000 blocks from: data-bin/pretrain/mem7/valid
2021-10-10 19:37:51 | INFO | fairseq.data.data_utils | loaded 1,000,000 examples from: data-bin/pretrain/mem8/valid
2021-10-10 19:37:51 | INFO | fairseq.tasks.xdep | loaded 1000000 blocks from: data-bin/pretrain/mem8/valid
2021-10-10 19:37:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2021-10-10 19:37:51 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for 2 nodes.
2021-10-10 19:37:51 | INFO | fairseq.trainer | detected shared parameter: encoder.sentence_encoder.embed_tokens.static.weight <- encoder.lm_head_code.weight
2021-10-10 19:37:51 | INFO | fairseq.utils | ***********************CUDA enviroments for all 2 workers***********************
2021-10-10 19:37:51 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2021-10-10 19:37:51 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2021-10-10 19:37:51 | INFO | fairseq.utils | ***********************CUDA enviroments for all 2 workers***********************
2021-10-10 19:37:51 | INFO | fairseq_cli.train | training on 2 devices (GPUs/TPUs)
2021-10-10 19:37:51 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 32
2021-10-10 19:37:51 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/pretrain/checkpoint_best.pt
2021-10-10 19:37:51 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/pretrain/checkpoint_best.pt
2021-10-10 19:37:51 | INFO | fairseq.trainer | loading train data for epoch 1
2021-10-10 19:37:54 | INFO | fairseq.data.data_utils | loaded 12,731,139 examples from: data-bin/pretrain/static/train
2021-10-10 19:37:55 | INFO | fairseq.tasks.xdep | loaded 12731139 blocks from: data-bin/pretrain/static/train
2021-10-10 19:37:57 | INFO | fairseq.data.data_utils | loaded 12,731,139 examples from: data-bin/pretrain/op_pos_emb/train
2021-10-10 19:37:58 | INFO | fairseq.tasks.xdep | loaded 12731139 blocks from: data-bin/pretrain/op_pos_emb/train
2021-10-10 19:38:01 | INFO | fairseq.data.data_utils | loaded 12,731,139 examples from: data-bin/pretrain/mem_mask/train
2021-10-10 19:38:01 | INFO | fairseq.tasks.xdep | loaded 12731139 blocks from: data-bin/pretrain/mem_mask/train
2021-10-10 19:38:04 | INFO | fairseq.data.data_utils | loaded 12,731,139 examples from: data-bin/pretrain/byte1/train
2021-10-10 19:38:04 | INFO | fairseq.tasks.xdep | loaded 12731139 blocks from: data-bin/pretrain/byte1/train
2021-10-10 19:38:08 | INFO | fairseq.data.data_utils | loaded 12,731,139 examples from: data-bin/pretrain/byte2/train
2021-10-10 19:38:08 | INFO | fairseq.tasks.xdep | loaded 12731139 blocks from: data-bin/pretrain/byte2/train
2021-10-10 19:38:11 | INFO | fairseq.data.data_utils | loaded 12,731,139 examples from: data-bin/pretrain/byte3/train
2021-10-10 19:38:11 | INFO | fairseq.tasks.xdep | loaded 12731139 blocks from: data-bin/pretrain/byte3/train
2021-10-10 19:38:15 | INFO | fairseq.data.data_utils | loaded 12,731,139 examples from: data-bin/pretrain/byte4/train
2021-10-10 19:38:15 | INFO | fairseq.tasks.xdep | loaded 12731139 blocks from: data-bin/pretrain/byte4/train
2021-10-10 19:38:18 | INFO | fairseq.data.data_utils | loaded 12,731,139 examples from: data-bin/pretrain/byte5/train
2021-10-10 19:38:20 | INFO | fairseq.tasks.xdep | loaded 12731139 blocks from: data-bin/pretrain/byte5/train
2021-10-10 19:38:23 | INFO | fairseq.data.data_utils | loaded 12,731,139 examples from: data-bin/pretrain/byte6/train
2021-10-10 19:38:24 | INFO | fairseq.tasks.xdep | loaded 12731139 blocks from: data-bin/pretrain/byte6/train
2021-10-10 19:38:27 | INFO | fairseq.data.data_utils | loaded 12,731,139 examples from: data-bin/pretrain/byte7/train
2021-10-10 19:38:29 | INFO | fairseq.tasks.xdep | loaded 12731139 blocks from: data-bin/pretrain/byte7/train
2021-10-10 19:38:32 | INFO | fairseq.data.data_utils | loaded 12,731,139 examples from: data-bin/pretrain/byte8/train
2021-10-10 19:38:33 | INFO | fairseq.tasks.xdep | loaded 12731139 blocks from: data-bin/pretrain/byte8/train
2021-10-10 19:38:36 | INFO | fairseq.data.data_utils | loaded 12,731,139 examples from: data-bin/pretrain/mem1/train
2021-10-10 19:38:38 | INFO | fairseq.tasks.xdep | loaded 12731139 blocks from: data-bin/pretrain/mem1/train
2021-10-10 19:38:41 | INFO | fairseq.data.data_utils | loaded 12,731,139 examples from: data-bin/pretrain/mem2/train
2021-10-10 19:38:42 | INFO | fairseq.tasks.xdep | loaded 12731139 blocks from: data-bin/pretrain/mem2/train
2021-10-10 19:38:45 | INFO | fairseq.data.data_utils | loaded 12,731,139 examples from: data-bin/pretrain/mem3/train
2021-10-10 19:38:46 | INFO | fairseq.tasks.xdep | loaded 12731139 blocks from: data-bin/pretrain/mem3/train
2021-10-10 19:38:50 | INFO | fairseq.data.data_utils | loaded 12,731,139 examples from: data-bin/pretrain/mem4/train
2021-10-10 19:38:51 | INFO | fairseq.tasks.xdep | loaded 12731139 blocks from: data-bin/pretrain/mem4/train
2021-10-10 19:38:54 | INFO | fairseq.data.data_utils | loaded 12,731,139 examples from: data-bin/pretrain/mem5/train
2021-10-10 19:38:55 | INFO | fairseq.tasks.xdep | loaded 12731139 blocks from: data-bin/pretrain/mem5/train
2021-10-10 19:38:58 | INFO | fairseq.data.data_utils | loaded 12,731,139 examples from: data-bin/pretrain/mem6/train
2021-10-10 19:39:00 | INFO | fairseq.tasks.xdep | loaded 12731139 blocks from: data-bin/pretrain/mem6/train
2021-10-10 19:39:03 | INFO | fairseq.data.data_utils | loaded 12,731,139 examples from: data-bin/pretrain/mem7/train
2021-10-10 19:39:05 | INFO | fairseq.tasks.xdep | loaded 12731139 blocks from: data-bin/pretrain/mem7/train
2021-10-10 19:39:08 | INFO | fairseq.data.data_utils | loaded 12,731,139 examples from: data-bin/pretrain/mem8/train
2021-10-10 19:39:09 | INFO | fairseq.tasks.xdep | loaded 12731139 blocks from: data-bin/pretrain/mem8/train
2021-10-10 19:39:22 | INFO | fairseq.optim.adam | using FusedAdam
2021-10-10 19:39:22 | INFO | fairseq.trainer | begin training epoch 1
2021-10-10 19:39:22 | INFO | fairseq_cli.train | Start iterating over samples
19 19
2021-10-10 19:40:48 | INFO | fairseq.modules.cross_entropy | using fused cross entropy
2021-10-10 19:40:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2021-10-10 19:41:00 | INFO | root | Reducer buckets have been rebuilt in this iteration.
2021-10-10 19:41:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2021-10-10 19:41:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2021-10-10 19:41:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2021-10-10 19:41:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-10-10 19:41:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-10-10 19:42:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-10 19:42:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2021-10-10 19:42:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-10 19:42:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
2021-10-10 19:42:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
2021-10-10 19:43:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
2021-10-10 19:43:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.015625
2021-10-10 19:43:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0078125
2021-10-10 19:45:45 | INFO | train_inner | {"epoch": 1, "update": 0.002, "loss": "17.591", "code_loss": "8.911", "value_loss_mse": "0.227", "code_ppl": "481.51", "wps": "18602.2", "ups": "0.08", "wpb": "239552", "bsz": "1024", "num_updates": "10", "lr": "5e-07", "gnorm": "447.321", "loss_scale": "0.0078", "train_wall": "95", "gb_free": "12.9", "wall": "474"}
2021-10-10 19:48:00 | INFO | train_inner | {"epoch": 1, "update": 0.003, "loss": "17.259", "code_loss": "8.905", "value_loss_mse": "0.222", "code_ppl": "479.46", "wps": "17253.9", "ups": "0.07", "wpb": "232288", "bsz": "1024", "num_updates": "20", "lr": "1e-06", "gnorm": "444.151", "loss_scale": "0.0078", "train_wall": "28", "gb_free": "12.9", "wall": "608"}
2021-10-10 19:50:02 | INFO | train_inner | {"epoch": 1, "update": 0.004, "loss": "16.095", "code_loss": "8.913", "value_loss_mse": "0.205", "code_ppl": "481.88", "wps": "18214.1", "ups": "0.08", "wpb": "222515", "bsz": "1024", "num_updates": "30", "lr": "1.5e-06", "gnorm": "423.478", "loss_scale": "0.0078", "train_wall": "22", "gb_free": "12.9", "wall": "730"}
2021-10-10 19:52:15 | INFO | train_inner | {"epoch": 1, "update": 0.004, "loss": "14.038", "code_loss": "8.914", "value_loss_mse": "0.175", "code_ppl": "482.45", "wps": "18945.6", "ups": "0.08", "wpb": "251683", "bsz": "1024", "num_updates": "40", "lr": "2e-06", "gnorm": "374.742", "loss_scale": "0.0078", "train_wall": "23", "gb_free": "12.9", "wall": "863"}
2021-10-10 19:54:20 | INFO | train_inner | {"epoch": 1, "update": 0.005, "loss": "10.936", "code_loss": "8.891", "value_loss_mse": "0.131", "code_ppl": "474.8", "wps": "18703.7", "ups": "0.08", "wpb": "233923", "bsz": "1024", "num_updates": "50", "lr": "2.5e-06", "gnorm": "285.31", "loss_scale": "0.0078", "train_wall": "23", "gb_free": "12.9", "wall": "988"}
2021-10-10 19:56:23 | INFO | train_inner | {"epoch": 1, "update": 0.006, "loss": "7.907", "code_loss": "8.842", "value_loss_mse": "0.087", "code_ppl": "458.92", "wps": "18690.1", "ups": "0.08", "wpb": "231366", "bsz": "1024", "num_updates": "60", "lr": "3e-06", "gnorm": "145.218", "loss_scale": "0.0078", "train_wall": "61", "gb_free": "12.9", "wall": "1112"}
2021-10-10 19:58:31 | INFO | train_inner | {"epoch": 1, "update": 0.007, "loss": "6.744", "code_loss": "8.762", "value_loss_mse": "0.07", "code_ppl": "434.25", "wps": "19039.3", "ups": "0.08", "wpb": "242063", "bsz": "1024", "num_updates": "70", "lr": "3.5e-06", "gnorm": "77.032", "loss_scale": "0.0078", "train_wall": "28", "gb_free": "12.9", "wall": "1239"}
2021-10-10 20:00:39 | INFO | train_inner | {"epoch": 1, "update": 0.008, "loss": "6.209", "code_loss": "8.634", "value_loss_mse": "0.063", "code_ppl": "397.37", "wps": "19472.5", "ups": "0.08", "wpb": "250419", "bsz": "1024", "num_updates": "80", "lr": "4e-06", "gnorm": "47.756", "loss_scale": "0.0078", "train_wall": "62", "gb_free": "12.9", "wall": "1368"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.10968017578125, 0.1275634765625, 0.10015869140625, 0.09930419921875, 0.11279296875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.1505126953125, 0.090576171875, 0.12200927734375, 0.06463623046875, 0.1363525390625]
byte3 tgt value: [0.2421875, 0.0, 0.0, 0.2421875, 0.49609375]
byte3 pred value: [0.140869140625, 0.146728515625, 0.0638427734375, 0.08929443359375, 0.168212890625]
byte4 tgt value: [0.18359375, 0.0, 0.0, 0.18359375, 0.99609375]
byte4 pred value: [0.09600830078125, 0.09332275390625, 0.1165771484375, 0.11737060546875, 0.10797119140625]
byte5 tgt value: [0.8671875, 0.0, 0.0, 0.8671875, 0.74609375]
byte5 pred value: [0.1680908203125, 0.15380859375, 0.2147216796875, 0.185546875, 0.23876953125]
byte6 tgt value: [0.57421875, 0.0, 0.0, 0.57421875, 0.31640625]
byte6 pred value: [0.075439453125, 0.0823974609375, 0.07763671875, 0.11981201171875, 0.0567626953125]
byte7 tgt value: [0.078125, 0.0, 0.234375, 0.3125, 0.17578125]
byte7 pred value: [0.2474365234375, 0.301025390625, 0.26806640625, 0.203369140625, 0.2349853515625]
byte8 tgt value: [0.13671875, 0.4375, 0.06640625, 0.359375, 0.0625]
byte8 pred value: [0.339111328125, 0.28857421875, 0.3271484375, 0.41552734375, 0.346923828125]
tgt code: hexvar eax rax + rax
pred code: rdx btc btc jmp btc
2021-10-10 20:02:58 | INFO | train_inner | {"epoch": 1, "update": 0.008, "loss": "5.984", "code_loss": "8.454", "value_loss_mse": "0.06", "code_ppl": "350.67", "wps": "17992.1", "ups": "0.07", "wpb": "249562", "bsz": "1024", "num_updates": "90", "lr": "4.5e-06", "gnorm": "30.525", "loss_scale": "0.0078", "train_wall": "20", "gb_free": "12.9", "wall": "1507"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.095703125, 0.0823974609375, 0.06903076171875, 0.0792236328125, 0.052825927734375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.09857177734375, 0.079345703125, 0.05865478515625, 0.06781005859375, 0.07720947265625]
byte3 tgt value: [0.41796875, 0.0, 0.41796875, 0.0, 0.41796875]
byte3 pred value: [0.1473388671875, 0.163330078125, 0.1121826171875, 0.119384765625, 0.1319580078125]
byte4 tgt value: [0.984375, 0.0, 0.984375, 0.0, 0.984375]
byte4 pred value: [0.08709716796875, 0.10687255859375, 0.10650634765625, 0.10858154296875, 0.09979248046875]
byte5 tgt value: [0.94921875, 0.0, 0.94921875, 0.0, 0.94921875]
byte5 pred value: [0.132568359375, 0.1533203125, 0.0948486328125, 0.12286376953125, 0.1171875]
byte6 tgt value: [0.515625, 0.0, 0.515625, 0.0, 0.5703125]
byte6 pred value: [0.1259765625, 0.1402587890625, 0.1416015625, 0.1083984375, 0.09857177734375]
byte7 tgt value: [0.21875, 0.0, 0.16015625, 0.0, 0.13671875]
byte7 pred value: [0.2398681640625, 0.22119140625, 0.279052734375, 0.2276611328125, 0.224365234375]
byte8 tgt value: [0.0625, 0.16015625, 0.3125, 0.1640625, 0.8125]
byte8 pred value: [0.2183837890625, 0.263671875, 0.31005859375, 0.405517578125, 0.1807861328125]
tgt code: xor hexvar ret rip
pred code: xorpd sil maxss fxch
2021-10-10 20:05:03 | INFO | train_inner | {"epoch": 1, "update": 0.009, "loss": "5.889", "code_loss": "8.238", "value_loss_mse": "0.06", "code_ppl": "301.86", "wps": "19437.1", "ups": "0.08", "wpb": "243190", "bsz": "1024", "num_updates": "100", "lr": "5e-06", "gnorm": "21.805", "loss_scale": "0.0078", "train_wall": "33", "gb_free": "12.9", "wall": "1632"}
2021-10-10 20:07:05 | INFO | train_inner | {"epoch": 1, "update": 0.01, "loss": "5.764", "code_loss": "7.999", "value_loss_mse": "0.059", "code_ppl": "255.85", "wps": "18650.3", "ups": "0.08", "wpb": "226851", "bsz": "1024", "num_updates": "110", "lr": "5.5e-06", "gnorm": "16.97", "loss_scale": "0.0078", "train_wall": "19", "gb_free": "12.9", "wall": "1753"}
2021-10-10 20:09:09 | INFO | train_inner | {"epoch": 1, "update": 0.011, "loss": "5.607", "code_loss": "7.723", "value_loss_mse": "0.057", "code_ppl": "211.32", "wps": "17925.2", "ups": "0.08", "wpb": "223252", "bsz": "1024", "num_updates": "120", "lr": "6e-06", "gnorm": "14.181", "loss_scale": "0.0078", "train_wall": "17", "gb_free": "12.9", "wall": "1878"}
2021-10-10 20:11:23 | INFO | train_inner | {"epoch": 1, "update": 0.012, "loss": "5.431", "code_loss": "7.413", "value_loss_mse": "0.056", "code_ppl": "170.39", "wps": "19125.9", "ups": "0.07", "wpb": "256474", "bsz": "1024", "num_updates": "130", "lr": "6.5e-06", "gnorm": "12.476", "loss_scale": "0.0078", "train_wall": "20", "gb_free": "12.9", "wall": "2012"}
2021-10-10 20:13:32 | INFO | train_inner | {"epoch": 1, "update": 0.012, "loss": "5.395", "code_loss": "7.074", "value_loss_mse": "0.056", "code_ppl": "134.77", "wps": "19214.5", "ups": "0.08", "wpb": "246672", "bsz": "1024", "num_updates": "140", "lr": "7e-06", "gnorm": "9.247", "loss_scale": "0.0078", "train_wall": "19", "gb_free": "12.9", "wall": "2140"}
2021-10-10 20:15:45 | INFO | train_inner | {"epoch": 1, "update": 0.013, "loss": "5.229", "code_loss": "6.756", "value_loss_mse": "0.055", "code_ppl": "108.09", "wps": "18720.3", "ups": "0.08", "wpb": "249547", "bsz": "1024", "num_updates": "150", "lr": "7.5e-06", "gnorm": "8.504", "loss_scale": "0.0078", "train_wall": "19", "gb_free": "12.9", "wall": "2274"}
2021-10-10 20:17:55 | INFO | train_inner | {"epoch": 1, "update": 0.014, "loss": "5.149", "code_loss": "6.489", "value_loss_mse": "0.054", "code_ppl": "89.84", "wps": "19449.5", "ups": "0.08", "wpb": "253603", "bsz": "1024", "num_updates": "160", "lr": "8e-06", "gnorm": "6.808", "loss_scale": "0.0078", "train_wall": "21", "gb_free": "12.9", "wall": "2404"}
2021-10-10 20:20:06 | INFO | train_inner | {"epoch": 1, "update": 0.015, "loss": "5.129", "code_loss": "6.278", "value_loss_mse": "0.055", "code_ppl": "77.61", "wps": "18779.3", "ups": "0.08", "wpb": "245008", "bsz": "1024", "num_updates": "170", "lr": "8.5e-06", "gnorm": "5.602", "loss_scale": "0.0078", "train_wall": "21", "gb_free": "12.9", "wall": "2535"}
2021-10-10 20:22:16 | INFO | train_inner | {"epoch": 1, "update": 0.016, "loss": "5.097", "code_loss": "6.089", "value_loss_mse": "0.055", "code_ppl": "68.05", "wps": "18464.1", "ups": "0.08", "wpb": "240445", "bsz": "1024", "num_updates": "180", "lr": "9e-06", "gnorm": "5.296", "loss_scale": "0.0078", "train_wall": "18", "gb_free": "12.9", "wall": "2665"}
2021-10-10 20:24:23 | INFO | train_inner | {"epoch": 1, "update": 0.016, "loss": "4.971", "code_loss": "5.935", "value_loss_mse": "0.054", "code_ppl": "61.16", "wps": "18428.9", "ups": "0.08", "wpb": "234634", "bsz": "1024", "num_updates": "190", "lr": "9.5e-06", "gnorm": "5.251", "loss_scale": "0.0078", "train_wall": "18", "gb_free": "12.9", "wall": "2792"}
2021-10-10 20:26:26 | INFO | train_inner | {"epoch": 1, "update": 0.017, "loss": "4.904", "code_loss": "5.787", "value_loss_mse": "0.053", "code_ppl": "55.22", "wps": "19253.2", "ups": "0.08", "wpb": "236348", "bsz": "1024", "num_updates": "200", "lr": "1e-05", "gnorm": "5.229", "loss_scale": "0.0078", "train_wall": "22", "gb_free": "12.9", "wall": "2915"}
2021-10-10 20:28:33 | INFO | train_inner | {"epoch": 1, "update": 0.018, "loss": "4.824", "code_loss": "5.668", "value_loss_mse": "0.052", "code_ppl": "50.83", "wps": "18851.4", "ups": "0.08", "wpb": "239565", "bsz": "1024", "num_updates": "210", "lr": "1.05e-05", "gnorm": "5.753", "loss_scale": "0.0078", "train_wall": "45", "gb_free": "12.9", "wall": "3042"}
2021-10-10 20:30:36 | INFO | train_inner | {"epoch": 1, "update": 0.019, "loss": "4.741", "code_loss": "5.569", "value_loss_mse": "0.051", "code_ppl": "47.46", "wps": "19392.3", "ups": "0.08", "wpb": "237445", "bsz": "1024", "num_updates": "220", "lr": "1.1e-05", "gnorm": "5.457", "loss_scale": "0.0078", "train_wall": "53", "gb_free": "12.9", "wall": "3164"}
2021-10-10 20:32:38 | INFO | train_inner | {"epoch": 1, "update": 0.02, "loss": "4.578", "code_loss": "5.482", "value_loss_mse": "0.049", "code_ppl": "44.68", "wps": "18958.1", "ups": "0.08", "wpb": "232002", "bsz": "1024", "num_updates": "230", "lr": "1.15e-05", "gnorm": "5.749", "loss_scale": "0.0078", "train_wall": "17", "gb_free": "12.9", "wall": "3287"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0323486328125, 0.033477783203125, 0.040252685546875, 0.03607177734375, 0.0292510986328125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0179901123046875, 0.0210418701171875, 0.02752685546875, 0.028167724609375, 0.03839111328125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.041473388671875, 0.08599853515625, 0.107421875, 0.055511474609375, 0.051849365234375]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.06585693359375, 0.049041748046875, 0.090087890625, 0.058013916015625, 0.118408203125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0546875, 0.058135986328125, 0.1500244140625, 0.06549072265625, 0.1014404296875]
byte6 tgt value: [0.0078125, 0.0078125, 0.00390625, 0.0, 0.0]
byte6 pred value: [0.08343505859375, 0.06829833984375, 0.0894775390625, 0.08465576171875, 0.089111328125]
byte7 tgt value: [0.640625, 0.640625, 0.7265625, 0.01171875, 0.4453125]
byte7 pred value: [0.486083984375, 0.368896484375, 0.1988525390625, 0.174072265625, 0.427734375]
byte8 tgt value: [0.52734375, 0.1796875, 0.484375, 0.15234375, 0.8125]
byte8 pred value: [0.5126953125, 0.465576171875, 0.376708984375, 0.216064453125, 0.386474609375]
tgt code: rax xor r12 add mov
pred code: hexvar mov hexvar hexvar hexvar
2021-10-10 20:34:56 | INFO | train_inner | {"epoch": 1, "update": 0.02, "loss": "4.347", "code_loss": "5.365", "value_loss_mse": "0.046", "code_ppl": "41.21", "wps": "18479.2", "ups": "0.07", "wpb": "254122", "bsz": "1024", "num_updates": "240", "lr": "1.2e-05", "gnorm": "6.116", "loss_scale": "0.0078", "train_wall": "63", "gb_free": "12.9", "wall": "3424"}
2021-10-10 20:37:02 | INFO | train_inner | {"epoch": 1, "update": 0.021, "loss": "4.286", "code_loss": "5.273", "value_loss_mse": "0.046", "code_ppl": "38.66", "wps": "18857.1", "ups": "0.08", "wpb": "239165", "bsz": "1024", "num_updates": "250", "lr": "1.25e-05", "gnorm": "6.513", "loss_scale": "0.0078", "train_wall": "94", "gb_free": "12.9", "wall": "3551"}
2021-10-10 20:39:03 | INFO | train_inner | {"epoch": 1, "update": 0.022, "loss": "4.146", "code_loss": "5.167", "value_loss_mse": "0.044", "code_ppl": "35.93", "wps": "19265", "ups": "0.08", "wpb": "232250", "bsz": "1024", "num_updates": "260", "lr": "1.3e-05", "gnorm": "8.853", "loss_scale": "0.0078", "train_wall": "63", "gb_free": "12.9", "wall": "3672"}
2021-10-10 20:41:14 | INFO | train_inner | {"epoch": 1, "update": 0.023, "loss": "4.111", "code_loss": "5.053", "value_loss_mse": "0.044", "code_ppl": "33.2", "wps": "18512.2", "ups": "0.08", "wpb": "242640", "bsz": "1024", "num_updates": "270", "lr": "1.35e-05", "gnorm": "5.7", "loss_scale": "0.0078", "train_wall": "85", "gb_free": "12.9", "wall": "3803"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.01519012451171875, 0.0219879150390625, 0.0119171142578125, 0.00963592529296875, 0.010650634765625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.01560211181640625, 0.0191192626953125, 0.01177978515625, 0.01282501220703125, 0.01395416259765625]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.034698486328125, 0.033843994140625, 0.247314453125, 0.07183837890625, 0.058013916015625]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.033843994140625, 0.0162811279296875, 0.378173828125, 0.08251953125, 0.0755615234375]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.10284423828125, 0.0321044921875, 0.51123046875, 0.272216796875, 0.1488037109375]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.05340576171875, 0.02886962890625, 0.366455078125, 0.1094970703125, 0.09368896484375]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.135986328125, 0.10723876953125, 0.16748046875, 0.1859130859375, 0.344970703125]
byte8 tgt value: [0.015625, 0.01171875, 0.0, 0.1171875, 0.00390625]
byte8 pred value: [0.286376953125, 0.15087890625, 0.283203125, 0.25341796875, 0.27734375]
tgt code: hexvar call r12 mov test
pred code: hexvar mov hexvar mov hexvar
2021-10-10 20:43:22 | INFO | train_inner | {"epoch": 1, "update": 0.024, "loss": "4.029", "code_loss": "4.95", "value_loss_mse": "0.043", "code_ppl": "30.9", "wps": "19127.6", "ups": "0.08", "wpb": "245690", "bsz": "1024", "num_updates": "280", "lr": "1.4e-05", "gnorm": "5.244", "loss_scale": "0.0078", "train_wall": "79", "gb_free": "12.9", "wall": "3931"}
2021-10-10 20:45:26 | INFO | train_inner | {"epoch": 1, "update": 0.024, "loss": "3.971", "code_loss": "4.832", "value_loss_mse": "0.043", "code_ppl": "28.49", "wps": "19409.7", "ups": "0.08", "wpb": "240461", "bsz": "1024", "num_updates": "290", "lr": "1.45e-05", "gnorm": "5.766", "loss_scale": "0.0078", "train_wall": "24", "gb_free": "12.9", "wall": "4055"}
2021-10-10 20:47:31 | INFO | train_inner | {"epoch": 1, "update": 0.025, "loss": "3.939", "code_loss": "4.722", "value_loss_mse": "0.042", "code_ppl": "26.38", "wps": "17675.4", "ups": "0.08", "wpb": "220867", "bsz": "1024", "num_updates": "300", "lr": "1.5e-05", "gnorm": "5.719", "loss_scale": "0.0078", "train_wall": "19", "gb_free": "12.9", "wall": "4180"}
2021-10-10 20:49:41 | INFO | train_inner | {"epoch": 1, "update": 0.026, "loss": "3.903", "code_loss": "4.602", "value_loss_mse": "0.042", "code_ppl": "24.29", "wps": "19008.8", "ups": "0.08", "wpb": "245584", "bsz": "1024", "num_updates": "310", "lr": "1.55e-05", "gnorm": "5.996", "loss_scale": "0.0078", "train_wall": "17", "gb_free": "12.9", "wall": "4309"}
2021-10-10 20:51:54 | INFO | train_inner | {"epoch": 1, "update": 0.027, "loss": "3.814", "code_loss": "4.497", "value_loss_mse": "0.041", "code_ppl": "22.58", "wps": "18572.8", "ups": "0.07", "wpb": "248813", "bsz": "1024", "num_updates": "320", "lr": "1.6e-05", "gnorm": "8.856", "loss_scale": "0.0078", "train_wall": "17", "gb_free": "12.9", "wall": "4443"}
2021-10-10 20:53:56 | INFO | train_inner | {"epoch": 1, "update": 0.028, "loss": "3.879", "code_loss": "4.394", "value_loss_mse": "0.042", "code_ppl": "21.03", "wps": "19452.7", "ups": "0.08", "wpb": "236122", "bsz": "1024", "num_updates": "330", "lr": "1.65e-05", "gnorm": "7.552", "loss_scale": "0.0078", "train_wall": "16", "gb_free": "12.9", "wall": "4565"}
2021-10-10 20:55:59 | INFO | train_inner | {"epoch": 1, "update": 0.028, "loss": "3.849", "code_loss": "4.287", "value_loss_mse": "0.042", "code_ppl": "19.52", "wps": "18475.8", "ups": "0.08", "wpb": "227798", "bsz": "1024", "num_updates": "340", "lr": "1.7e-05", "gnorm": "5.703", "loss_scale": "0.0078", "train_wall": "25", "gb_free": "12.9", "wall": "4688"}
2021-10-10 20:58:06 | INFO | train_inner | {"epoch": 1, "update": 0.029, "loss": "3.771", "code_loss": "4.197", "value_loss_mse": "0.042", "code_ppl": "18.35", "wps": "19647.4", "ups": "0.08", "wpb": "248741", "bsz": "1024", "num_updates": "350", "lr": "1.75e-05", "gnorm": "5.452", "loss_scale": "0.0078", "train_wall": "37", "gb_free": "12.9", "wall": "4814"}
2021-10-10 21:00:20 | INFO | train_inner | {"epoch": 1, "update": 0.03, "loss": "3.648", "code_loss": "4.085", "value_loss_mse": "0.04", "code_ppl": "16.97", "wps": "19243.4", "ups": "0.07", "wpb": "258301", "bsz": "1024", "num_updates": "360", "lr": "1.8e-05", "gnorm": "4.964", "loss_scale": "0.0078", "train_wall": "23", "gb_free": "12.9", "wall": "4949"}
2021-10-10 21:02:27 | INFO | train_inner | {"epoch": 1, "update": 0.031, "loss": "3.744", "code_loss": "4.036", "value_loss_mse": "0.042", "code_ppl": "16.41", "wps": "18806.7", "ups": "0.08", "wpb": "238998", "bsz": "1024", "num_updates": "370", "lr": "1.85e-05", "gnorm": "4.756", "loss_scale": "0.0078", "train_wall": "17", "gb_free": "12.9", "wall": "5076"}
2021-10-10 21:04:25 | INFO | train_inner | {"epoch": 1, "update": 0.032, "loss": "3.648", "code_loss": "3.942", "value_loss_mse": "0.041", "code_ppl": "15.37", "wps": "19313.6", "ups": "0.08", "wpb": "227517", "bsz": "1024", "num_updates": "380", "lr": "1.9e-05", "gnorm": "3.988", "loss_scale": "0.0078", "train_wall": "15", "gb_free": "12.9", "wall": "5194"}
2021-10-10 21:06:34 | INFO | train_inner | {"epoch": 1, "update": 0.032, "loss": "3.677", "code_loss": "3.902", "value_loss_mse": "0.041", "code_ppl": "14.95", "wps": "18040.8", "ups": "0.08", "wpb": "232099", "bsz": "1024", "num_updates": "390", "lr": "1.95e-05", "gnorm": "3.675", "loss_scale": "0.0078", "train_wall": "17", "gb_free": "12.9", "wall": "5322"}
2021-10-10 21:08:39 | INFO | train_inner | {"epoch": 1, "update": 0.033, "loss": "3.626", "code_loss": "3.831", "value_loss_mse": "0.041", "code_ppl": "14.23", "wps": "19142.2", "ups": "0.08", "wpb": "239965", "bsz": "1024", "num_updates": "400", "lr": "2e-05", "gnorm": "4.469", "loss_scale": "0.0078", "train_wall": "16", "gb_free": "12.9", "wall": "5448"}
2021-10-10 21:10:50 | INFO | train_inner | {"epoch": 1, "update": 0.034, "loss": "3.607", "code_loss": "3.78", "value_loss_mse": "0.04", "code_ppl": "13.74", "wps": "18032.1", "ups": "0.08", "wpb": "236869", "bsz": "1024", "num_updates": "410", "lr": "2.05e-05", "gnorm": "6.429", "loss_scale": "0.0078", "train_wall": "17", "gb_free": "12.9", "wall": "5579"}
2021-10-10 21:12:59 | INFO | train_inner | {"epoch": 1, "update": 0.035, "loss": "3.612", "code_loss": "3.742", "value_loss_mse": "0.041", "code_ppl": "13.38", "wps": "18628.3", "ups": "0.08", "wpb": "239693", "bsz": "1024", "num_updates": "420", "lr": "2.1e-05", "gnorm": "5.431", "loss_scale": "0.0078", "train_wall": "17", "gb_free": "12.9", "wall": "5708"}
2021-10-10 21:14:56 | INFO | train_inner | {"epoch": 1, "update": 0.036, "loss": "3.651", "code_loss": "3.691", "value_loss_mse": "0.041", "code_ppl": "12.91", "wps": "19144.3", "ups": "0.09", "wpb": "224920", "bsz": "1024", "num_updates": "430", "lr": "2.15e-05", "gnorm": "5.433", "loss_scale": "0.0078", "train_wall": "18", "gb_free": "12.9", "wall": "5825"}
2021-10-10 21:17:12 | INFO | train_inner | {"epoch": 1, "update": 0.037, "loss": "3.543", "code_loss": "3.676", "value_loss_mse": "0.04", "code_ppl": "12.78", "wps": "18528.1", "ups": "0.07", "wpb": "251962", "bsz": "1024", "num_updates": "440", "lr": "2.2e-05", "gnorm": "5.354", "loss_scale": "0.0078", "train_wall": "18", "gb_free": "12.9", "wall": "5961"}
2021-10-10 21:19:06 | INFO | train_inner | {"epoch": 1, "update": 0.037, "loss": "3.532", "code_loss": "3.626", "value_loss_mse": "0.04", "code_ppl": "12.34", "wps": "18663.9", "ups": "0.09", "wpb": "211766", "bsz": "1024", "num_updates": "450", "lr": "2.25e-05", "gnorm": "4.639", "loss_scale": "0.0078", "train_wall": "15", "gb_free": "12.9", "wall": "6075"}
2021-10-10 21:21:10 | INFO | train_inner | {"epoch": 1, "update": 0.038, "loss": "3.503", "code_loss": "3.598", "value_loss_mse": "0.039", "code_ppl": "12.11", "wps": "18574.1", "ups": "0.08", "wpb": "230573", "bsz": "1024", "num_updates": "460", "lr": "2.3e-05", "gnorm": "5.113", "loss_scale": "0.0078", "train_wall": "16", "gb_free": "12.9", "wall": "6199"}
2021-10-10 21:23:09 | INFO | train_inner | {"epoch": 1, "update": 0.039, "loss": "3.463", "code_loss": "3.563", "value_loss_mse": "0.039", "code_ppl": "11.82", "wps": "18802.6", "ups": "0.08", "wpb": "224320", "bsz": "1024", "num_updates": "470", "lr": "2.35e-05", "gnorm": "4.318", "loss_scale": "0.0078", "train_wall": "31", "gb_free": "19.3", "wall": "6318"}
2021-10-10 21:25:10 | INFO | train_inner | {"epoch": 1, "update": 0.04, "loss": "3.449", "code_loss": "3.54", "value_loss_mse": "0.039", "code_ppl": "11.63", "wps": "19153.1", "ups": "0.08", "wpb": "230931", "bsz": "1024", "num_updates": "480", "lr": "2.4e-05", "gnorm": "5.749", "loss_scale": "0.0078", "train_wall": "34", "gb_free": "12.9", "wall": "6439"}
2021-10-10 21:27:20 | INFO | train_inner | {"epoch": 1, "update": 0.041, "loss": "3.593", "code_loss": "3.549", "value_loss_mse": "0.041", "code_ppl": "11.7", "wps": "17497.8", "ups": "0.08", "wpb": "228560", "bsz": "1024", "num_updates": "490", "lr": "2.45e-05", "gnorm": "5.422", "loss_scale": "0.0078", "train_wall": "17", "gb_free": "12.9", "wall": "6569"}
2021-10-10 21:29:25 | INFO | train_inner | {"epoch": 1, "update": 0.041, "loss": "3.412", "code_loss": "3.513", "value_loss_mse": "0.038", "code_ppl": "11.42", "wps": "18520.8", "ups": "0.08", "wpb": "230413", "bsz": "1024", "num_updates": "500", "lr": "2.5e-05", "gnorm": "7.153", "loss_scale": "0.0078", "train_wall": "16", "gb_free": "12.9", "wall": "6694"}
2021-10-10 21:31:33 | INFO | train_inner | {"epoch": 1, "update": 0.042, "loss": "3.459", "code_loss": "3.488", "value_loss_mse": "0.039", "code_ppl": "11.22", "wps": "17950.3", "ups": "0.08", "wpb": "230272", "bsz": "1024", "num_updates": "510", "lr": "2.55e-05", "gnorm": "6.193", "loss_scale": "0.0078", "train_wall": "17", "gb_free": "12.9", "wall": "6822"}
2021-10-10 21:33:40 | INFO | train_inner | {"epoch": 1, "update": 0.043, "loss": "3.415", "code_loss": "3.484", "value_loss_mse": "0.039", "code_ppl": "11.19", "wps": "18603.1", "ups": "0.08", "wpb": "235492", "bsz": "1024", "num_updates": "520", "lr": "2.6e-05", "gnorm": "7.267", "loss_scale": "0.0156", "train_wall": "17", "gb_free": "12.9", "wall": "6948"}
2021-10-10 21:35:45 | INFO | train_inner | {"epoch": 1, "update": 0.044, "loss": "3.393", "code_loss": "3.426", "value_loss_mse": "0.038", "code_ppl": "10.75", "wps": "18887", "ups": "0.08", "wpb": "235821", "bsz": "1024", "num_updates": "530", "lr": "2.65e-05", "gnorm": "3.805", "loss_scale": "0.0156", "train_wall": "35", "gb_free": "12.9", "wall": "7073"}
2021-10-10 21:37:54 | INFO | train_inner | {"epoch": 1, "update": 0.045, "loss": "3.366", "code_loss": "3.424", "value_loss_mse": "0.038", "code_ppl": "10.73", "wps": "18010.3", "ups": "0.08", "wpb": "232358", "bsz": "1024", "num_updates": "540", "lr": "2.7e-05", "gnorm": "3.74", "loss_scale": "0.0156", "train_wall": "33", "gb_free": "12.9", "wall": "7202"}
2021-10-10 21:40:05 | INFO | train_inner | {"epoch": 1, "update": 0.045, "loss": "3.359", "code_loss": "3.409", "value_loss_mse": "0.038", "code_ppl": "10.62", "wps": "18835", "ups": "0.08", "wpb": "247322", "bsz": "1024", "num_updates": "550", "lr": "2.75e-05", "gnorm": "4.705", "loss_scale": "0.0156", "train_wall": "18", "gb_free": "12.9", "wall": "7334"}
2021-10-10 21:42:04 | INFO | train_inner | {"epoch": 1, "update": 0.046, "loss": "3.305", "code_loss": "3.385", "value_loss_mse": "0.037", "code_ppl": "10.45", "wps": "19376.8", "ups": "0.08", "wpb": "231242", "bsz": "1024", "num_updates": "560", "lr": "2.8e-05", "gnorm": "5.512", "loss_scale": "0.0156", "train_wall": "17", "gb_free": "12.9", "wall": "7453"}
2021-10-10 21:44:11 | INFO | train_inner | {"epoch": 1, "update": 0.047, "loss": "3.298", "code_loss": "3.379", "value_loss_mse": "0.037", "code_ppl": "10.41", "wps": "18500.9", "ups": "0.08", "wpb": "234774", "bsz": "1024", "num_updates": "570", "lr": "2.85e-05", "gnorm": "4.446", "loss_scale": "0.0156", "train_wall": "22", "gb_free": "12.9", "wall": "7580"}
2021-10-10 21:46:23 | INFO | train_inner | {"epoch": 1, "update": 0.048, "loss": "3.366", "code_loss": "3.368", "value_loss_mse": "0.038", "code_ppl": "10.32", "wps": "18484", "ups": "0.08", "wpb": "244377", "bsz": "1024", "num_updates": "580", "lr": "2.9e-05", "gnorm": "5.589", "loss_scale": "0.0156", "train_wall": "17", "gb_free": "12.9", "wall": "7712"}
2021-10-10 21:48:28 | INFO | train_inner | {"epoch": 1, "update": 0.049, "loss": "3.24", "code_loss": "3.338", "value_loss_mse": "0.037", "code_ppl": "10.11", "wps": "20011.4", "ups": "0.08", "wpb": "248888", "bsz": "1024", "num_updates": "590", "lr": "2.95e-05", "gnorm": "4.528", "loss_scale": "0.0156", "train_wall": "17", "gb_free": "12.9", "wall": "7836"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.021453857421875, 0.01036834716796875, 0.011688232421875, 0.0186920166015625, 0.0352783203125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.03021240234375, 0.01078033447265625, 0.01302337646484375, 0.01751708984375, 0.050048828125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.017913818359375, 0.012054443359375, 0.01177978515625, 0.0154876708984375, 0.08465576171875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.019866943359375, 0.006984710693359375, 0.006191253662109375, 0.0135345458984375, 0.08660888671875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.03277587890625, 0.0112457275390625, 0.0094146728515625, 0.0254669189453125, 0.089111328125]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.037384033203125, 0.0204925537109375, 0.015777587890625, 0.0274810791015625, 0.12335205078125]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.027374267578125, 0.185546875, 0.058441162109375, 0.0260009765625, 0.07611083984375]
byte8 tgt value: [0.09375, 0.03125, 0.03125, 0.0, 0.0]
byte8 pred value: [0.1495361328125, 0.283447265625, 0.1993408203125, 0.092529296875, 0.16064453125]
tgt code: hexvar push rdi ^8 hexvar
pred code: hexvar mov hexvar ^8 hexvar
2021-10-10 21:50:41 | INFO | train_inner | {"epoch": 1, "update": 0.049, "loss": "3.31", "code_loss": "3.311", "value_loss_mse": "0.038", "code_ppl": "9.92", "wps": "18811", "ups": "0.07", "wpb": "251139", "bsz": "1024", "num_updates": "600", "lr": "3e-05", "gnorm": "4.414", "loss_scale": "0.0156", "train_wall": "40", "gb_free": "12.9", "wall": "7970"}
2021-10-10 21:52:53 | INFO | train_inner | {"epoch": 1, "update": 0.05, "loss": "3.239", "code_loss": "3.294", "value_loss_mse": "0.037", "code_ppl": "9.81", "wps": "19148.6", "ups": "0.08", "wpb": "253146", "bsz": "1024", "num_updates": "610", "lr": "3.05e-05", "gnorm": "4.601", "loss_scale": "0.0156", "train_wall": "95", "gb_free": "12.9", "wall": "8102"}
2021-10-10 21:54:59 | INFO | train_inner | {"epoch": 1, "update": 0.051, "loss": "3.309", "code_loss": "3.267", "value_loss_mse": "0.038", "code_ppl": "9.62", "wps": "18477.2", "ups": "0.08", "wpb": "231398", "bsz": "1024", "num_updates": "620", "lr": "3.1e-05", "gnorm": "3.971", "loss_scale": "0.0156", "train_wall": "96", "gb_free": "12.9", "wall": "8227"}
2021-10-10 21:57:03 | INFO | train_inner | {"epoch": 1, "update": 0.052, "loss": "3.261", "code_loss": "3.273", "value_loss_mse": "0.037", "code_ppl": "9.66", "wps": "19466.9", "ups": "0.08", "wpb": "242843", "bsz": "1024", "num_updates": "630", "lr": "3.15e-05", "gnorm": "6.408", "loss_scale": "0.0156", "train_wall": "23", "gb_free": "20", "wall": "8352"}
2021-10-10 21:59:19 | INFO | train_inner | {"epoch": 1, "update": 0.053, "loss": "3.163", "code_loss": "3.234", "value_loss_mse": "0.036", "code_ppl": "9.41", "wps": "19465.4", "ups": "0.07", "wpb": "263221", "bsz": "1024", "num_updates": "640", "lr": "3.2e-05", "gnorm": "4.281", "loss_scale": "0.0156", "train_wall": "20", "gb_free": "12.9", "wall": "8487"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.6728515625, 0.60693359375, 0.62548828125, 0.732421875, 0.64990234375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.1805419921875, 0.1710205078125, 0.1756591796875, 0.207275390625, 0.2880859375]
byte3 tgt value: [0.47265625, 0.49609375, 0.0, 0.0, 0.0]
byte3 pred value: [0.521484375, 0.41015625, 0.3876953125, 0.5009765625, 0.40771484375]
byte4 tgt value: [0.765625, 0.99609375, 0.0, 0.0, 0.0]
byte4 pred value: [0.52197265625, 0.5283203125, 0.6982421875, 0.487060546875, 0.46142578125]
byte5 tgt value: [0.8828125, 0.87890625, 0.0, 0.0, 0.0]
byte5 pred value: [0.38037109375, 0.4453125, 0.303466796875, 0.51611328125, 0.4384765625]
byte6 tgt value: [0.69140625, 0.3203125, 0.0, 0.0, 0.0]
byte6 pred value: [0.62451171875, 0.63623046875, 0.658203125, 0.650390625, 0.74951171875]
byte7 tgt value: [0.25390625, 0.296875, 0.0, 0.0, 0.0]
byte7 pred value: [0.5869140625, 0.54736328125, 0.5078125, 0.51953125, 0.61669921875]
byte8 tgt value: [0.1875, 0.9375, 0.03125, 0.0, 0.1953125]
byte8 pred value: [0.603515625, 0.5810546875, 0.54443359375, 0.64794921875, 0.51220703125]
tgt code: eax je rip edi add
pred code: xorpd cvtsi2ss fcmovbe jo rep
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.1361083984375, 0.10089111328125, 0.13525390625, 0.0999755859375, 0.06292724609375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0728759765625, 0.06634521484375, 0.0975341796875, 0.061981201171875, 0.040374755859375]
byte3 tgt value: [0.171875, 0.49609375, 0.49609375, 0.0, 0.06640625]
byte3 pred value: [0.06964111328125, 0.0810546875, 0.07208251953125, 0.0762939453125, 0.09466552734375]
byte4 tgt value: [0.703125, 0.99609375, 0.99609375, 0.0, 0.82421875]
byte4 pred value: [0.11474609375, 0.1978759765625, 0.168212890625, 0.12066650390625, 0.1593017578125]
byte5 tgt value: [0.7890625, 0.9296875, 0.9296875, 0.0, 0.984375]
byte5 pred value: [0.1187744140625, 0.1375732421875, 0.16845703125, 0.10321044921875, 0.171630859375]
byte6 tgt value: [0.3984375, 0.26953125, 0.26953125, 0.0, 0.11328125]
byte6 pred value: [0.09619140625, 0.10467529296875, 0.09173583984375, 0.11920166015625, 0.11395263671875]
byte7 tgt value: [0.91796875, 0.23828125, 0.23828125, 0.0, 0.89453125]
byte7 pred value: [0.1795654296875, 0.234619140625, 0.237548828125, 0.255615234375, 0.313720703125]
byte8 tgt value: [0.41015625, 0.15625, 0.125, 0.1328125, 0.5625]
byte8 pred value: [0.2978515625, 0.2451171875, 0.3388671875, 0.2083740234375, 0.312744140625]
tgt code: hexvar pop rbx mov ^4
pred code: btc sbb nop rsi sar
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.07763671875, 0.07806396484375, 0.047607421875, 0.07183837890625, 0.07781982421875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.060516357421875, 0.048675537109375, 0.045013427734375, 0.062103271484375, 0.06427001953125]
byte3 tgt value: [0.19140625, 0.0, 0.0, 0.0, 0.19140625]
byte3 pred value: [0.1177978515625, 0.0994873046875, 0.09332275390625, 0.09930419921875, 0.07275390625]
byte4 tgt value: [0.38671875, 0.0, 0.0, 0.0, 0.38671875]
byte4 pred value: [0.1466064453125, 0.11932373046875, 0.1517333984375, 0.10174560546875, 0.12054443359375]
byte5 tgt value: [0.125, 0.0, 0.0, 0.0, 0.125]
byte5 pred value: [0.136962890625, 0.0987548828125, 0.120361328125, 0.0970458984375, 0.1416015625]
byte6 tgt value: [0.7578125, 0.0078125, 0.0, 0.0078125, 0.7578125]
byte6 pred value: [0.10504150390625, 0.13330078125, 0.1368408203125, 0.144287109375, 0.1253662109375]
byte7 tgt value: [0.69140625, 0.73828125, 0.0, 0.13671875, 0.75390625]
byte7 pred value: [0.2335205078125, 0.1561279296875, 0.1490478515625, 0.1866455078125, 0.1646728515625]
byte8 tgt value: [0.86328125, 0.890625, 0.1953125, 0.08984375, 0.75]
byte8 pred value: [0.2425537109375, 0.2587890625, 0.30810546875, 0.1959228515625, 0.25732421875]
tgt code: push sub rsp mov ^8
pred code: rbx sbb mov mov btc
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0106964111328125, 0.03875732421875, 0.011871337890625, 0.0212860107421875, 0.0232391357421875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00974273681640625, 0.0457763671875, 0.010009765625, 0.027587890625, 0.0208892822265625]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.07421875, 0.048675537109375, 0.0472412109375, 0.1083984375, 0.0264129638671875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.136962890625, 0.0880126953125, 0.105224609375, 0.1517333984375, 0.03271484375]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.249267578125, 0.1048583984375, 0.178955078125, 0.1766357421875, 0.0765380859375]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.192138671875, 0.07586669921875, 0.1424560546875, 0.1473388671875, 0.062225341796875]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.29052734375, 0.0869140625, 0.2490234375, 0.1927490234375, 0.06109619140625]
byte8 tgt value: [0.09765625, 0.09765625, 0.0078125, 0.0, 0.1953125]
byte8 pred value: [0.328857421875, 0.1456298828125, 0.281494140625, 0.240478515625, 0.1290283203125]
tgt code: hexvar r8 rbp mov hexvar
pred code: hexvar hexvar hexvar mov hexvar
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0165252685546875, 0.11859130859375, 0.01282501220703125, 0.007404327392578125, 0.04302978515625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0144500732421875, 0.1077880859375, 0.01302337646484375, 0.006313323974609375, 0.0253753662109375]
byte3 tgt value: [0.0, 0.140625, 0.140625, 0.0, 0.0]
byte3 pred value: [0.030670166015625, 0.2371826171875, 0.08526611328125, 0.01554107666015625, 0.06536865234375]
byte4 tgt value: [0.0, 0.16015625, 0.16015625, 0.0, 0.0]
byte4 pred value: [0.045013427734375, 0.330078125, 0.132568359375, 0.01861572265625, 0.08197021484375]
byte5 tgt value: [0.0, 0.37890625, 0.37890625, 0.0, 0.0]
byte5 pred value: [0.044586181640625, 0.281005859375, 0.1353759765625, 0.018157958984375, 0.0489501953125]
byte6 tgt value: [0.0, 0.93359375, 0.9140625, 0.0, 0.0]
byte6 pred value: [0.05023193359375, 0.287841796875, 0.2012939453125, 0.049957275390625, 0.081787109375]
byte7 tgt value: [0.0, 0.40234375, 0.40625, 0.0, 0.0]
byte7 pred value: [0.04681396484375, 0.237548828125, 0.308349609375, 0.390380859375, 0.061981201171875]
byte8 tgt value: [0.03125, 0.0625, 0.0, 0.40625, 0.40625]
byte8 pred value: [0.15234375, 0.1904296875, 0.3203125, 0.5693359375, 0.1322021484375]
tgt code: hexvar add rdx rbp rbx
pred code: hexvar mov hexvar hexvar hexvar
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0194244384765625, 0.0069580078125, 0.0135345458984375, 0.0202484130859375, 0.004665374755859375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.011871337890625, 0.00891876220703125, 0.017578125, 0.01837158203125, 0.006168365478515625]
byte3 tgt value: [0.0, 0.4609375, 0.49609375, 0.0, 0.0]
byte3 pred value: [0.0262603759765625, 0.186279296875, 0.471435546875, 0.056854248046875, 0.028167724609375]
byte4 tgt value: [0.0, 0.55859375, 0.99609375, 0.0, 0.0]
byte4 pred value: [0.0257110595703125, 0.4052734375, 0.94775390625, 0.06524658203125, 0.03985595703125]
byte5 tgt value: [0.0, 0.19921875, 0.66796875, 0.0, 0.0]
byte5 pred value: [0.05419921875, 0.42333984375, 0.78173828125, 0.09332275390625, 0.037811279296875]
byte6 tgt value: [0.0, 0.9921875, 0.59765625, 0.0, 0.0]
byte6 pred value: [0.04510498046875, 0.41162109375, 0.51220703125, 0.10284423828125, 0.0755615234375]
byte7 tgt value: [0.0, 0.4453125, 0.92578125, 0.0, 0.56640625]
byte7 pred value: [0.045196533203125, 0.4755859375, 0.45068359375, 0.06829833984375, 0.54248046875]
byte8 tgt value: [0.03125, 0.5625, 0.0, 0.03125, 0.34765625]
byte8 pred value: [0.11614990234375, 0.380859375, 0.3564453125, 0.152587890625, 0.404052734375]
tgt code: ret rsp hexvar rcx rax
pred code: mov hexvar hexvar hexvar +
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.004573822021484375, 0.00908660888671875, 0.007965087890625, 0.0322265625, 0.004848480224609375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: 2021-10-10 22:01:22 | INFO | train_inner | {"epoch": 1, "update": 0.053, "loss": "3.248", "code_loss": "3.26", "value_loss_mse": "0.037", "code_ppl": "9.58", "wps": "18815", "ups": "0.08", "wpb": "231942", "bsz": "1024", "num_updates": "650", "lr": "3.25e-05", "gnorm": "4.75", "loss_scale": "0.0156", "train_wall": "37", "gb_free": "12.9", "wall": "8611"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0165863037109375, 0.01137542724609375, 0.0345458984375, 0.027740478515625, 0.00945281982421875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.02532958984375, 0.01049041748046875, 0.034088134765625, 0.034759521484375, 0.007259368896484375]
byte3 tgt value: [0.31640625, 0.0, 0.31640625, 0.0, 0.0]
byte3 pred value: [0.312744140625, 0.10089111328125, 0.093017578125, 0.0616455078125, 0.01934814453125]
byte4 tgt value: [0.50390625, 0.0, 0.50390625, 0.0, 0.0]
byte4 pred value: [0.56005859375, 0.1890869140625, 0.11932373046875, 0.12158203125, 0.0299224853515625]
byte5 tgt value: [0.68359375, 0.0, 0.68359375, 0.0, 0.0]
byte5 pred value: [0.609375, 0.16845703125, 0.1290283203125, 0.1248779296875, 0.2130126953125]
byte6 tgt value: [0.08984375, 0.0, 0.13671875, 0.0, 0.0]
byte6 pred value: [0.363525390625, 0.126953125, 0.124755859375, 0.12408447265625, 0.167724609375]
byte7 tgt value: [0.8984375, 0.0, 0.5546875, 0.0, 0.0]
byte7 pred value: [0.63232421875, 0.1998291015625, 0.1175537109375, 0.09893798828125, 0.17333984375]
byte8 tgt value: [0.265625, 0.00390625, 0.5625, 0.0, 0.0]
byte8 pred value: [0.467041015625, 0.25048828125, 0.1939697265625, 0.1917724609375, 0.2313232421875]
tgt code: sub rbp rsp rax movzx
pred code: mov rbp rbp rip mov
2021-10-10 22:03:30 | INFO | train_inner | {"epoch": 1, "update": 0.054, "loss": "3.213", "code_loss": "3.2", "value_loss_mse": "0.037", "code_ppl": "9.19", "wps": "19017", "ups": "0.08", "wpb": "243383", "bsz": "1024", "num_updates": "660", "lr": "3.3e-05", "gnorm": "4.645", "loss_scale": "0.0156", "train_wall": "42", "gb_free": "12.9", "wall": "8739"}
2021-10-10 22:05:31 | INFO | train_inner | {"epoch": 1, "update": 0.055, "loss": "3.22", "code_loss": "3.199", "value_loss_mse": "0.037", "code_ppl": "9.19", "wps": "19233.5", "ups": "0.08", "wpb": "232480", "bsz": "1024", "num_updates": "670", "lr": "3.35e-05", "gnorm": "4.467", "loss_scale": "0.0156", "train_wall": "16", "gb_free": "12.9", "wall": "8860"}
2021-10-10 22:07:38 | INFO | train_inner | {"epoch": 1, "update": 0.056, "loss": "3.224", "code_loss": "3.182", "value_loss_mse": "0.037", "code_ppl": "9.08", "wps": "18789.3", "ups": "0.08", "wpb": "238390", "bsz": "1024", "num_updates": "680", "lr": "3.4e-05", "gnorm": "4.431", "loss_scale": "0.0156", "train_wall": "24", "gb_free": "12.9", "wall": "8986"}
2021-10-10 22:09:36 | INFO | train_inner | {"epoch": 1, "update": 0.057, "loss": "3.3", "code_loss": "3.175", "value_loss_mse": "0.038", "code_ppl": "9.03", "wps": "18870.4", "ups": "0.08", "wpb": "223904", "bsz": "1024", "num_updates": "690", "lr": "3.45e-05", "gnorm": "3.982", "loss_scale": "0.0156", "train_wall": "34", "gb_free": "12.9", "wall": "9105"}
2021-10-10 22:11:37 | INFO | train_inner | {"epoch": 1, "update": 0.057, "loss": "3.159", "code_loss": "3.136", "value_loss_mse": "0.036", "code_ppl": "8.79", "wps": "18855.3", "ups": "0.08", "wpb": "226765", "bsz": "1024", "num_updates": "700", "lr": "3.5e-05", "gnorm": "3.783", "loss_scale": "0.0156", "train_wall": "39", "gb_free": "12.9", "wall": "9225"}
2021-10-10 22:13:36 | INFO | train_inner | {"epoch": 1, "update": 0.058, "loss": "3.186", "code_loss": "3.116", "value_loss_mse": "0.036", "code_ppl": "8.67", "wps": "18582.8", "ups": "0.08", "wpb": "222118", "bsz": "1024", "num_updates": "710", "lr": "3.55e-05", "gnorm": "3.743", "loss_scale": "0.0156", "train_wall": "48", "gb_free": "12.9", "wall": "9345"}
2021-10-10 22:15:43 | INFO | train_inner | {"epoch": 1, "update": 0.059, "loss": "3.182", "code_loss": "3.098", "value_loss_mse": "0.036", "code_ppl": "8.56", "wps": "18380", "ups": "0.08", "wpb": "233370", "bsz": "1024", "num_updates": "720", "lr": "3.6e-05", "gnorm": "3.24", "loss_scale": "0.0156", "train_wall": "16", "gb_free": "12.9", "wall": "9472"}
2021-10-10 22:17:56 | INFO | train_inner | {"epoch": 1, "update": 0.06, "loss": "3.138", "code_loss": "3.089", "value_loss_mse": "0.036", "code_ppl": "8.51", "wps": "18498.6", "ups": "0.08", "wpb": "246261", "bsz": "1024", "num_updates": "730", "lr": "3.65e-05", "gnorm": "3.681", "loss_scale": "0.0156", "train_wall": "17", "gb_free": "12.9", "wall": "9605"}
2021-10-10 22:20:09 | INFO | train_inner | {"epoch": 1, "update": 0.061, "loss": "3.176", "code_loss": "3.07", "value_loss_mse": "0.036", "code_ppl": "8.4", "wps": "18500.9", "ups": "0.08", "wpb": "245325", "bsz": "1024", "num_updates": "740", "lr": "3.7e-05", "gnorm": "3.404", "loss_scale": "0.0156", "train_wall": "17", "gb_free": "12.9", "wall": "9738"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00881195068359375, 0.00669097900390625, 0.006439208984375, 0.0236968994140625, 0.004924774169921875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00945281982421875, 0.007175445556640625, 0.00572967529296875, 0.025177001953125, 0.005100250244140625]
byte3 tgt value: [0.0, 0.0, 0.30859375, 0.0, 0.0]
byte3 pred value: [0.006313323974609375, 0.0082855224609375, 0.042572021484375, 0.033477783203125, 0.03155517578125]
byte4 tgt value: [0.0, 0.0, 0.14453125, 0.0, 0.0]
byte4 pred value: [0.00572967529296875, 0.004627227783203125, 0.041778564453125, 0.0225830078125, 0.034759521484375]
byte5 tgt value: [0.0, 0.0, 0.046875, 0.0, 0.0]
byte5 pred value: [0.0074310302734375, 0.00885009765625, 0.04638671875, 0.027435302734375, 0.0260009765625]
byte6 tgt value: [0.0, 0.0, 0.53125, 0.0, 0.0]
byte6 pred value: [0.01483917236328125, 0.01422882080078125, 0.060516357421875, 0.0333251953125, 0.037689208984375]
byte7 tgt value: [0.0, 0.0, 0.5, 0.0, 0.3203125]
byte7 pred value: [0.0222930908203125, 0.03131103515625, 0.28515625, 0.0439453125, 0.40625]
byte8 tgt value: [0.1875, 0.15625, 0.14453125, 0.0390625, 0.1875]
byte8 pred value: [0.13525390625, 0.1591796875, 0.31982421875, 0.130126953125, 0.416259765625]
tgt code: rdi rbp + test hexvar
pred code: + + + mov hexvar
2021-10-10 22:22:20 | INFO | train_inner | {"epoch": 1, "update": 0.061, "loss": "3.085", "code_loss": "3.038", "value_loss_mse": "0.035", "code_ppl": "8.22", "wps": "18816.8", "ups": "0.08", "wpb": "247346", "bsz": "1024", "num_updates": "750", "lr": "3.75e-05", "gnorm": "3.298", "loss_scale": "0.0156", "train_wall": "17", "gb_free": "12.9", "wall": "9869"}
2021-10-10 22:24:20 | INFO | train_inner | {"epoch": 1, "update": 0.062, "loss": "3.205", "code_loss": "3.046", "value_loss_mse": "0.037", "code_ppl": "8.26", "wps": "18967", "ups": "0.08", "wpb": "227136", "bsz": "1024", "num_updates": "760", "lr": "3.8e-05", "gnorm": "3.653", "loss_scale": "0.0156", "train_wall": "16", "gb_free": "12.9", "wall": "9989"}
2021-10-10 22:26:30 | INFO | train_inner | {"epoch": 1, "update": 0.063, "loss": "3.145", "code_loss": "2.986", "value_loss_mse": "0.036", "code_ppl": "7.92", "wps": "18068.4", "ups": "0.08", "wpb": "234147", "bsz": "1024", "num_updates": "770", "lr": "3.85e-05", "gnorm": "4.375", "loss_scale": "0.0156", "train_wall": "66", "gb_free": "12.9", "wall": "10118"}
2021-10-10 22:28:32 | INFO | train_inner | {"epoch": 1, "update": 0.064, "loss": "3.14", "code_loss": "3.002", "value_loss_mse": "0.036", "code_ppl": "8.01", "wps": "18319.5", "ups": "0.08", "wpb": "224397", "bsz": "1024", "num_updates": "780", "lr": "3.9e-05", "gnorm": "3.767", "loss_scale": "0.0156", "train_wall": "92", "gb_free": "12.9", "wall": "10241"}
2021-10-10 22:30:36 | INFO | train_inner | {"epoch": 1, "update": 0.065, "loss": "3.124", "code_loss": "2.971", "value_loss_mse": "0.036", "code_ppl": "7.84", "wps": "19072.1", "ups": "0.08", "wpb": "236621", "bsz": "1024", "num_updates": "790", "lr": "3.95e-05", "gnorm": "3.664", "loss_scale": "0.0156", "train_wall": "64", "gb_free": "12.9", "wall": "10365"}
2021-10-10 22:32:41 | INFO | train_inner | {"epoch": 1, "update": 0.065, "loss": "3.158", "code_loss": "2.968", "value_loss_mse": "0.036", "code_ppl": "7.83", "wps": "18414.9", "ups": "0.08", "wpb": "230109", "bsz": "1024", "num_updates": "800", "lr": "4e-05", "gnorm": "3.152", "loss_scale": "0.0156", "train_wall": "26", "gb_free": "12.9", "wall": "10490"}
2021-10-10 22:34:49 | INFO | train_inner | {"epoch": 1, "update": 0.066, "loss": "3.067", "code_loss": "2.95", "value_loss_mse": "0.035", "code_ppl": "7.73", "wps": "19653.1", "ups": "0.08", "wpb": "250746", "bsz": "1024", "num_updates": "810", "lr": "4.05e-05", "gnorm": "3.024", "loss_scale": "0.0156", "train_wall": "17", "gb_free": "12.9", "wall": "10617"}
2021-10-10 22:36:57 | INFO | train_inner | {"epoch": 1, "update": 0.067, "loss": "3.07", "code_loss": "2.945", "value_loss_mse": "0.035", "code_ppl": "7.7", "wps": "18453", "ups": "0.08", "wpb": "237242", "bsz": "1024", "num_updates": "820", "lr": "4.1e-05", "gnorm": "3.298", "loss_scale": "0.0156", "train_wall": "17", "gb_free": "12.9", "wall": "10746"}
2021-10-10 22:39:09 | INFO | train_inner | {"epoch": 1, "update": 0.068, "loss": "3.084", "code_loss": "2.934", "value_loss_mse": "0.036", "code_ppl": "7.64", "wps": "19584.1", "ups": "0.08", "wpb": "256979", "bsz": "1024", "num_updates": "830", "lr": "4.15e-05", "gnorm": "3.356", "loss_scale": "0.0156", "train_wall": "33", "gb_free": "12.9", "wall": "10877"}
2021-10-10 22:41:10 | INFO | train_inner | {"epoch": 1, "update": 0.069, "loss": "3.199", "code_loss": "2.925", "value_loss_mse": "0.037", "code_ppl": "7.59", "wps": "18236", "ups": "0.08", "wpb": "221520", "bsz": "1024", "num_updates": "840", "lr": "4.2e-05", "gnorm": "3.332", "loss_scale": "0.0156", "train_wall": "39", "gb_free": "12.9", "wall": "10999"}
2021-10-10 22:43:17 | INFO | train_inner | {"epoch": 1, "update": 0.069, "loss": "3.136", "code_loss": "2.895", "value_loss_mse": "0.036", "code_ppl": "7.44", "wps": "17980", "ups": "0.08", "wpb": "228550", "bsz": "1024", "num_updates": "850", "lr": "4.25e-05", "gnorm": "3.569", "loss_scale": "0.0156", "train_wall": "16", "gb_free": "12.9", "wall": "11126"}
2021-10-10 22:45:17 | INFO | train_inner | {"epoch": 1, "update": 0.07, "loss": "3.138", "code_loss": "2.896", "value_loss_mse": "0.036", "code_ppl": "7.44", "wps": "19247.1", "ups": "0.08", "wpb": "230266", "bsz": "1024", "num_updates": "860", "lr": "4.3e-05", "gnorm": "3.278", "loss_scale": "0.0156", "train_wall": "21", "gb_free": "12.9", "wall": "11245"}
2021-10-10 22:47:26 | INFO | train_inner | {"epoch": 1, "update": 0.071, "loss": "3.112", "code_loss": "2.92", "value_loss_mse": "0.036", "code_ppl": "7.57", "wps": "19252.9", "ups": "0.08", "wpb": "248494", "bsz": "1024", "num_updates": "870", "lr": "4.35e-05", "gnorm": "4.162", "loss_scale": "0.0156", "train_wall": "20", "gb_free": "12.9", "wall": "11375"}
2021-10-10 22:49:35 | INFO | train_inner | {"epoch": 1, "update": 0.072, "loss": "3.1", "code_loss": "2.893", "value_loss_mse": "0.036", "code_ppl": "7.43", "wps": "18450.6", "ups": "0.08", "wpb": "238510", "bsz": "1024", "num_updates": "880", "lr": "4.4e-05", "gnorm": "5.09", "loss_scale": "0.0156", "train_wall": "25", "gb_free": "12.9", "wall": "11504"}
2021-10-10 22:51:38 | INFO | train_inner | {"epoch": 1, "update": 0.073, "loss": "3.141", "code_loss": "2.882", "value_loss_mse": "0.036", "code_ppl": "7.37", "wps": "18789.4", "ups": "0.08", "wpb": "230211", "bsz": "1024", "num_updates": "890", "lr": "4.45e-05", "gnorm": "4.164", "loss_scale": "0.0156", "train_wall": "34", "gb_free": "12.9", "wall": "11626"}
2021-10-10 22:53:39 | INFO | train_inner | {"epoch": 1, "update": 0.074, "loss": "3.08", "code_loss": "2.855", "value_loss_mse": "0.036", "code_ppl": "7.23", "wps": "19741.7", "ups": "0.08", "wpb": "240496", "bsz": "1024", "num_updates": "900", "lr": "4.5e-05", "gnorm": "3.855", "loss_scale": "0.0156", "train_wall": "52", "gb_free": "12.9", "wall": "11748"}
2021-10-10 22:55:47 | INFO | train_inner | {"epoch": 1, "update": 0.074, "loss": "3.029", "code_loss": "2.872", "value_loss_mse": "0.035", "code_ppl": "7.32", "wps": "17963.5", "ups": "0.08", "wpb": "229008", "bsz": "1024", "num_updates": "910", "lr": "4.55e-05", "gnorm": "4.369", "loss_scale": "0.0156", "train_wall": "18", "gb_free": "12.9", "wall": "11876"}
2021-10-10 22:57:52 | INFO | train_inner | {"epoch": 1, "update": 0.075, "loss": "3.012", "code_loss": "2.854", "value_loss_mse": "0.035", "code_ppl": "7.23", "wps": "19319.9", "ups": "0.08", "wpb": "241532", "bsz": "1024", "num_updates": "920", "lr": "4.6e-05", "gnorm": "3.236", "loss_scale": "0.0156", "train_wall": "16", "gb_free": "12.9", "wall": "12001"}
2021-10-10 22:59:52 | INFO | train_inner | {"epoch": 1, "update": 0.076, "loss": "3.05", "code_loss": "2.841", "value_loss_mse": "0.035", "code_ppl": "7.17", "wps": "18866", "ups": "0.08", "wpb": "226026", "bsz": "1024", "num_updates": "930", "lr": "4.65e-05", "gnorm": "2.884", "loss_scale": "0.0156", "train_wall": "17", "gb_free": "12.9", "wall": "12120"}
2021-10-10 23:02:06 | INFO | train_inner | {"epoch": 1, "update": 0.077, "loss": "3.009", "code_loss": "2.849", "value_loss_mse": "0.035", "code_ppl": "7.21", "wps": "18858.9", "ups": "0.07", "wpb": "253827", "bsz": "1024", "num_updates": "940", "lr": "4.7e-05", "gnorm": "3.268", "loss_scale": "0.0156", "train_wall": "28", "gb_free": "12.9", "wall": "12255"}
byte1 tgt value: [0.0, 0.44140625, 0.0, 0.0, 0.0]
byte1 pred value: [0.010650634765625, 0.0250396728515625, 0.004070281982421875, 0.007843017578125, 0.00395965576171875]
byte2 tgt value: [0.0, 0.10546875, 0.0, 0.0, 0.0]
byte2 pred value: [0.008514404296875, 0.0162811279296875, 0.004451751708984375, 0.0062408447265625, 0.00498199462890625]
byte3 tgt value: [0.0, 0.5, 0.0, 0.0, 0.0]
byte3 pred value: [0.027740478515625, 0.018402099609375, 0.0237274169921875, 0.005039215087890625, 0.0323486328125]
byte4 tgt value: [0.0, 0.94921875, 0.0, 0.0, 0.0]
byte4 pred value: [0.09124755859375, 0.0222930908203125, 0.041534423828125, 0.005279541015625, 0.06890869140625]
byte5 tgt value: [0.0, 0.125, 0.0, 0.0, 0.0]
byte5 pred value: [0.06744384765625, 0.02801513671875, 0.050506591796875, 0.006488800048828125, 0.059539794921875]
byte6 tgt value: [0.0, 0.765625, 0.0, 0.0, 0.01953125]
byte6 pred value: [0.06427001953125, 0.039337158203125, 0.048675537109375, 0.00881195068359375, 0.058563232421875]
byte7 tgt value: [0.0, 0.21484375, 0.4375, 0.0, 0.34765625]
byte7 pred value: [0.30615234375, 0.0284881591796875, 0.4716796875, 0.05706787109375, 0.460205078125]
byte8 tgt value: [0.0390625, 0.85546875, 0.1875, 0.1875, 0.0]
byte8 pred value: [0.389892578125, 0.143798828125, 0.50341796875, 0.18359375, 0.5009765625]
tgt code: hexvar + + hexvar rdi
pred code: hexvar + + hexvar rsp
2021-10-10 23:04:16 | INFO | train_inner | {"epoch": 1, "update": 0.078, "loss": "3.034", "code_loss": "2.852", "value_loss_mse": "0.035", "code_ppl": "7.22", "wps": "18977.1", "ups": "0.08", "wpb": "245337", "bsz": "1024", "num_updates": "950", "lr": "4.75e-05", "gnorm": "3.67", "loss_scale": "0.0156", "train_wall": "92", "gb_free": "12.9", "wall": "12384"}
2021-10-10 23:06:22 | INFO | train_inner | {"epoch": 1, "update": 0.078, "loss": "2.987", "code_loss": "2.831", "value_loss_mse": "0.034", "code_ppl": "7.12", "wps": "18507.6", "ups": "0.08", "wpb": "233844", "bsz": "1024", "num_updates": "960", "lr": "4.8e-05", "gnorm": "3.551", "loss_scale": "0.0156", "train_wall": "88", "gb_free": "12.9", "wall": "12511"}
2021-10-10 23:08:28 | INFO | train_inner | {"epoch": 1, "update": 0.079, "loss": "3.071", "code_loss": "2.828", "value_loss_mse": "0.036", "code_ppl": "7.1", "wps": "18992.2", "ups": "0.08", "wpb": "238944", "bsz": "1024", "num_updates": "970", "lr": "4.85e-05", "gnorm": "5.096", "loss_scale": "0.0156", "train_wall": "73", "gb_free": "12.9", "wall": "12636"}
2021-10-10 23:10:27 | INFO | train_inner | {"epoch": 1, "update": 0.08, "loss": "3.094", "code_loss": "2.806", "value_loss_mse": "0.036", "code_ppl": "7", "wps": "18592.5", "ups": "0.08", "wpb": "222379", "bsz": "1024", "num_updates": "980", "lr": "4.9e-05", "gnorm": "4.614", "loss_scale": "0.0156", "train_wall": "25", "gb_free": "12.9", "wall": "12756"}
2021-10-10 23:12:26 | INFO | train_inner | {"epoch": 1, "update": 0.081, "loss": "3.054", "code_loss": "2.796", "value_loss_mse": "0.035", "code_ppl": "6.94", "wps": "18659.9", "ups": "0.08", "wpb": "221920", "bsz": "1024", "num_updates": "990", "lr": "4.95e-05", "gnorm": "4.272", "loss_scale": "0.0156", "train_wall": "71", "gb_free": "12.9", "wall": "12875"}
2021-10-10 23:14:36 | INFO | train_inner | {"epoch": 1, "update": 0.082, "loss": "3.034", "code_loss": "2.83", "value_loss_mse": "0.035", "code_ppl": "7.11", "wps": "18654.8", "ups": "0.08", "wpb": "241232", "bsz": "1024", "num_updates": "1000", "lr": "5e-05", "gnorm": "3.174", "loss_scale": "0.0156", "train_wall": "68", "gb_free": "12.9", "wall": "13004"}
2021-10-10 23:16:39 | INFO | train_inner | {"epoch": 1, "update": 0.082, "loss": "3.014", "code_loss": "2.802", "value_loss_mse": "0.035", "code_ppl": "6.97", "wps": "19726.3", "ups": "0.08", "wpb": "243638", "bsz": "1024", "num_updates": "1010", "lr": "5.05e-05", "gnorm": "3.448", "loss_scale": "0.0156", "train_wall": "29", "gb_free": "12.9", "wall": "13128"}
2021-10-10 23:18:51 | INFO | train_inner | {"epoch": 1, "update": 0.083, "loss": "3.042", "code_loss": "2.803", "value_loss_mse": "0.035", "code_ppl": "6.98", "wps": "18152", "ups": "0.08", "wpb": "238934", "bsz": "1024", "num_updates": "1020", "lr": "5.1e-05", "gnorm": "2.542", "loss_scale": "0.0156", "train_wall": "20", "gb_free": "12.9", "wall": "13259"}
2021-10-10 23:20:50 | INFO | train_inner | {"epoch": 1, "update": 0.084, "loss": "3.14", "code_loss": "2.782", "value_loss_mse": "0.037", "code_ppl": "6.88", "wps": "18786.7", "ups": "0.08", "wpb": "223359", "bsz": "1024", "num_updates": "1030", "lr": "5.15e-05", "gnorm": "3.173", "loss_scale": "0.0312", "train_wall": "29", "gb_free": "12.9", "wall": "13378"}
2021-10-10 23:22:52 | INFO | train_inner | {"epoch": 1, "update": 0.085, "loss": "2.959", "code_loss": "2.803", "value_loss_mse": "0.034", "code_ppl": "6.98", "wps": "18992", "ups": "0.08", "wpb": "232093", "bsz": "1024", "num_updates": "1040", "lr": "5.2e-05", "gnorm": "2.729", "loss_scale": "0.0312", "train_wall": "34", "gb_free": "12.9", "wall": "13501"}
2021-10-10 23:24:51 | INFO | train_inner | {"epoch": 1, "update": 0.086, "loss": "2.998", "code_loss": "2.778", "value_loss_mse": "0.035", "code_ppl": "6.86", "wps": "18787.4", "ups": "0.08", "wpb": "223671", "bsz": "1024", "num_updates": "1050", "lr": "5.25e-05", "gnorm": "3.192", "loss_scale": "0.0312", "train_wall": "19", "gb_free": "12.9", "wall": "13620"}
2021-10-10 23:26:58 | INFO | train_inner | {"epoch": 1, "update": 0.086, "loss": "3.04", "code_loss": "2.802", "value_loss_mse": "0.035", "code_ppl": "6.98", "wps": "19325", "ups": "0.08", "wpb": "246493", "bsz": "1024", "num_updates": "1060", "lr": "5.3e-05", "gnorm": "3.883", "loss_scale": "0.0312", "train_wall": "21", "gb_free": "12.9", "wall": "13747"}
2021-10-10 23:28:59 | INFO | train_inner | {"epoch": 1, "update": 0.087, "loss": "3.022", "code_loss": "2.79", "value_loss_mse": "0.035", "code_ppl": "6.92", "wps": "18456.5", "ups": "0.08", "wpb": "222060", "bsz": "1024", "num_updates": "1070", "lr": "5.35e-05", "gnorm": "3.573", "loss_scale": "0.0312", "train_wall": "44", "gb_free": "12.9", "wall": "13867"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0170440673828125, 0.039794921875, 0.076416015625, 0.075439453125, 0.0189056396484375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.020843505859375, 0.038238525390625, 0.0703125, 0.06658935546875, 0.021209716796875]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0262603759765625, 0.054412841796875, 0.08868408203125, 0.1087646484375, 0.0190582275390625]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0240478515625, 0.08038330078125, 0.14013671875, 0.1275634765625, 0.0205230712890625]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.056640625, 0.06781005859375, 0.1331787109375, 0.10394287109375, 0.0232391357421875]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.0546875, 0.057586669921875, 0.10052490234375, 0.10015869140625, 0.0254669189453125]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.036224365234375, 0.045440673828125, 0.09912109375, 0.07781982421875, 0.018157958984375]
byte8 tgt value: [0.23828125, 0.046875, 0.23828125, 0.11328125, 0.0]
byte8 pred value: [0.157470703125, 0.1689453125, 0.1812744140625, 0.218994140625, 0.09912109375]
tgt code: rbp rbp - - mov
pred code: ^4 ^8 rbp - mov
2021-10-10 23:31:13 | INFO | train_inner | {"epoch": 1, "update": 0.088, "loss": "2.926", "code_loss": "2.745", "value_loss_mse": "0.034", "code_ppl": "6.7", "wps": "18342.7", "ups": "0.07", "wpb": "246820", "bsz": "1024", "num_updates": "1080", "lr": "5.4e-05", "gnorm": "3.018", "loss_scale": "0.0312", "train_wall": "18", "gb_free": "12.9", "wall": "14002"}
2021-10-10 23:33:26 | INFO | train_inner | {"epoch": 1, "update": 0.089, "loss": "2.936", "code_loss": "2.77", "value_loss_mse": "0.034", "code_ppl": "6.82", "wps": "18836.9", "ups": "0.08", "wpb": "250672", "bsz": "1024", "num_updates": "1090", "lr": "5.45e-05", "gnorm": "2.494", "loss_scale": "0.0312", "train_wall": "17", "gb_free": "12.9", "wall": "14135"}
2021-10-10 23:35:31 | INFO | train_inner | {"epoch": 1, "update": 0.09, "loss": "3.002", "code_loss": "2.761", "value_loss_mse": "0.035", "code_ppl": "6.78", "wps": "18809.1", "ups": "0.08", "wpb": "233443", "bsz": "1024", "num_updates": "1100", "lr": "5.5e-05", "gnorm": "3.477", "loss_scale": "0.0312", "train_wall": "16", "gb_free": "12.9", "wall": "14259"}
byte1 tgt value: [0.0, 0.0, 0.8828125, 0.0, 0.0]
byte1 pred value: [0.016021728515625, 0.00885009765625, 0.0290374755859375, 0.0025310516357421875, 0.00524139404296875]
byte2 tgt value: [0.0, 0.0, 0.83984375, 0.0, 0.0]
byte2 pred value: [0.01433563232421875, 0.006824493408203125, 0.0287017822265625, 0.0025615692138671875, 0.004680633544921875]
byte3 tgt value: [0.49609375, 0.0, 0.3203125, 0.0, 0.0]
byte3 pred value: [0.5009765625, 0.0185089111328125, 0.2117919921875, 0.004085540771484375, 0.0070953369140625]
byte4 tgt value: [0.99609375, 0.0, 0.05859375, 0.0, 0.0]
byte4 pred value: [0.9794921875, 0.02691650390625, 0.441650390625, 0.00453948974609375, 0.011199951171875]
byte5 tgt value: [0.71875, 0.0, 0.08203125, 0.0, 0.0]
byte5 pred value: [0.7568359375, 0.01560211181640625, 0.2666015625, 0.0032596588134765625, 0.0171051025390625]
byte6 tgt value: [0.45703125, 0.0, 0.06640625, 0.0, 0.0]
byte6 pred value: [0.46484375, 0.0187225341796875, 0.2333984375, 0.00600433349609375, 0.030731201171875]
byte7 tgt value: [0.921875, 0.0, 0.9765625, 0.0, 0.0]
byte7 pred value: [0.48388671875, 0.018096923828125, 0.288330078125, 0.1337890625, 0.017578125]
byte8 tgt value: [0.90625, 0.45703125, 0.91015625, 0.0625, 0.0390625]
byte8 pred value: [0.8681640625, 0.146484375, 0.456787109375, 0.265625, 0.05224609375]
tgt code: rbx mov eax rax mov
pred code: hexvar mov hexvar rsp mov
2021-10-10 23:37:47 | INFO | train_inner | {"epoch": 1, "update": 0.09, "loss": "2.968", "code_loss": "2.754", "value_loss_mse": "0.034", "code_ppl": "6.75", "wps": "17308.7", "ups": "0.07", "wpb": "236691", "bsz": "1024", "num_updates": "1110", "lr": "5.55e-05", "gnorm": "3.083", "loss_scale": "0.0312", "train_wall": "18", "gb_free": "12.9", "wall": "14396"}
2021-10-10 23:39:53 | INFO | train_inner | {"epoch": 1, "update": 0.091, "loss": "2.919", "code_loss": "2.751", "value_loss_mse": "0.034", "code_ppl": "6.73", "wps": "18264.3", "ups": "0.08", "wpb": "229648", "bsz": "1024", "num_updates": "1120", "lr": "5.6e-05", "gnorm": "3.137", "loss_scale": "0.0312", "train_wall": "16", "gb_free": "12.9", "wall": "14522"}
2021-10-10 23:42:03 | INFO | train_inner | {"epoch": 1, "update": 0.092, "loss": "3.002", "code_loss": "2.741", "value_loss_mse": "0.035", "code_ppl": "6.68", "wps": "17749.2", "ups": "0.08", "wpb": "231485", "bsz": "1024", "num_updates": "1130", "lr": "5.65e-05", "gnorm": "3.365", "loss_scale": "0.0312", "train_wall": "17", "gb_free": "12.9", "wall": "14652"}
2021-10-10 23:44:15 | INFO | train_inner | {"epoch": 1, "update": 0.093, "loss": "2.956", "code_loss": "2.741", "value_loss_mse": "0.034", "code_ppl": "6.69", "wps": "19227.2", "ups": "0.08", "wpb": "253072", "bsz": "1024", "num_updates": "1140", "lr": "5.7e-05", "gnorm": "3.725", "loss_scale": "0.0312", "train_wall": "17", "gb_free": "12.9", "wall": "14784"}
2021-10-10 23:46:16 | INFO | train_inner | {"epoch": 1, "update": 0.094, "loss": "2.969", "code_loss": "2.737", "value_loss_mse": "0.035", "code_ppl": "6.67", "wps": "19355.9", "ups": "0.08", "wpb": "234272", "bsz": "1024", "num_updates": "1150", "lr": "5.75e-05", "gnorm": "3.442", "loss_scale": "0.0312", "train_wall": "28", "gb_free": "12.9", "wall": "14905"}
2021-10-10 23:48:23 | INFO | train_inner | {"epoch": 1, "update": 0.094, "loss": "2.923", "code_loss": "2.709", "value_loss_mse": "0.034", "code_ppl": "6.54", "wps": "18784", "ups": "0.08", "wpb": "239043", "bsz": "1024", "num_updates": "1160", "lr": "5.8e-05", "gnorm": "4.342", "loss_scale": "0.0312", "train_wall": "35", "gb_free": "12.9", "wall": "15032"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.012237548828125, 0.00844573974609375, 0.0022258758544921875, 0.13623046875, 0.00981903076171875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.010009765625, 0.00757598876953125, 0.0023975372314453125, 0.1529541015625, 0.009674072265625]
byte3 tgt value: [0.49609375, 0.49609375, 0.0, 0.078125, 0.49609375]
byte3 pred value: [0.469482421875, 0.477783203125, 0.0043487548828125, 0.198974609375, 0.51171875]
byte4 tgt value: [0.99609375, 0.99609375, 0.0, 0.1875, 0.99609375]
byte4 pred value: [0.9755859375, 0.9697265625, 0.0048675537109375, 0.2265625, 0.97021484375]
byte5 tgt value: [0.87109375, 0.87109375, 0.0, 0.77734375, 0.87109375]
byte5 pred value: [0.75439453125, 0.7470703125, 0.00595855712890625, 0.2281494140625, 0.76171875]
byte6 tgt value: [0.6953125, 0.6953125, 0.0, 0.30078125, 0.6953125]
byte6 pred value: [0.51806640625, 0.521484375, 0.00981903076171875, 0.2091064453125, 0.52392578125]
byte7 tgt value: [0.61328125, 0.61328125, 0.0, 0.015625, 0.61328125]
byte7 pred value: [0.572265625, 0.57763671875, 0.0141754150390625, 0.2469482421875, 0.58154296875]
byte8 tgt value: [0.0625, 0.0625, 0.0625, 0.4375, 0.0625]
byte8 pred value: [0.07122802734375, 0.0855712890625, 0.39111328125, 0.283203125, 0.09808349609375]
tgt code: rbp ^8 - - hexvar
pred code: rbp ^8 - - hexvar
2021-10-10 23:50:31 | INFO | train_inner | {"epoch": 1, "update": 0.095, "loss": "2.917", "code_loss": "2.699", "value_loss_mse": "0.034", "code_ppl": "6.49", "wps": "18471.6", "ups": "0.08", "wpb": "235258", "bsz": "1024", "num_updates": "1170", "lr": "5.85e-05", "gnorm": "3.718", "loss_scale": "0.0312", "train_wall": "18", "gb_free": "12.9", "wall": "15159"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00319671630859375, 0.0101318359375, 0.004230499267578125, 0.003765106201171875, 0.003650665283203125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00243377685546875, 0.008544921875, 0.0054473876953125, 0.0034427642822265625, 0.003185272216796875]
byte3 tgt value: [0.0, 0.49609375, 0.0, 0.0, 0.0]
byte3 pred value: [0.0050811767578125, 0.468505859375, 0.0059814453125, 0.006771087646484375, 0.00518035888671875]
byte4 tgt value: [0.0, 0.99609375, 0.0, 0.0, 0.0]
byte4 pred value: [0.004314422607421875, 0.978515625, 0.00359344482421875, 0.004451751708984375, 0.00428009033203125]
byte5 tgt value: [0.0, 0.98046875, 0.0, 0.0, 0.0]
byte5 pred value: [0.00392913818359375, 0.787109375, 0.005619049072265625, 0.00916290283203125, 0.00572967529296875]
byte6 tgt value: [0.0, 0.7265625, 0.0, 0.0, 0.0]
byte6 pred value: [0.0083770751953125, 0.51416015625, 0.00812530517578125, 0.0090179443359375, 0.007965087890625]
byte7 tgt value: [0.0, 0.48828125, 0.0, 0.0, 0.0]
byte7 pred value: [0.019683837890625, 0.56689453125, 0.0222930908203125, 0.0169830322265625, 0.020294189453125]
byte8 tgt value: [0.03125, 0.125, 0.03125, 0.03125, 0.03125]
byte8 pred value: [0.1239013671875, 0.10760498046875, 0.1312255859375, 0.09844970703125, 0.09619140625]
tgt code: rax - hexvar rdi rax
pred code: hexvar - hexvar rax hexvar
2021-10-10 23:52:37 | INFO | train_inner | {"epoch": 1, "update": 0.096, "loss": "2.896", "code_loss": "2.732", "value_loss_mse": "0.033", "code_ppl": "6.64", "wps": "18566.2", "ups": "0.08", "wpb": "233990", "bsz": "1024", "num_updates": "1180", "lr": "5.9e-05", "gnorm": "3.852", "loss_scale": "0.0312", "train_wall": "17", "gb_free": "12.9", "wall": "15285"}
[0.004364013671875, 0.01078033447265625, 0.0118255615234375, 0.047332763671875, 0.005687713623046875]
byte3 tgt value: [0.453125, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.05987548828125, 0.006290435791015625, 0.007724761962890625, 0.03228759765625, 0.05059814453125]
byte4 tgt value: [0.29296875, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.1689453125, 0.006145477294921875, 0.00905609130859375, 0.049957275390625, 0.11065673828125]
byte5 tgt value: [0.46484375, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.109130859375, 0.0131683349609375, 0.0127716064453125, 0.06622314453125, 0.09027099609375]
byte6 tgt value: [0.45703125, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.1639404296875, 0.0184783935546875, 0.0185089111328125, 0.093994140625, 0.1104736328125]
byte7 tgt value: [0.62890625, 0.0, 0.46484375, 0.0, 0.53125]
byte7 pred value: [0.446044921875, 0.039794921875, 0.029754638671875, 0.0251312255859375, 0.38330078125]
byte8 tgt value: [0.75, 0.00390625, 0.2265625, 0.0078125, 0.625]
byte8 pred value: [0.55517578125, 0.2132568359375, 0.1890869140625, 0.1517333984375, 0.499755859375]
tgt code: xor lea rbp mov hexvar
pred code: mov mov hexvar mov hexvar
byte1 tgt value: [0.0, 0.99609375, 0.0, 0.0, 0.0]
byte1 pred value: [0.006191253662109375, 0.04168701171875, 0.09088134765625, 0.007122039794921875, 0.01678466796875]
byte2 tgt value: [0.0, 0.390625, 0.0, 0.0, 0.0]
byte2 pred value: [0.0082550048828125, 0.03521728515625, 0.076416015625, 0.00908660888671875, 0.018341064453125]
byte3 tgt value: [0.0, 0.85546875, 0.0, 0.0, 0.0]
byte3 pred value: [0.11419677734375, 0.08770751953125, 0.08197021484375, 0.007205963134765625, 0.05792236328125]
byte4 tgt value: [0.0, 0.60546875, 0.0, 0.0, 0.0]
byte4 pred value: [0.2822265625, 0.1458740234375, 0.1217041015625, 0.011871337890625, 0.11737060546875]
byte5 tgt value: [0.0, 0.91796875, 0.0, 0.0, 0.0]
byte5 pred value: [0.2042236328125, 0.107421875, 0.072265625, 0.1331787109375, 0.09588623046875]
byte6 tgt value: [0.0078125, 0.03125, 0.0, 0.0, 0.0]
byte6 pred value: [0.2091064453125, 0.1337890625, 0.07574462890625, 0.12335205078125, 0.097900390625]
byte7 tgt value: [0.9453125, 0.88671875, 0.0, 0.0, 0.0]
byte7 pred value: [0.5322265625, 0.1392822265625, 0.1424560546875, 0.143310546875, 0.251220703125]
byte8 tgt value: [0.375, 0.49609375, 0.09765625, 0.16015625, 0.1875]
byte8 pred value: [0.51611328125, 0.1927490234375, 0.205322265625, 0.227783203125, 0.308837890625]
tgt code: hexvar rbx hexvar hexvar eax
pred code: hexvar + hexvar hexvar eax
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00948333740234375, 0.021331787109375, 0.0025501251220703125, 0.0030517578125, 0.0024814605712890625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.01348114013671875, 0.0224609375, 0.003692626953125, 0.0038852691650390625, 0.00269317626953125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.03790283203125, 0.037689208984375, 0.0482177734375, 0.04931640625, 0.0038700103759765625]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0723876953125, 0.03533935546875, 0.0966796875, 0.1114501953125, 0.00579833984375]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.12408447265625, 0.054595947265625, 0.055206298828125, 0.060760498046875, 0.004680633544921875]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.13720703125, 0.055816650390625, 0.0802001953125, 0.07586669921875, 0.01238250732421875]
byte7 tgt value: [0.0, 0.0, 0.12890625, 0.43359375, 0.0]
byte7 pred value: [0.1705322265625, 0.06451416015625, 0.370361328125, 0.389892578125, 0.247802734375]
byte8 tgt value: [0.01171875, 0.125, 0.75, 0.60546875, 0.00390625]
byte8 pred value: [0.227783203125, 0.1927490234375, 0.497314453125, 0.486572265625, 0.36962890625]
tgt code: rsi mov rsi r13 hexvar
pred code: eax mov rbx eax hexvar
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00392913818359375, 0.005889892578125, 0.0022258758544921875, 0.003063201904296875, 0.0030269622802734375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.004215240478515625, 0.008575439453125, 0.003551483154296875, 0.005062103271484375, 0.004398345947265625]
byte3 tgt value: [0.0, 0.4921875, 0.0, 0.0, 0.0]
byte3 pred value: [0.051544189453125, 0.258544921875, 0.01433563232421875, 0.07806396484375, 0.0246124267578125]
byte4 tgt value: [0.0, 0.20703125, 0.0, 0.0, 0.0]
byte4 pred value: [0.1104736328125, 0.41845703125, 0.0129241943359375, 0.09515380859375, 0.048126220703125]
byte5 tgt value: [0.0, 0.078125, 0.0, 0.0, 0.0]
byte5 pred value: [0.1646728515625, 0.2890625, 0.0163421630859375, 0.08978271484375, 0.152099609375]
byte6 tgt value: [0.046875, 0.48828125, 0.00390625, 0.0, 0.0]
byte6 pred value: [0.126708984375, 0.454345703125, 0.04168701171875, 0.15576171875, 0.26513671875]
byte7 tgt value: [0.28125, 0.73046875, 0.83203125, 0.0, 0.0]
byte7 pred value: [0.320556640625, 0.372314453125, 0.33056640625, 0.1480712890625, 0.26171875]
byte8 tgt value: [0.4296875, 0.6875, 0.08984375, 0.01953125, 0.0]
byte8 pred value: [0.396240234375, 0.4677734375, 0.56591796875, 0.244873046875, 0.339111328125]
tgt code: rax jne hexvar ^4 ^4
pred code: eax mov hexvar rip ^4
byte1 tgt value: [0.0, 0.0, 0.0, 0.23828125, 0.984375]
byte1 pred value: [0.003124237060546875, 0.0032978057861328125, 0.01024627685546875, 0.053802490234375, 0.04327392578125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.30859375, 0.77734375]
byte2 pred value: [0.00313568115234375, 0.00557708740234375, 0.0118255615234375, 0.073974609375, 0.03460693359375]
byte3 tgt value: [0.0, 0.0, 0.0, 0.65234375, 0.890625]
byte3 pred value: [0.1361083984375, 0.280517578125, 0.01358795166015625, 0.0782470703125, 0.08770751953125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.21484375, 0.65625]
byte4 pred value: [0.364013671875, 0.472900390625, 0.0185089111328125, 0.13134765625, 0.1312255859375]
byte5 tgt value: [0.0, 0.0, 0.0, 0.140625, 0.68359375]
byte5 pred value: [0.281982421875, 0.419921875, 0.0238189697265625, 0.1336669921875, 0.1566162109375]
byte6 tgt value: [0.0, 0.0, 0.0, 0.48046875, 0.37109375]
byte6 pred value: [0.403076171875, 0.5068359375, 0.02423095703125, 0.10015869140625, 0.1143798828125]
byte7 tgt value: [0.0, 0.57421875, 0.0, 0.6015625, 0.82421875]
byte7 pred value: [0.2890625, 0.413330078125, 0.0202178955078125, 0.12042236328125, 0.11395263671875]
byte8 tgt value: [0.0234375, 0.9375, 0.2109375, 0.1328125, 0.12890625]
byte8 pred value: [0.264404296875, 0.326171875, 0.11474609375, 0.1923828125, 0.171875]
tgt code: - edi hexvar rip hexvar
pred code: + hexvar edi rip hexvar
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.01036834716796875, 0.0028228759765625, 0.0017271041870117188, 0.0024433135986328125, 0.00577545166015625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.007843017578125, 0.001964569091796875, 0.0015544891357421875, 0.0029582977294921875, 0.004886627197265625]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.1875]
byte3 pred value: [0.0257110595703125, 0.0069580078125, 0.00885009765625, 0.2100830078125, 0.16357421875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.046875]
byte4 pred value: [0.02838134765625, 0.0070648193359375, 0.010528564453125, 0.456787109375, 0.2293701171875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.3671875]
byte5 pred value: [0.0401611328125, 0.00885009765625, 0.013427734375, 0.41796875, 0.50341796875]
byte6 tgt value: [0.0, 0.0234375, 0.0234375, 0.01171875, 0.69921875]
byte6 pred value: [0.044342041015625, 0.014007568359375, 0.0199127197265625, 0.1993408203125, 0.283935546875]
byte7 tgt value: [0.0, 0.53515625, 0.5390625, 0.29296875, 0.8203125]
byte7 pred value: [0.06512451171875, 0.5283203125, 0.5068359375, 0.607421875, 0.52685546875]
byte8 tgt value: [0.0078125, 0.87109375, 0.0, 0.20703125, 0.625]
byte8 pred value: [0.097900390625, 0.4765625, 0.4306640625, 0.429931640625, 0.4765625]
tgt code: hexvar rip + add hexvar
pred code: hexvar rip + mov hexvar
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00530242919921875, 0.128173828125, 0.0154876708984375, 0.0034427642822265625, 0.05224609375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0043487548828125, 0.006744384765625, 0.005428314208984375, 0.005260467529296875, 0.001941680908203125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00397491455078125, 0.006313323974609375, 0.004467010498046875, 0.0038852691650390625, 0.0021495819091796875]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0038852691650390625, 0.0264129638671875, 0.004398345947265625, 0.0034427642822265625, 0.015838623046875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.004299163818359375, 0.06854248046875, 0.00399017333984375, 0.002811431884765625, 0.039337158203125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.006168365478515625, 0.07421875, 0.004627227783203125, 0.0029468536376953125, 0.047607421875]
byte6 tgt value: [0.0234375, 0.0, 0.0, 0.0, 0.0078125]
byte6 pred value: [0.0104522705078125, 0.06634521484375, 0.007549285888671875, 0.00626373291015625, 0.051544189453125]
byte7 tgt value: [0.3125, 0.79296875, 0.0, 0.0, 0.515625]
byte7 pred value: [0.285888671875, 0.53759765625, 0.018585205078125, 0.027374267578125, 0.5439453125]
byte8 tgt value: [0.171875, 0.8125, 0.125, 0.125, 0.5]
byte8 pred value: [0.31689453125, 0.427978515625, 0.1248779296875, 0.1353759765625, 0.49267578125]
tgt code: rbx movzx rdx + je
pred code: rdi mov rdi + mov
2021-10-10 23:54:38 | INFO | train_inner | {"epoch": 1, "update": 0.097, "loss": "2.942", "code_loss": "2.721", "value_loss_mse": "0.034", "code_ppl": "6.6", "wps": "18556.9", "ups": "0.08", "wpb": "225674", "bsz": "1024", "num_updates": "1190", "lr": "5.95e-05", "gnorm": "5.723", "loss_scale": "0.0312", "train_wall": "15", "gb_free": "12.9", "wall": "15407"}
2021-10-10 23:56:45 | INFO | train_inner | {"epoch": 1, "update": 0.098, "loss": "2.912", "code_loss": "2.713", "value_loss_mse": "0.034", "code_ppl": "6.56", "wps": "18899.6", "ups": "0.08", "wpb": "238986", "bsz": "1024", "num_updates": "1200", "lr": "6e-05", "gnorm": "4.428", "loss_scale": "0.0312", "train_wall": "28", "gb_free": "12.9", "wall": "15534"}
2021-10-10 23:58:47 | INFO | train_inner | {"epoch": 1, "update": 0.098, "loss": "2.913", "code_loss": "2.711", "value_loss_mse": "0.034", "code_ppl": "6.55", "wps": "18850.5", "ups": "0.08", "wpb": "229968", "bsz": "1024", "num_updates": "1210", "lr": "6.05e-05", "gnorm": "3.128", "loss_scale": "0.0312", "train_wall": "43", "gb_free": "12.9", "wall": "15656"}
2021-10-11 00:00:58 | INFO | train_inner | {"epoch": 1, "update": 0.099, "loss": "2.902", "code_loss": "2.709", "value_loss_mse": "0.034", "code_ppl": "6.54", "wps": "18748.1", "ups": "0.08", "wpb": "245289", "bsz": "1024", "num_updates": "1220", "lr": "6.1e-05", "gnorm": "3.65", "loss_scale": "0.0312", "train_wall": "16", "gb_free": "12.9", "wall": "15786"}
2021-10-11 00:03:12 | INFO | train_inner | {"epoch": 1, "update": 0.1, "loss": "2.86", "code_loss": "2.716", "value_loss_mse": "0.033", "code_ppl": "6.57", "wps": "18990.8", "ups": "0.07", "wpb": "254566", "bsz": "1024", "num_updates": "1230", "lr": "6.15e-05", "gnorm": "2.754", "loss_scale": "0.0312", "train_wall": "17", "gb_free": "12.9", "wall": "15920"}
2021-10-11 00:05:21 | INFO | train_inner | {"epoch": 1, "update": 0.101, "loss": "2.843", "code_loss": "2.706", "value_loss_mse": "0.033", "code_ppl": "6.52", "wps": "19038.4", "ups": "0.08", "wpb": "246854", "bsz": "1024", "num_updates": "1240", "lr": "6.2e-05", "gnorm": "3.841", "loss_scale": "0.0312", "train_wall": "16", "gb_free": "12.9", "wall": "16050"}
2021-10-11 00:07:28 | INFO | train_inner | {"epoch": 1, "update": 0.102, "loss": "2.984", "code_loss": "2.709", "value_loss_mse": "0.035", "code_ppl": "6.54", "wps": "19169.8", "ups": "0.08", "wpb": "242554", "bsz": "1024", "num_updates": "1250", "lr": "6.25e-05", "gnorm": "5.201", "loss_scale": "0.0312", "train_wall": "16", "gb_free": "12.9", "wall": "16177"}
2021-10-11 00:09:35 | INFO | train_inner | {"epoch": 1, "update": 0.102, "loss": "2.89", "code_loss": "2.692", "value_loss_mse": "0.033", "code_ppl": "6.46", "wps": "19022.4", "ups": "0.08", "wpb": "242026", "bsz": "1024", "num_updates": "1260", "lr": "6.3e-05", "gnorm": "3.482", "loss_scale": "0.0312", "train_wall": "50", "gb_free": "12.9", "wall": "16304"}
2021-10-11 00:11:49 | INFO | train_inner | {"epoch": 1, "update": 0.103, "loss": "2.808", "code_loss": "2.681", "value_loss_mse": "0.032", "code_ppl": "6.42", "wps": "19077.2", "ups": "0.07", "wpb": "255508", "bsz": "1024", "num_updates": "1270", "lr": "6.35e-05", "gnorm": "3.125", "loss_scale": "0.0312", "train_wall": "72", "gb_free": "12.9", "wall": "16438"}
2021-10-11 00:13:54 | INFO | train_inner | {"epoch": 1, "update": 0.104, "loss": "2.895", "code_loss": "2.71", "value_loss_mse": "0.033", "code_ppl": "6.54", "wps": "18274.8", "ups": "0.08", "wpb": "227690", "bsz": "1024", "num_updates": "1280", "lr": "6.4e-05", "gnorm": "3.232", "loss_scale": "0.0312", "train_wall": "57", "gb_free": "12.9", "wall": "16562"}
2021-10-11 00:16:00 | INFO | train_inner | {"epoch": 1, "update": 0.105, "loss": "2.914", "code_loss": "2.685", "value_loss_mse": "0.034", "code_ppl": "6.43", "wps": "18616.7", "ups": "0.08", "wpb": "234506", "bsz": "1024", "num_updates": "1290", "lr": "6.45e-05", "gnorm": "2.994", "loss_scale": "0.0312", "train_wall": "92", "gb_free": "12.9", "wall": "16688"}
2021-10-11 00:18:12 | INFO | train_inner | {"epoch": 1, "update": 0.106, "loss": "2.882", "code_loss": "2.726", "value_loss_mse": "0.033", "code_ppl": "6.62", "wps": "19384", "ups": "0.08", "wpb": "255782", "bsz": "1024", "num_updates": "1300", "lr": "6.5e-05", "gnorm": "3.671", "loss_scale": "0.0312", "train_wall": "37", "gb_free": "12.9", "wall": "16820"}
2021-10-11 00:20:20 | INFO | train_inner | {"epoch": 1, "update": 0.106, "loss": "2.862", "code_loss": "2.663", "value_loss_mse": "0.033", "code_ppl": "6.33", "wps": "18607.1", "ups": "0.08", "wpb": "239754", "bsz": "1024", "num_updates": "1310", "lr": "6.55e-05", "gnorm": "2.941", "loss_scale": "0.0312", "train_wall": "16", "gb_free": "12.9", "wall": "16949"}
2021-10-11 00:22:23 | INFO | train_inner | {"epoch": 1, "update": 0.107, "loss": "2.784", "code_loss": "2.676", "value_loss_mse": "0.032", "code_ppl": "6.39", "wps": "19527.4", "ups": "0.08", "wpb": "240141", "bsz": "1024", "num_updates": "1320", "lr": "6.6e-05", "gnorm": "3.366", "loss_scale": "0.0312", "train_wall": "18", "gb_free": "12.9", "wall": "17072"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.007205963134765625, 0.001483917236328125, 0.00279998779296875, 0.004055023193359375, 0.003040313720703125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0032978057861328125, 0.0022335052490234375, 0.00147247314453125, 0.001949310302734375, 0.0016679763793945312]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0129241943359375, 0.004665374755859375, 0.0030040740966796875, 0.01111602783203125, 0.01519012451171875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.019378662109375, 0.004962921142578125, 0.0029010772705078125, 0.0139007568359375, 0.01751708984375]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0165863037109375, 0.004665374755859375, 0.0032978057861328125, 0.01233673095703125, 0.01467132568359375]
byte6 tgt value: [0.0, 0.01171875, 0.0, 0.0, 0.0]
byte6 pred value: [0.022979736328125, 0.0099334716796875, 0.0074310302734375, 0.01512908935546875, 0.0160980224609375]
byte7 tgt value: [0.80078125, 0.04296875, 0.0, 0.4375, 0.796875]
byte7 pred value: [0.708984375, 0.1654052734375, 0.08038330078125, 0.748046875, 0.72412109375]
byte8 tgt value: [0.3671875, 0.390625, 0.15625, 0.4375, 0.23828125]
byte8 pred value: [0.47021484375, 0.294921875, 0.292724609375, 0.46923828125, 0.494384765625]
tgt code: rbp hexvar mov or je
pred code: rax hexvar mov mov mov
2021-10-11 00:24:33 | INFO | train_inner | {"epoch": 1, "update": 0.108, "loss": "2.848", "code_loss": "2.658", "value_loss_mse": "0.033", "code_ppl": "6.31", "wps": "19193", "ups": "0.08", "wpb": "249184", "bsz": "1024", "num_updates": "1330", "lr": "6.65e-05", "gnorm": "3.386", "loss_scale": "0.0312", "train_wall": "23", "gb_free": "12.9", "wall": "17202"}
2021-10-11 00:26:34 | INFO | train_inner | {"epoch": 1, "update": 0.109, "loss": "2.84", "code_loss": "2.667", "value_loss_mse": "0.033", "code_ppl": "6.35", "wps": "18560.9", "ups": "0.08", "wpb": "224275", "bsz": "1024", "num_updates": "1340", "lr": "6.7e-05", "gnorm": "3.943", "loss_scale": "0.0312", "train_wall": "51", "gb_free": "12.9", "wall": "17323"}
2021-10-11 00:28:41 | INFO | train_inner | {"epoch": 1, "update": 0.11, "loss": "2.795", "code_loss": "2.698", "value_loss_mse": "0.032", "code_ppl": "6.49", "wps": "18055.3", "ups": "0.08", "wpb": "229674", "bsz": "1024", "num_updates": "1350", "lr": "6.75e-05", "gnorm": "2.762", "loss_scale": "0.0312", "train_wall": "18", "gb_free": "12.9", "wall": "17450"}
2021-10-11 00:30:54 | INFO | train_inner | {"epoch": 1, "update": 0.111, "loss": "2.778", "code_loss": "2.684", "value_loss_mse": "0.032", "code_ppl": "6.43", "wps": "18197.5", "ups": "0.08", "wpb": "240748", "bsz": "1024", "num_updates": "1360", "lr": "6.8e-05", "gnorm": "2.634", "loss_scale": "0.0312", "train_wall": "17", "gb_free": "12.9", "wall": "17582"}
2021-10-11 00:32:58 | INFO | train_inner | {"epoch": 1, "update": 0.111, "loss": "2.83", "code_loss": "2.661", "value_loss_mse": "0.033", "code_ppl": "6.33", "wps": "18080.9", "ups": "0.08", "wpb": "224704", "bsz": "1024", "num_updates": "1370", "lr": "6.85e-05", "gnorm": "2.816", "loss_scale": "0.0312", "train_wall": "61", "gb_free": "12.9", "wall": "17707"}
2021-10-11 00:35:04 | INFO | train_inner | {"epoch": 1, "update": 0.112, "loss": "2.862", "code_loss": "2.682", "value_loss_mse": "0.033", "code_ppl": "6.42", "wps": "18811.2", "ups": "0.08", "wpb": "238218", "bsz": "1024", "num_updates": "1380", "lr": "6.9e-05", "gnorm": "2.48", "loss_scale": "0.0312", "train_wall": "90", "gb_free": "12.9", "wall": "17833"}
2021-10-11 00:37:20 | INFO | train_inner | {"epoch": 1, "update": 0.113, "loss": "2.792", "code_loss": "2.673", "value_loss_mse": "0.032", "code_ppl": "6.38", "wps": "18797.1", "ups": "0.07", "wpb": "255528", "bsz": "1024", "num_updates": "1390", "lr": "6.95e-05", "gnorm": "2.786", "loss_scale": "0.0312", "train_wall": "94", "gb_free": "12.9", "wall": "17969"}
2021-10-11 00:39:26 | INFO | train_inner | {"epoch": 1, "update": 0.114, "loss": "2.787", "code_loss": "2.631", "value_loss_mse": "0.032", "code_ppl": "6.19", "wps": "18988.2", "ups": "0.08", "wpb": "238611", "bsz": "1024", "num_updates": "1400", "lr": "7e-05", "gnorm": "2.759", "loss_scale": "0.0312", "train_wall": "25", "gb_free": "12.9", "wall": "18095"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.011871337890625, 0.003429412841796875, 0.0021820068359375, 0.0015125274658203125, 0.0021820068359375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00766754150390625, 0.0033111572265625, 0.0012111663818359375, 0.0020427703857421875, 0.0015306472778320312]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.01090240478515625, 0.006313323974609375, 0.006984710693359375, 0.1358642578125, 0.0070953369140625]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0141754150390625, 0.005218505859375, 0.007965087890625, 0.16162109375, 0.00653839111328125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0143890380859375, 0.007724761962890625, 0.0150146484375, 0.293212890625, 0.01473236083984375]
byte6 tgt value: [0.0, 0.0, 0.05859375, 0.0078125, 0.05859375]
byte6 pred value: [0.01111602783203125, 0.0090179443359375, 0.0225372314453125, 0.168701171875, 0.025665283203125]
byte7 tgt value: [0.0, 0.0, 0.98828125, 0.83984375, 0.98828125]
byte7 pred value: [0.016021728515625, 0.0305023193359375, 0.67236328125, 0.5244140625, 0.70263671875]
byte8 tgt value: [0.0, 0.28125, 0.41015625, 0.9375, 0.34375]
byte8 pred value: [0.1131591796875, 0.1368408203125, 0.498291015625, 0.49365234375, 0.51611328125]
tgt code: hexvar movdqu rbx movups ^16
pred code: + mov rdi mov ^8
2021-10-11 00:41:38 | INFO | train_inner | {"epoch": 1, "update": 0.115, "loss": "2.772", "code_loss": "2.658", "value_loss_mse": "0.032", "code_ppl": "6.31", "wps": "19724.9", "ups": "0.08", "wpb": "260283", "bsz": "1024", "num_updates": "1410", "lr": "7.05e-05", "gnorm": "3.043", "loss_scale": "0.0312", "train_wall": "17", "gb_free": "12.9", "wall": "18227"}
2021-10-11 00:43:43 | INFO | train_inner | {"epoch": 1, "update": 0.115, "loss": "2.779", "code_loss": "2.638", "value_loss_mse": "0.032", "code_ppl": "6.23", "wps": "19112.9", "ups": "0.08", "wpb": "238646", "bsz": "1024", "num_updates": "1420", "lr": "7.1e-05", "gnorm": "3.154", "loss_scale": "0.0312", "train_wall": "39", "gb_free": "12.9", "wall": "18352"}
2021-10-11 00:45:54 | INFO | train_inner | {"epoch": 1, "update": 0.116, "loss": "2.743", "code_loss": "2.645", "value_loss_mse": "0.032", "code_ppl": "6.26", "wps": "19304.9", "ups": "0.08", "wpb": "253818", "bsz": "1024", "num_updates": "1430", "lr": "7.15e-05", "gnorm": "2.999", "loss_scale": "0.0312", "train_wall": "27", "gb_free": "12.9", "wall": "18483"}
2021-10-11 00:47:58 | INFO | train_inner | {"epoch": 1, "update": 0.117, "loss": "2.786", "code_loss": "2.645", "value_loss_mse": "0.032", "code_ppl": "6.26", "wps": "18847.2", "ups": "0.08", "wpb": "232982", "bsz": "1024", "num_updates": "1440", "lr": "7.2e-05", "gnorm": "3.73", "loss_scale": "0.0312", "train_wall": "32", "gb_free": "12.9", "wall": "18607"}
2021-10-11 00:50:08 | INFO | train_inner | {"epoch": 1, "update": 0.118, "loss": "2.865", "code_loss": "2.664", "value_loss_mse": "0.033", "code_ppl": "6.34", "wps": "17910", "ups": "0.08", "wpb": "232106", "bsz": "1024", "num_updates": "1450", "lr": "7.25e-05", "gnorm": "3.539", "loss_scale": "0.0312", "train_wall": "64", "gb_free": "12.9", "wall": "18736"}
2021-10-11 00:52:08 | INFO | train_inner | {"epoch": 1, "update": 0.119, "loss": "2.783", "code_loss": "2.636", "value_loss_mse": "0.032", "code_ppl": "6.21", "wps": "19079.9", "ups": "0.08", "wpb": "229222", "bsz": "1024", "num_updates": "1460", "lr": "7.3e-05", "gnorm": "3.928", "loss_scale": "0.0312", "train_wall": "35", "gb_free": "12.9", "wall": "18856"}
2021-10-11 00:54:08 | INFO | train_inner | {"epoch": 1, "update": 0.119, "loss": "2.763", "code_loss": "2.639", "value_loss_mse": "0.032", "code_ppl": "6.23", "wps": "18978.6", "ups": "0.08", "wpb": "228586", "bsz": "1024", "num_updates": "1470", "lr": "7.35e-05", "gnorm": "3.433", "loss_scale": "0.0312", "train_wall": "18", "gb_free": "12.9", "wall": "18977"}
2021-10-11 00:56:20 | INFO | train_inner | {"epoch": 1, "update": 0.12, "loss": "2.708", "code_loss": "2.606", "value_loss_mse": "0.031", "code_ppl": "6.09", "wps": "18815.4", "ups": "0.08", "wpb": "247398", "bsz": "1024", "num_updates": "1480", "lr": "7.4e-05", "gnorm": "2.69", "loss_scale": "0.0312", "train_wall": "66", "gb_free": "12.9", "wall": "19108"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0063629150390625, 0.0013723373413085938, 0.043853759765625, 0.01450347900390625, 0.0125732421875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00595855712890625, 0.0015363693237304688, 0.0472412109375, 0.0153045654296875, 0.0137939453125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0082550048828125, 0.005039215087890625, 0.06854248046875, 0.194580078125, 0.01302337646484375]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.011505126953125, 0.006877899169921875, 0.10723876953125, 0.328857421875, 0.01861572265625]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.01495361328125, 0.00731658935546875, 0.07476806640625, 0.20849609375, 0.0205230712890625]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.018646240234375, 0.0194549560546875, 0.09515380859375, 0.371826171875, 0.02691650390625]
byte7 tgt value: [0.0, 0.27734375, 0.0, 0.0, 0.0]
byte7 pred value: [0.027801513671875, 0.1492919921875, 0.07208251953125, 0.357421875, 0.0184783935546875]
byte8 tgt value: [0.00390625, 0.046875, 0.0, 0.0, 0.00390625]
byte8 pred value: [0.0631103515625, 0.379150390625, 0.1773681640625, 0.4765625, 0.0966796875]
tgt code: rdi mov rbp rax rax
pred code: hexvar mov hexvar rax rax
2021-10-11 00:58:37 | INFO | train_inner | {"epoch": 1, "update": 0.121, "loss": "2.761", "code_loss": "2.636", "value_loss_mse": "0.032", "code_ppl": "6.22", "wps": "18428", "ups": "0.07", "wpb": "252851", "bsz": "1024", "num_updates": "1490", "lr": "7.45e-05", "gnorm": "3.186", "loss_scale": "0.0312", "train_wall": "89", "gb_free": "12.9", "wall": "19246"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.013427734375, 0.00787353515625, 0.0032100677490234375, 0.00279998779296875, 0.0023784637451171875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.014007568359375, 0.005489349365234375, 0.00453948974609375, 0.00266265869140625, 0.00254058837890625]
byte3 tgt value: [0.0, 0.0, 0.0703125, 0.0, 0.0]
byte3 pred value: [0.0297088623046875, 0.0162811279296875, 0.21484375, 0.003749847412109375, 0.004024505615234375]
byte4 tgt value: [0.0, 0.0, 0.921875, 0.0, 0.0]
byte4 pred value: [0.0386962890625, 0.0216522216796875, 0.477783203125, 0.00394439697265625, 0.004329681396484375]
byte5 tgt value: [0.0, 0.0, 0.98046875, 0.0, 0.0]
byte5 pred value: [0.06231689453125, 0.018585205078125, 0.68896484375, 0.005161285400390625, 0.00455474853515625]
byte6 tgt value: [0.0, 0.0, 0.40234375, 0.0, 0.0]
byte6 pred value: [0.04486083984375, 0.0197601318359375, 0.5498046875, 0.006984710693359375, 0.00572967529296875]
byte7 tgt value: [0.0, 0.0, 0.00390625, 0.0, 0.0]
byte7 pred value: [0.033660888671875, 0.01666259765625, 0.3818359375, 0.0274810791015625, 0.0309600830078125]
byte8 tgt value: [0.0859375, 0.1953125, 0.625, 0.0625, 0.09375]
byte8 pred value: [0.1470947265625, 0.12054443359375, 0.41796875, 0.139404296875, 0.131103515625]
tgt code: test rsi call mov rax
pred code: nop hexvar call mov rax
2021-10-11 01:00:52 | INFO | train_inner | {"epoch": 1, "update": 0.122, "loss": "2.725", "code_loss": "2.627", "value_loss_mse": "0.031", "code_ppl": "6.18", "wps": "17960.4", "ups": "0.07", "wpb": "242274", "bsz": "1024", "num_updates": "1500", "lr": "7.5e-05", "gnorm": "3.044", "loss_scale": "0.0312", "train_wall": "106", "gb_free": "12.9", "wall": "19380"}
[0.006412506103515625, 0.1689453125, 0.0141754150390625, 0.0045928955078125, 0.05572509765625]
byte3 tgt value: [0.3515625, 0.3515625, 0.0, 0.0, 0.0]
byte3 pred value: [0.330810546875, 0.280517578125, 0.015960693359375, 0.03594970703125, 0.11163330078125]
byte4 tgt value: [0.63671875, 0.63671875, 0.0, 0.0, 0.0]
byte4 pred value: [0.5986328125, 0.41259765625, 0.0161590576171875, 0.033966064453125, 0.1748046875]
byte5 tgt value: [0.83203125, 0.83203125, 0.0, 0.0, 0.0]
byte5 pred value: [0.74853515625, 0.5576171875, 0.0271759033203125, 0.028167724609375, 0.232666015625]
byte6 tgt value: [0.98046875, 0.984375, 0.0, 0.0, 0.0]
byte6 pred value: [0.6103515625, 0.43310546875, 0.023101806640625, 0.0751953125, 0.158447265625]
byte7 tgt value: [0.6953125, 0.328125, 0.0, 0.3984375, 0.0]
byte7 pred value: [0.419677734375, 0.385498046875, 0.0189361572265625, 0.46484375, 0.137939453125]
byte8 tgt value: [0.38671875, 0.375, 0.15625, 0.6484375, 0.2265625]
byte8 pred value: [0.6396484375, 0.36669921875, 0.1207275390625, 0.54931640625, 0.23876953125]
tgt code: + ^8 rbx hexvar
pred code: + ^8 rdi hexvar
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.004451751708984375, 0.0025615692138671875, 0.0037364959716796875, 0.00127410888671875, 0.0313720703125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.005279541015625, 0.0011920928955078125, 0.004024505615234375, 0.0019121170043945312, 0.039337158203125]
byte3 tgt value: [0.0, 0.0, 0.10546875, 0.0, 0.0]
byte3 pred value: [0.08209228515625, 0.01282501220703125, 0.312255859375, 0.0217437744140625, 0.03204345703125]
byte4 tgt value: [0.0, 0.0, 0.79296875, 0.0, 0.0]
byte4 pred value: [0.252685546875, 0.017852783203125, 0.7333984375, 0.042236328125, 0.028167724609375]
byte5 tgt value: [0.0, 0.0, 0.48828125, 0.0, 0.0]
byte5 pred value: [0.1727294921875, 0.0306243896484375, 0.60498046875, 0.0379638671875, 0.0509033203125]
byte6 tgt value: [0.0, 0.0, 0.3125, 0.0078125, 0.0]
byte6 pred value: [0.12054443359375, 0.044525146484375, 0.3115234375, 0.040679931640625, 0.047088623046875]
byte7 tgt value: [0.0, 0.0, 0.53515625, 0.69921875, 0.0]
byte7 pred value: [0.2325439453125, 0.034881591796875, 0.447998046875, 0.2978515625, 0.0640869140625]
byte8 tgt value: [0.03515625, 0.03515625, 0.28125, 0.21875, 0.03125]
byte8 pred value: [0.257568359375, 0.141845703125, 0.462158203125, 0.499267578125, 0.11932373046875]
tgt code: mov rax rsp
pred code: mov + rdx
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00669097900390625, 0.00260162353515625, 0.004180908203125, 0.002811431884765625, 0.00482940673828125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.008575439453125, 0.0022430419921875, 0.004150390625, 0.00269317626953125, 0.00455474853515625]
byte3 tgt value: [0.25, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.1484375, 0.004573822021484375, 0.042022705078125, 0.04193115234375, 0.006313323974609375]
byte4 tgt value: [0.140625, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.1868896484375, 0.0068511962890625, 0.06939697265625, 0.07122802734375, 0.006488800048828125]
byte5 tgt value: [0.12109375, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.251220703125, 0.00885009765625, 0.07861328125, 0.09185791015625, 0.006984710693359375]
byte6 tgt value: [0.6953125, 0.0, 0.01171875, 0.01171875, 0.01953125]
byte6 pred value: [0.2137451171875, 0.018768310546875, 0.0880126953125, 0.097900390625, 0.0161590576171875]
byte7 tgt value: [0.08203125, 0.0, 0.83203125, 0.83203125, 0.59765625]
byte7 pred value: [0.390625, 0.307373046875, 0.56396484375, 0.5673828125, 0.484619140625]
byte8 tgt value: [0.625, 0.09375, 0.0625, 0.0, 0.234375]
byte8 pred value: [0.42431640625, 0.339599609375, 0.434326171875, 0.436767578125, 0.47021484375]
tgt code: call rbx test rax ^8
pred code: mov hexvar mov hexvar ^8
byte1 tgt value: [0.87890625, 0.0, 0.87890625, 0.0, 0.0]
byte1 pred value: [0.40234375, 0.020843505859375, 0.438232421875, 0.00579833984375, 0.10321044921875]
byte2 tgt value: [0.0234375, 0.0, 0.0234375, 0.0, 0.0]
byte2 pred value: [0.39306640625, 0.0295867919921875, 0.40478515625, 0.006290435791015625, 0.1195068359375]
byte3 tgt value: [0.29296875, 0.0, 0.29296875, 0.0, 0.0]
byte3 pred value: [0.376708984375, 0.04132080078125, 0.413330078125, 0.01056671142578125, 0.10650634765625]
byte4 tgt value: [0.73046875, 0.0, 0.73046875, 0.0, 0.0]
byte4 pred value: [0.46435546875, 0.10797119140625, 0.52001953125, 0.01898193359375, 0.1689453125]
byte5 tgt value: [0.01953125, 0.0, 0.01953125, 0.0, 0.0]
byte5 pred value: [0.4365234375, 0.075439453125, 0.49853515625, 0.01678466796875, 0.1497802734375]
byte6 tgt value: [0.578125, 0.0, 0.578125, 0.0, 0.0]
byte6 pred value: [0.320068359375, 0.060760498046875, 0.374755859375, 0.011199951171875, 0.1143798828125]
byte7 tgt value: [0.57421875, 0.0, 0.57421875, 0.0, 0.0]
byte7 pred value: [0.4140625, 0.2486572265625, 0.484375, 0.0272674560546875, 0.141357421875]
byte8 tgt value: [0.75, 0.0703125, 0.75, 0.03515625, 0.0]
byte8 pred value: [0.343505859375, 0.294677734375, 0.373046875, 0.116943359375, 0.2015380859375]
tgt code: hexvar + lea rdi ^4
pred code: hexvar + mov rax ^8
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00234222412109375, 0.0079345703125, 0.0020198822021484375, 0.01009368896484375, 0.00206756591796875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.003795623779296875, 0.00661468505859375, 0.0020904541015625, 0.006641387939453125, 0.0014896392822265625]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.008544921875, 0.011688232421875, 0.005039215087890625, 0.0121002197265625, 0.00473785400390625]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0030879974365234375, 0.0079345703125, 0.003223419189453125, 0.01116180419921875, 0.0037364959716796875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.00494384765625, 0.0197906494140625, 0.005641937255859375, 0.0243377685546875, 0.005321502685546875]
byte6 tgt value: [0.00390625, 0.0, 0.00390625, 0.0, 0.0]
byte6 pred value: [0.0101318359375, 0.01953125, 0.00916290283203125, 0.02655029296875, 0.0059356689453125]
byte7 tgt value: [0.3125, 0.0, 0.4609375, 0.0, 0.0]
byte7 pred value: [0.35595703125, 0.023284912109375, 0.1993408203125, 0.029205322265625, 0.0192413330078125]
byte8 tgt value: [0.046875, 0.0, 0.89453125, 0.0, 0.34375]
byte8 pred value: [0.458251953125, 0.076416015625, 0.39013671875, 0.09368896484375, 0.2359619140625]
tgt code: hexvar mov rax - hexvar
pred code: hexvar mov rax - hexvar
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0035114288330078125, 0.0034427642822265625, 0.041778564453125, 0.0025615692138671875, 0.003040313720703125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.004314422607421875, 0.00511932373046875, 0.055511474609375, 0.00229644775390625, 0.004451751708984375]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.01332855224609375, 0.003147125244140625, 0.0300445556640625, 0.00319671630859375, 0.0034961700439453125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0304412841796875, 0.0034427642822265625, 0.0274810791015625, 0.00345611572265625, 0.0030517578125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.027008056640625, 0.00424957275390625, 0.051361083984375, 0.0038089752197265625, 0.0038242340087890625]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.0271759033203125, 0.00634002685546875, 0.048309326171875, 0.00555419921875, 0.00441741943359375]
byte7 tgt value: [0.3671875, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.2232666015625, 0.0309600830078125, 0.09466552734375, 0.0121002197265625, 0.026153564453125]
byte8 tgt value: [0.71484375, 0.0625, 0.00390625, 0.0625, 0.0625]
byte8 pred value: [0.438232421875, 0.2325439453125, 0.1533203125, 0.190673828125, 0.1981201171875]
tgt code: rax ^4 rax r10 xmm1
pred code: hexvar ^8 ^8 rax rdi
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00424957275390625, 0.0245208740234375, 0.018798828125, 0.0013885498046875, 0.00469970703125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: 2021-10-11 01:03:06 | INFO | train_inner | {"epoch": 1, "update": 0.123, "loss": "2.741", "code_loss": "2.618", "value_loss_mse": "0.032", "code_ppl": "6.14", "wps": "18675", "ups": "0.07", "wpb": "250659", "bsz": "1024", "num_updates": "1510", "lr": "7.55e-05", "gnorm": "2.556", "loss_scale": "0.0312", "train_wall": "104", "gb_free": "12.9", "wall": "19515"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.001628875732421875, 0.0024242401123046875, 0.001956939697265625, 0.0227203369140625, 0.01763916015625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0016355514526367188, 0.0029468536376953125, 0.0027904510498046875, 0.0220794677734375, 0.01137542724609375]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0021648406982421875, 0.003337860107421875, 0.0029697418212890625, 0.0212860107421875, 0.0517578125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0028667449951171875, 0.003749847412109375, 0.004230499267578125, 0.0169219970703125, 0.057586669921875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.004150390625, 0.006122589111328125, 0.005641937255859375, 0.037811279296875, 0.051666259765625]
byte6 tgt value: [0.0, 0.015625, 0.0, 0.0, 0.0]
byte6 pred value: [0.00511932373046875, 0.00787353515625, 0.005428314208984375, 0.03338623046875, 0.043365478515625]
byte7 tgt value: [0.0, 0.86328125, 0.0, 0.0, 0.0]
byte7 pred value: [0.06427001953125, 0.259521484375, 0.06243896484375, 0.03912353515625, 0.0843505859375]
byte8 tgt value: [0.1875, 0.7578125, 0.0625, 0.1328125, 0.02734375]
byte8 pred value: [0.1890869140625, 0.403564453125, 0.192138671875, 0.0975341796875, 0.182861328125]
tgt code: hexvar cmp ^8 mov rax
pred code: hexvar mov ^4 mov rax
2021-10-11 01:05:07 | INFO | train_inner | {"epoch": 1, "update": 0.123, "loss": "2.711", "code_loss": "2.641", "value_loss_mse": "0.031", "code_ppl": "6.24", "wps": "19070.8", "ups": "0.08", "wpb": "230350", "bsz": "1024", "num_updates": "1520", "lr": "7.6e-05", "gnorm": "2.601", "loss_scale": "0.0312", "train_wall": "31", "gb_free": "12.9", "wall": "19635"}
2021-10-11 01:07:10 | INFO | train_inner | {"epoch": 1, "update": 0.124, "loss": "2.786", "code_loss": "2.622", "value_loss_mse": "0.032", "code_ppl": "6.16", "wps": "18135.7", "ups": "0.08", "wpb": "224012", "bsz": "1024", "num_updates": "1530", "lr": "7.65e-05", "gnorm": "2.858", "loss_scale": "0.0312", "train_wall": "21", "gb_free": "12.9", "wall": "19759"}
2021-10-11 01:09:09 | INFO | train_inner | {"epoch": 1, "update": 0.125, "loss": "2.66", "code_loss": "2.587", "value_loss_mse": "0.03", "code_ppl": "6.01", "wps": "18797.2", "ups": "0.08", "wpb": "223811", "bsz": "1024", "num_updates": "1540", "lr": "7.7e-05", "gnorm": "3.429", "loss_scale": "0.0625", "train_wall": "15", "gb_free": "12.9", "wall": "19878"}
2021-10-11 01:11:22 | INFO | train_inner | {"epoch": 1, "update": 0.126, "loss": "2.709", "code_loss": "2.588", "value_loss_mse": "0.031", "code_ppl": "6.01", "wps": "17828.4", "ups": "0.08", "wpb": "237184", "bsz": "1024", "num_updates": "1550", "lr": "7.75e-05", "gnorm": "2.971", "loss_scale": "0.0625", "train_wall": "20", "gb_free": "12.9", "wall": "20011"}
2021-10-11 01:13:22 | INFO | train_inner | {"epoch": 1, "update": 0.127, "loss": "2.714", "code_loss": "2.602", "value_loss_mse": "0.031", "code_ppl": "6.07", "wps": "19022", "ups": "0.08", "wpb": "226768", "bsz": "1024", "num_updates": "1560", "lr": "7.8e-05", "gnorm": "3.51", "loss_scale": "0.0625", "train_wall": "19", "gb_free": "12.9", "wall": "20130"}
2021-10-11 01:15:25 | INFO | train_inner | {"epoch": 1, "update": 0.127, "loss": "2.67", "code_loss": "2.61", "value_loss_mse": "0.031", "code_ppl": "6.11", "wps": "19204.2", "ups": "0.08", "wpb": "237347", "bsz": "1024", "num_updates": "1570", "lr": "7.85e-05", "gnorm": "3.823", "loss_scale": "0.0625", "train_wall": "23", "gb_free": "12.9", "wall": "20254"}
2021-10-11 01:17:31 | INFO | train_inner | {"epoch": 1, "update": 0.128, "loss": "2.69", "code_loss": "2.606", "value_loss_mse": "0.031", "code_ppl": "6.09", "wps": "18267.4", "ups": "0.08", "wpb": "230080", "bsz": "1024", "num_updates": "1580", "lr": "7.9e-05", "gnorm": "3.185", "loss_scale": "0.0625", "train_wall": "78", "gb_free": "12.9", "wall": "20380"}
2021-10-11 01:19:33 | INFO | train_inner | {"epoch": 1, "update": 0.129, "loss": "2.594", "code_loss": "2.597", "value_loss_mse": "0.03", "code_ppl": "6.05", "wps": "19335.3", "ups": "0.08", "wpb": "235965", "bsz": "1024", "num_updates": "1590", "lr": "7.95e-05", "gnorm": "2.621", "loss_scale": "0.0625", "train_wall": "54", "gb_free": "12.9", "wall": "20502"}
2021-10-11 01:21:46 | INFO | train_inner | {"epoch": 1, "update": 0.13, "loss": "2.629", "code_loss": "2.611", "value_loss_mse": "0.03", "code_ppl": "6.11", "wps": "18660.3", "ups": "0.08", "wpb": "247402", "bsz": "1024", "num_updates": "1600", "lr": "8e-05", "gnorm": "2.307", "loss_scale": "0.0625", "train_wall": "19", "gb_free": "12.9", "wall": "20634"}
2021-10-11 01:23:50 | INFO | train_inner | {"epoch": 1, "update": 0.131, "loss": "2.664", "code_loss": "2.597", "value_loss_mse": "0.031", "code_ppl": "6.05", "wps": "19067.8", "ups": "0.08", "wpb": "237669", "bsz": "1024", "num_updates": "1610", "lr": "8.05e-05", "gnorm": "3.28", "loss_scale": "0.0625", "train_wall": "16", "gb_free": "15", "wall": "20759"}
2021-10-11 01:25:56 | INFO | train_inner | {"epoch": 1, "update": 0.131, "loss": "2.658", "code_loss": "2.588", "value_loss_mse": "0.03", "code_ppl": "6.01", "wps": "18886.2", "ups": "0.08", "wpb": "236781", "bsz": "1024", "num_updates": "1620", "lr": "8.1e-05", "gnorm": "3.347", "loss_scale": "0.0625", "train_wall": "37", "gb_free": "12.9", "wall": "20885"}
2021-10-11 01:28:03 | INFO | train_inner | {"epoch": 1, "update": 0.132, "loss": "2.632", "code_loss": "2.61", "value_loss_mse": "0.03", "code_ppl": "6.11", "wps": "18731.2", "ups": "0.08", "wpb": "237914", "bsz": "1024", "num_updates": "1630", "lr": "8.15e-05", "gnorm": "2.714", "loss_scale": "0.0625", "train_wall": "16", "gb_free": "12.9", "wall": "21012"}
2021-10-11 01:30:18 | INFO | train_inner | {"epoch": 1, "update": 0.133, "loss": "2.641", "code_loss": "2.611", "value_loss_mse": "0.03", "code_ppl": "6.11", "wps": "17837.1", "ups": "0.07", "wpb": "240342", "bsz": "1024", "num_updates": "1640", "lr": "8.2e-05", "gnorm": "3.062", "loss_scale": "0.0625", "train_wall": "17", "gb_free": "12.9", "wall": "21146"}
2021-10-11 01:32:23 | INFO | train_inner | {"epoch": 1, "update": 0.134, "loss": "2.586", "code_loss": "2.577", "value_loss_mse": "0.029", "code_ppl": "5.97", "wps": "18943.4", "ups": "0.08", "wpb": "237389", "bsz": "1024", "num_updates": "1650", "lr": "8.25e-05", "gnorm": "2.594", "loss_scale": "0.0625", "train_wall": "19", "gb_free": "12.9", "wall": "21272"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.006412506103515625, 0.01177978515625, 0.010009765625, 0.045196533203125, 0.00128936767578125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.006191253662109375, 0.01238250732421875, 0.01267242431640625, 0.055206298828125, 0.0016613006591796875]
byte3 tgt value: [0.0, 0.09765625, 0.0, 0.0, 0.0]
byte3 pred value: [0.0050201416015625, 0.131591796875, 0.00864410400390625, 0.11395263671875, 0.0048675537109375]
byte4 tgt value: [0.0, 0.109375, 0.0, 0.0, 0.0]
byte4 pred value: [0.006313323974609375, 0.1812744140625, 0.011871337890625, 0.11260986328125, 0.004772186279296875]
byte5 tgt value: [0.0, 0.1953125, 0.0, 0.0, 0.0]
byte5 pred value: [0.005405426025390625, 0.2381591796875, 0.0097808837890625, 0.134521484375, 0.006439208984375]
byte6 tgt value: [0.0, 0.29296875, 0.0, 0.0, 0.03515625]
byte6 pred value: [0.0070953369140625, 0.3583984375, 0.012725830078125, 0.1934814453125, 0.0208892822265625]
byte7 tgt value: [0.0, 0.41796875, 0.0, 0.0, 0.50390625]
byte7 pred value: [0.01094818115234375, 0.320068359375, 0.011688232421875, 0.1470947265625, 0.332763671875]
byte8 tgt value: [0.1953125, 0.8125, 0.15625, 0.234375, 0.01171875]
byte8 pred value: [0.1279296875, 0.464599609375, 0.11029052734375, 0.29052734375, 0.480712890625]
tgt code: hexvar rdi r13 mov edx
pred code: hexvar r12 rdi mov rbp
2021-10-11 01:34:29 | INFO | train_inner | {"epoch": 1, "update": 0.135, "loss": "2.586", "code_loss": "2.587", "value_loss_mse": "0.029", "code_ppl": "6.01", "wps": "18799", "ups": "0.08", "wpb": "236880", "bsz": "1024", "num_updates": "1660", "lr": "8.3e-05", "gnorm": "2.562", "loss_scale": "0.0625", "train_wall": "49", "gb_free": "12.9", "wall": "21398"}
2021-10-11 01:36:40 | INFO | train_inner | {"epoch": 1, "update": 0.135, "loss": "2.649", "code_loss": "2.608", "value_loss_mse": "0.03", "code_ppl": "6.1", "wps": "19565.2", "ups": "0.08", "wpb": "256189", "bsz": "1024", "num_updates": "1670", "lr": "8.35e-05", "gnorm": "2.661", "loss_scale": "0.0625", "train_wall": "38", "gb_free": "12.9", "wall": "21529"}
2021-10-11 01:38:45 | INFO | train_inner | {"epoch": 1, "update": 0.136, "loss": "2.642", "code_loss": "2.591", "value_loss_mse": "0.03", "code_ppl": "6.03", "wps": "18912.7", "ups": "0.08", "wpb": "236333", "bsz": "1024", "num_updates": "1680", "lr": "8.4e-05", "gnorm": "2.726", "loss_scale": "0.0625", "train_wall": "35", "gb_free": "12.9", "wall": "21653"}
2021-10-11 01:40:53 | INFO | train_inner | {"epoch": 1, "update": 0.137, "loss": "2.629", "code_loss": "2.58", "value_loss_mse": "0.03", "code_ppl": "5.98", "wps": "19064.8", "ups": "0.08", "wpb": "245037", "bsz": "1024", "num_updates": "1690", "lr": "8.45e-05", "gnorm": "2.684", "loss_scale": "0.0625", "train_wall": "17", "gb_free": "12.9", "wall": "21782"}
2021-10-11 01:43:00 | INFO | train_inner | {"epoch": 1, "update": 0.138, "loss": "2.555", "code_loss": "2.567", "value_loss_mse": "0.029", "code_ppl": "5.92", "wps": "18875.7", "ups": "0.08", "wpb": "238262", "bsz": "1024", "num_updates": "1700", "lr": "8.5e-05", "gnorm": "2.558", "loss_scale": "0.0625", "train_wall": "44", "gb_free": "12.9", "wall": "21908"}
2021-10-11 01:44:57 | INFO | train_inner | {"epoch": 1, "update": 0.139, "loss": "2.669", "code_loss": "2.583", "value_loss_mse": "0.031", "code_ppl": "5.99", "wps": "18589.8", "ups": "0.09", "wpb": "217869", "bsz": "1024", "num_updates": "1710", "lr": "8.55e-05", "gnorm": "2.845", "loss_scale": "0.0625", "train_wall": "28", "gb_free": "12.9", "wall": "22025"}
2021-10-11 01:47:01 | INFO | train_inner | {"epoch": 1, "update": 0.139, "loss": "2.608", "code_loss": "2.558", "value_loss_mse": "0.03", "code_ppl": "5.89", "wps": "19234.3", "ups": "0.08", "wpb": "238306", "bsz": "1024", "num_updates": "1720", "lr": "8.6e-05", "gnorm": "3.009", "loss_scale": "0.0625", "train_wall": "17", "gb_free": "12.9", "wall": "22149"}
[0.00482940673828125, 0.0214080810546875, 0.0197601318359375, 0.002452850341796875, 0.0038852691650390625]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.059539794921875, 0.024566650390625, 0.018646240234375, 0.053009033203125, 0.00760650634765625]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.1358642578125, 0.021453857421875, 0.0200653076171875, 0.100341796875, 0.012054443359375]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.15673828125, 0.038970947265625, 0.038818359375, 0.173583984375, 0.011871337890625]
byte6 tgt value: [0.0, 0.0, 0.0, 0.00390625, 0.0]
byte6 pred value: [0.11297607421875, 0.0369873046875, 0.03790283203125, 0.11981201171875, 0.01560211181640625]
byte7 tgt value: [0.0, 0.0, 0.0, 0.515625, 0.0]
byte7 pred value: [0.41015625, 0.0360107421875, 0.0411376953125, 0.57275390625, 0.020294189453125]
byte8 tgt value: [0.23046875, 0.0234375, 0.0625, 0.46484375, 0.0859375]
byte8 pred value: [0.409423828125, 0.0765380859375, 0.09368896484375, 0.49072265625, 0.10723876953125]
tgt code: rax + rbx hexvar rdi
pred code: rax + hexvar hexvar hexvar
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.028106689453125, 0.001941680908203125, 0.0300445556640625, 0.0252227783203125, 0.0050201416015625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.03790283203125, 0.00424957275390625, 0.0369873046875, 0.03515625, 0.00905609130859375]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0287628173828125, 0.03271484375, 0.025421142578125, 0.0282745361328125, 0.00948333740234375]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0299224853515625, 0.1378173828125, 0.0287628173828125, 0.03143310546875, 0.0161590576171875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.11737060546875, 0.1441650390625, 0.07794189453125, 0.0938720703125, 0.25634765625]
byte6 tgt value: [0.0, 0.00390625, 0.0, 0.0, 0.0]
byte6 pred value: [0.102294921875, 0.0843505859375, 0.06793212890625, 0.075439453125, 0.2286376953125]
byte7 tgt value: [0.0, 0.03125, 0.0, 0.0, 0.0]
byte7 pred value: [0.10992431640625, 0.26416015625, 0.07574462890625, 0.07879638671875, 0.286376953125]
byte8 tgt value: [0.53125, 0.10546875, 0.05859375, 0.03125, 0.09765625]
byte8 pred value: [0.151611328125, 0.50048828125, 0.1253662109375, 0.130615234375, 0.341552734375]
tgt code: + mov cmp mov jmp
pred code: + mov mov mov mov
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.001964569091796875, 0.0016870498657226562, 0.0018749237060546875, 0.0028228759765625, 0.0011653900146484375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0017070770263671875, 0.0015306472778320312, 0.00254058837890625, 0.0027790069580078125, 0.0010690689086914062]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0031719207763671875, 0.00760650634765625, 0.00266265869140625, 0.00359344482421875, 0.007549285888671875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.004486083984375, 0.010986328125, 0.0023136138916015625, 0.004314422607421875, 0.01129150390625]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.005062103271484375, 0.01358795166015625, 0.004230499267578125, 0.006389617919921875, 0.01348114013671875]
byte6 tgt value: [0.0, 0.0078125, 0.0, 0.0, 0.0]
byte6 pred value: [0.00919342041015625, 0.01473236083984375, 0.0099334716796875, 0.0118255615234375, 0.0163421630859375]
byte7 tgt value: [0.0, 0.77734375, 0.0, 0.0, 0.44140625]
byte7 pred value: [0.448486328125, 0.57080078125, 0.447021484375, 0.162109375, 0.587890625]
byte8 tgt value: [0.40625, 0.36328125, 0.4375, 0.15625, 0.1875]
byte8 pred value: [0.423583984375, 0.42333984375, 0.445556640625, 0.200439453125, 0.4609375]
tgt code: edi rdi call pop ret
pred code: edi eax mov pop mov
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.05572509765625, 0.001720428466796875, 0.00284576416015625, 0.002349853515625, 0.0031719207763671875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.061187744140625, 0.0015735626220703125, 0.003040313720703125, 0.0023136138916015625, 0.00392913818359375]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.125]
byte3 pred value: [0.146728515625, 0.0031604766845703125, 0.005001068115234375, 0.005161285400390625, 0.09271240234375]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.546875]
byte4 pred value: [0.2489013671875, 0.005535125732421875, 0.00595855712890625, 0.0063629150390625, 0.1536865234375]
byte5 tgt value: [0.0, 0.0, 0.0, 0.99609375, 0.4453125]
byte5 pred value: [0.2294921875, 0.00609588623046875, 0.1693115234375, 0.31640625, 0.1806640625]
byte6 tgt value: [0.0, 0.046875, 0.0, 0.99609375, 0.6875]
byte6 pred value: [0.1654052734375, 0.01406097412109375, 0.1259765625, 0.261962890625, 0.12451171875]
byte7 tgt value: [0.0, 0.83984375, 0.0, 0.99609375, 0.1484375]
byte7 pred value: [0.25634765625, 0.345703125, 0.129150390625, 0.306884765625, 0.5224609375]
byte8 tgt value: [0.0, 0.83203125, 0.0, 0.99609375, 0.59375]
byte8 pred value: [0.2239990234375, 0.3095703125, 0.1483154296875, 0.268310546875, 0.443603515625]
tgt code: lea rdi rax jne hexvar
pred code: mov eax hexvar mov hexvar
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.001094818115234375, 0.0037212371826171875, 0.0023326873779296875, 0.0011606216430664062, 0.00803375244140625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0012598037719726562, 0.003635406494140625, 0.0020904541015625, 0.0013246536254882812, 0.0125274658203125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.47265625]
byte3 pred value: [0.01422882080078125, 0.0048675537109375, 0.002414703369140625, 0.016845703125, 0.28125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.09375]
byte4 pred value: [0.01450347900390625, 0.004451751708984375, 0.0020580291748046875, 0.0141754150390625, 0.18701171875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.33984375]
byte5 pred value: [0.034088134765625, 0.00945281982421875, 0.004962921142578125, 0.041839599609375, 0.6162109375]
byte6 tgt value: [0.00390625, 0.0, 0.0078125, 0.00390625, 0.87890625]
byte6 pred value: [0.036163330078125, 0.01085662841796875, 0.00881195068359375, 0.034088134765625, 0.50244140625]
byte7 tgt value: [0.2109375, 0.0, 0.98828125, 0.2109375, 0.90234375]
byte7 pred value: [0.395263671875, 0.01287078857421875, 0.359375, 0.375, 0.703125]
byte8 tgt value: [0.875, 0.0390625, 0.1015625, 0.57421875, 0.08203125]
byte8 pred value: [0.4677734375, 0.0701904296875, 0.320556640625, 0.447509765625, 0.342041015625]
tgt code: edi call jmp ^2 ^8
pred code: edi mov mov ^4 ^8
byte1 tgt value: [0.0, 0.0, 0.0, 0.796875, 0.0]
byte1 pred value: [0.004810333251953125, 0.0015125274658203125, 0.008544921875, 0.018768310546875, 0.001129150390625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.796875, 0.0]
byte2 pred value: [0.0050201416015625, 0.0020351409912109375, 0.01078033447265625, 0.0164031982421875, 0.0012445449829101562]
byte3 tgt value: [0.0, 0.0, 0.0, 0.796875, 0.0]
byte3 pred value: [0.005706787109375, 0.0160980224609375, 0.00803375244140625, 0.0147857666015625, 0.0022335052490234375]
byte4 tgt value: [0.0, 0.0, 0.0, 0.796875, 0.0]
byte4 pred value: [0.005619049072265625, 0.0147857666015625, 0.00763702392578125, 0.0179901123046875, 0.002269744873046875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.796875, 0.0]
byte5 pred value: [0.00945281982421875, 0.025909423828125, 0.0141754150390625, 0.026611328125, 0.004024505615234375]
byte6 tgt value: [0.0, 0.0, 0.0, 0.796875, 0.0]
byte6 pred value: [0.00981903076171875, 0.0165863037109375, 0.01507568359375, 0.0242767333984375, 0.00464630126953125]
byte7 tgt value: [0.00390625, 0.44921875, 0.0, 0.796875, 0.0]
byte7 pred value: [0.0087127685546875, 0.2493896484375, 0.010650634765625, 0.029815673828125, 0.0592041015625]
byte8 tgt value: [0.34375, 0.83984375, 0.0625, 0.80078125, 0.125]
byte8 pred value: [0.08282470703125, 0.494140625, 0.05572509765625, 0.1199951171875, 0.2340087890625]
tgt code: rsp hexvar hexvar edi ^4
pred code: rsp hexvar hexvar rdx ^8
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0083770751953125, 0.0031108856201171875, 0.008514404296875, 0.0030269622802734375, 0.02484130859375]
byte2 tgt value: 2021-10-11 01:49:00 | INFO | train_inner | {"epoch": 1, "update": 0.14, "loss": "2.603", "code_loss": "2.587", "value_loss_mse": "0.03", "code_ppl": "6.01", "wps": "18484", "ups": "0.08", "wpb": "220893", "bsz": "1024", "num_updates": "1730", "lr": "8.65e-05", "gnorm": "2.996", "loss_scale": "0.0625", "train_wall": "20", "gb_free": "12.9", "wall": "22269"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.609375, 0.0]
byte1 pred value: [0.0021820068359375, 0.020721435546875, 0.0013151168823242188, 0.2086181640625, 0.0034027099609375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.3984375, 0.0]
byte2 pred value: [0.0018606185913085938, 0.019378662109375, 0.0010080337524414062, 0.2437744140625, 0.0036792755126953125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.09765625, 0.37890625]
byte3 pred value: [0.0024242401123046875, 0.048126220703125, 0.00183868408203125, 0.36083984375, 0.138671875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.4140625, 0.42578125]
byte4 pred value: [0.0024929046630859375, 0.0699462890625, 0.003063201904296875, 0.462158203125, 0.43994140625]
byte5 tgt value: [0.0, 0.0, 0.0, 0.4453125, 0.35546875]
byte5 pred value: [0.0028781890869140625, 0.1015625, 0.004215240478515625, 0.50537109375, 0.433349609375]
byte6 tgt value: [0.0, 0.0, 0.0, 0.48046875, 0.4609375]
byte6 pred value: [0.005619049072265625, 0.07318115234375, 0.011871337890625, 0.53125, 0.331298828125]
byte7 tgt value: [0.0, 0.0, 0.0, 0.94140625, 0.45703125]
byte7 pred value: [0.034088134765625, 0.05645751953125, 0.2381591796875, 0.53076171875, 0.311767578125]
byte8 tgt value: [0.21875, 0.17578125, 0.40625, 0.546875, 0.03515625]
byte8 pred value: [0.1937255859375, 0.1339111328125, 0.29248046875, 0.414794921875, 0.389892578125]
tgt code: hexvar ret + hexvar +
pred code: hexvar mov + hexvar +
2021-10-11 01:51:01 | INFO | train_inner | {"epoch": 1, "update": 0.141, "loss": "2.624", "code_loss": "2.587", "value_loss_mse": "0.03", "code_ppl": "6.01", "wps": "18876.7", "ups": "0.08", "wpb": "227818", "bsz": "1024", "num_updates": "1740", "lr": "8.7e-05", "gnorm": "2.778", "loss_scale": "0.0625", "train_wall": "18", "gb_free": "12.9", "wall": "22390"}
2021-10-11 01:53:13 | INFO | train_inner | {"epoch": 1, "update": 0.142, "loss": "2.561", "code_loss": "2.615", "value_loss_mse": "0.029", "code_ppl": "6.13", "wps": "19178.6", "ups": "0.08", "wpb": "254003", "bsz": "1024", "num_updates": "1750", "lr": "8.75e-05", "gnorm": "2.781", "loss_scale": "0.0625", "train_wall": "19", "gb_free": "12.9", "wall": "22522"}
2021-10-11 01:55:20 | INFO | train_inner | {"epoch": 1, "update": 0.143, "loss": "2.584", "code_loss": "2.577", "value_loss_mse": "0.029", "code_ppl": "5.97", "wps": "19364.1", "ups": "0.08", "wpb": "246240", "bsz": "1024", "num_updates": "1760", "lr": "8.8e-05", "gnorm": "2.6", "loss_scale": "0.0625", "train_wall": "17", "gb_free": "12.9", "wall": "22649"}
2021-10-11 01:57:25 | INFO | train_inner | {"epoch": 1, "update": 0.143, "loss": "2.623", "code_loss": "2.569", "value_loss_mse": "0.03", "code_ppl": "5.93", "wps": "18855.1", "ups": "0.08", "wpb": "235578", "bsz": "1024", "num_updates": "1770", "lr": "8.85e-05", "gnorm": "2.754", "loss_scale": "0.0625", "train_wall": "28", "gb_free": "12.9", "wall": "22774"}
2021-10-11 01:59:37 | INFO | train_inner | {"epoch": 1, "update": 0.144, "loss": "2.637", "code_loss": "2.58", "value_loss_mse": "0.03", "code_ppl": "5.98", "wps": "18171.6", "ups": "0.08", "wpb": "239892", "bsz": "1024", "num_updates": "1780", "lr": "8.9e-05", "gnorm": "2.754", "loss_scale": "0.0625", "train_wall": "17", "gb_free": "12.9", "wall": "22906"}
2021-10-11 02:01:46 | INFO | train_inner | {"epoch": 1, "update": 0.145, "loss": "2.575", "code_loss": "2.576", "value_loss_mse": "0.029", "code_ppl": "5.96", "wps": "19385.3", "ups": "0.08", "wpb": "250020", "bsz": "1024", "num_updates": "1790", "lr": "8.95e-05", "gnorm": "3.284", "loss_scale": "0.0625", "train_wall": "16", "gb_free": "12.9", "wall": "23035"}
2021-10-11 02:03:56 | INFO | train_inner | {"epoch": 1, "update": 0.146, "loss": "2.575", "code_loss": "2.56", "value_loss_mse": "0.029", "code_ppl": "5.9", "wps": "18559.6", "ups": "0.08", "wpb": "241275", "bsz": "1024", "num_updates": "1800", "lr": "9e-05", "gnorm": "2.29", "loss_scale": "0.0625", "train_wall": "17", "gb_free": "12.9", "wall": "23165"}
2021-10-11 02:05:59 | INFO | train_inner | {"epoch": 1, "update": 0.147, "loss": "2.623", "code_loss": "2.56", "value_loss_mse": "0.03", "code_ppl": "5.9", "wps": "18199", "ups": "0.08", "wpb": "222413", "bsz": "1024", "num_updates": "1810", "lr": "9.05e-05", "gnorm": "2.849", "loss_scale": "0.0625", "train_wall": "16", "gb_free": "12.9", "wall": "23287"}
2021-10-11 02:08:00 | INFO | train_inner | {"epoch": 1, "update": 0.148, "loss": "2.547", "code_loss": "2.549", "value_loss_mse": "0.029", "code_ppl": "5.85", "wps": "18546.2", "ups": "0.08", "wpb": "225939", "bsz": "1024", "num_updates": "1820", "lr": "9.1e-05", "gnorm": "2.969", "loss_scale": "0.0625", "train_wall": "16", "gb_free": "12.9", "wall": "23409"}
2021-10-11 02:10:06 | INFO | train_inner | {"epoch": 1, "update": 0.148, "loss": "2.577", "code_loss": "2.556", "value_loss_mse": "0.029", "code_ppl": "5.88", "wps": "18711.1", "ups": "0.08", "wpb": "234717", "bsz": "1024", "num_updates": "1830", "lr": "9.15e-05", "gnorm": "2.626", "loss_scale": "0.0625", "train_wall": "36", "gb_free": "12.9", "wall": "23535"}
2021-10-11 02:12:22 | INFO | train_inner | {"epoch": 1, "update": 0.149, "loss": "2.55", "code_loss": "2.568", "value_loss_mse": "0.029", "code_ppl": "5.93", "wps": "18646.8", "ups": "0.07", "wpb": "253519", "bsz": "1024", "num_updates": "1840", "lr": "9.2e-05", "gnorm": "2.678", "loss_scale": "0.0625", "train_wall": "68", "gb_free": "12.9", "wall": "23671"}
2021-10-11 02:14:30 | INFO | train_inner | {"epoch": 1, "update": 0.15, "loss": "2.532", "code_loss": "2.558", "value_loss_mse": "0.029", "code_ppl": "5.89", "wps": "18808.4", "ups": "0.08", "wpb": "240490", "bsz": "1024", "num_updates": "1850", "lr": "9.25e-05", "gnorm": "2.387", "loss_scale": "0.0625", "train_wall": "57", "gb_free": "12.9", "wall": "23798"}
2021-10-11 02:16:32 | INFO | train_inner | {"epoch": 1, "update": 0.151, "loss": "2.568", "code_loss": "2.558", "value_loss_mse": "0.029", "code_ppl": "5.89", "wps": "18198.2", "ups": "0.08", "wpb": "222038", "bsz": "1024", "num_updates": "1860", "lr": "9.3e-05", "gnorm": "2.697", "loss_scale": "0.0625", "train_wall": "30", "gb_free": "12.9", "wall": "23920"}
2021-10-11 02:18:36 | INFO | train_inner | {"epoch": 1, "update": 0.152, "loss": "2.543", "code_loss": "2.547", "value_loss_mse": "0.029", "code_ppl": "5.84", "wps": "18924.8", "ups": "0.08", "wpb": "234771", "bsz": "1024", "num_updates": "1870", "lr": "9.35e-05", "gnorm": "3.346", "loss_scale": "0.0625", "train_wall": "16", "gb_free": "12.9", "wall": "24044"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00345611572265625, 0.004055023193359375, 0.0030994415283203125, 0.00806427001953125, 0.0031719207763671875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.004772186279296875, 0.005641937255859375, 0.0025119781494140625, 0.00926971435546875, 0.0035800933837890625]
byte3 tgt value: [0.28515625, 0.49609375, 0.0, 0.46484375, 0.0]
byte3 pred value: [0.2384033203125, 0.051361083984375, 0.004718780517578125, 0.23876953125, 0.0082855224609375]
byte4 tgt value: [0.8203125, 0.99609375, 0.0, 0.19140625, 0.0]
byte4 pred value: [0.74755859375, 0.115966796875, 0.004150390625, 0.1868896484375, 0.007549285888671875]
byte5 tgt value: [0.13671875, 0.69140625, 0.0, 0.515625, 0.0]
byte5 pred value: [0.2705078125, 0.158447265625, 0.00609588623046875, 0.3125, 0.01090240478515625]
byte6 tgt value: [0.54296875, 0.19921875, 0.0, 0.59375, 0.0]
byte6 pred value: [0.5166015625, 0.144775390625, 0.006122589111328125, 0.548828125, 0.016021728515625]
byte7 tgt value: [0.05078125, 0.48046875, 0.0, 0.26171875, 0.0]
byte7 pred value: [0.188232421875, 0.11676025390625, 0.01056671142578125, 0.346435546875, 0.01507568359375]
byte8 tgt value: [0.85546875, 0.6953125, 0.1015625, 0.75, 0.15625]
byte8 pred value: [0.72900390625, 0.1983642578125, 0.126953125, 0.477783203125, 0.131103515625]
tgt code: hexvar rbp nop mov edi
pred code: hexvar eax mov mov edi
2021-10-11 02:20:39 | INFO | train_inner | {"epoch": 1, "update": 0.152, "loss": "2.528", "code_loss": "2.546", "value_loss_mse": "0.029", "code_ppl": "5.84", "wps": "19020.7", "ups": "0.08", "wpb": "234465", "bsz": "1024", "num_updates": "1880", "lr": "9.4e-05", "gnorm": "2.582", "loss_scale": "0.0625", "train_wall": "30", "gb_free": "12.9", "wall": "24168"}
2021-10-11 02:22:37 | INFO | train_inner | {"epoch": 1, "update": 0.153, "loss": "2.528", "code_loss": "2.561", "value_loss_mse": "0.029", "code_ppl": "5.9", "wps": "18596.2", "ups": "0.08", "wpb": "220237", "bsz": "1024", "num_updates": "1890", "lr": "9.45e-05", "gnorm": "3.088", "loss_scale": "0.0625", "train_wall": "15", "gb_free": "12.9", "wall": "24286"}
byte1 tgt value: [0.0, 0.0, 0.328125, 0.0, 0.0]
byte1 pred value: [0.02606201171875, 0.0018243789672851562, 0.0263519287109375, 0.0278472900390625, 0.0153656005859375]
byte2 tgt value: [0.0, 0.0, 0.98046875, 0.0, 0.0]
byte2 pred value: [0.022674560546875, 0.0017480850219726562, 0.0253753662109375, 0.024566650390625, 0.0302734375]
byte3 tgt value: [0.0, 0.0, 0.4765625, 0.0, 0.49609375]
byte3 pred value: [0.0224609375, 0.0025615692138671875, 0.02532958984375, 0.0283355712890625, 0.239013671875]
byte4 tgt value: [0.0, 0.0, 0.9296875, 0.0, 0.99609375]
byte4 pred value: [0.026763916015625, 0.0022525787353515625, 0.03216552734375, 0.027008056640625, 0.2152099609375]
byte5 tgt value: [0.0, 0.0, 0.33203125, 0.0, 0.671875]
byte5 pred value: [0.040618896484375, 0.0027790069580078125, 0.04638671875, 0.033843994140625, 0.576171875]
byte6 tgt value: [0.0, 0.0, 0.66796875, 0.0, 0.8828125]
byte6 pred value: [0.038116455078125, 0.0048675537109375, 0.044097900390625, 0.039642333984375, 0.85302734375]
byte7 tgt value: [0.0, 0.0, 0.2890625, 0.0, 0.30078125]
byte7 pred value: [0.03643798828125, 0.01262664794921875, 0.038330078125, 0.0333251953125, 0.607421875]
byte8 tgt value: [0.08984375, 0.15625, 0.84375, 0.08984375, 0.125]
byte8 pred value: [0.10211181640625, 0.1624755859375, 0.1063232421875, 0.10089111328125, 0.5625]
tgt code: rbp - hexvar ^8 rax
pred code: rbp rbp hexvar ^8 rax
2021-10-11 02:24:45 | INFO | train_inner | {"epoch": 1, "update": 0.154, "loss": "2.505", "code_loss": "2.545", "value_loss_mse": "0.028", "code_ppl": "5.84", "wps": "18808.2", "ups": "0.08", "wpb": "239885", "bsz": "1024", "num_updates": "1900", "lr": "9.5e-05", "gnorm": "2.676", "loss_scale": "0.0625", "train_wall": "74", "gb_free": "12.9", "wall": "24414"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.234375, 0.0]
byte1 pred value: [0.0006513595581054688, 0.0018243789672851562, 0.0217437744140625, 0.054412841796875, 0.004886627197265625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.265625, 0.0]
byte2 pred value: [0.0009927749633789062, 0.0007791519165039062, 0.0211181640625, 0.059326171875, 0.007785797119140625]
byte3 tgt value: [0.359375, 0.0, 0.0, 0.30078125, 0.0]
byte3 pred value: [0.03338623046875, 0.003765106201171875, 0.015899658203125, 0.0526123046875, 0.097412109375]
byte4 tgt value: [0.8984375, 0.0, 0.0, 0.7578125, 0.0]
byte4 pred value: [0.1087646484375, 0.007122039794921875, 0.01422882080078125, 0.0526123046875, 0.277099609375]
byte5 tgt value: [0.66015625, 0.0, 0.0, 0.95703125, 0.0]
byte5 pred value: [0.0816650390625, 0.0068511962890625, 0.0153656005859375, 0.05792236328125, 0.335205078125]
byte6 tgt value: [0.421875, 0.0, 0.0, 0.734375, 0.00390625]
byte6 pred value: [0.050811767578125, 0.0180206298828125, 0.01525115966796875, 0.06109619140625, 0.361572265625]
byte7 tgt value: [0.03125, 0.23828125, 0.0, 0.03515625, 0.43359375]
byte7 pred value: [0.20068359375, 0.44091796875, 0.01433563232421875, 0.060760498046875, 0.4208984375]
byte8 tgt value: [0.03125, 0.1171875, 0.1328125, 0.84375, 0.25]
byte8 pred value: [0.474853515625, 0.41162109375, 0.1263427734375, 0.133056640625, 0.50341796875]
tgt code: rip cmp hexvar rip +
pred code: rip mov hexvar rip +
2021-10-11 02:26:52 | INFO | train_inner | {"epoch": 1, "update": 0.155, "loss": "2.519", "code_loss": "2.528", "value_loss_mse": "0.029", "code_ppl": "5.77", "wps": "18743.3", "ups": "0.08", "wpb": "237459", "bsz": "1024", "num_updates": "1910", "lr": "9.55e-05", "gnorm": "2.524", "loss_scale": "0.0625", "train_wall": "19", "gb_free": "12.9", "wall": "24540"}
2021-10-11 02:28:56 | INFO | train_inner | {"epoch": 1, "update": 0.156, "loss": "2.495", "code_loss": "2.534", "value_loss_mse": "0.028", "code_ppl": "5.79", "wps": "19342.2", "ups": "0.08", "wpb": "241085", "bsz": "1024", "num_updates": "1920", "lr": "9.6e-05", "gnorm": "2.634", "loss_scale": "0.0625", "train_wall": "17", "gb_free": "12.9", "wall": "24665"}
2021-10-11 02:31:04 | INFO | train_inner | {"epoch": 1, "update": 0.156, "loss": "2.586", "code_loss": "2.544", "value_loss_mse": "0.029", "code_ppl": "5.83", "wps": "18844.8", "ups": "0.08", "wpb": "240902", "bsz": "1024", "num_updates": "1930", "lr": "9.65e-05", "gnorm": "2.882", "loss_scale": "0.0625", "train_wall": "16", "gb_free": "12.9", "wall": "24793"}
2021-10-11 02:33:13 | INFO | train_inner | {"epoch": 1, "update": 0.157, "loss": "2.517", "code_loss": "2.518", "value_loss_mse": "0.029", "code_ppl": "5.73", "wps": "18403", "ups": "0.08", "wpb": "237424", "bsz": "1024", "num_updates": "1940", "lr": "9.7e-05", "gnorm": "2.451", "loss_scale": "0.0625", "train_wall": "51", "gb_free": "12.9", "wall": "24922"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.2230224609375, 0.002452850341796875, 0.004608154296875, 0.0022792816162109375, 0.006290435791015625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.35302734375, 0.00263214111328125, 0.003780364990234375, 0.002002716064453125, 0.00701141357421875]
byte3 tgt value: [0.3125, 0.3125, 0.49609375, 0.0, 0.49609375]
byte3 pred value: [0.398193359375, 0.100341796875, 0.5146484375, 0.0055999755859375, 0.5205078125]
byte4 tgt value: [0.39453125, 0.39453125, 0.99609375, 0.0, 0.99609375]
byte4 pred value: [0.79638671875, 0.32177734375, 0.98583984375, 0.007232666015625, 0.9892578125]
byte5 tgt value: [0.6328125, 0.6328125, 0.64453125, 0.0, 0.64453125]
byte5 pred value: [0.6181640625, 0.2469482421875, 0.791015625, 0.00809478759765625, 0.81640625]
byte6 tgt value: [0.73046875, 0.73046875, 0.64453125, 0.0, 0.64453125]
byte6 pred value: [0.8193359375, 0.481689453125, 0.4365234375, 0.00600433349609375, 0.45556640625]
byte7 tgt value: [0.046875, 0.046875, 0.17578125, 0.0, 0.17578125]
byte7 pred value: [0.74365234375, 0.36083984375, 0.465576171875, 0.0089874267578125, 0.548828125]
byte8 tgt value: [0.875, 0.96875, 0.0625, 0.06640625, 0.0625]
byte8 pred value: [0.4560546875, 0.338623046875, 0.1163330078125, 0.107421875, 0.095703125]
tgt code: ebx hexvar jne hexvar hexvar
pred code: rbp hexvar mov rbp hexvar
2021-10-11 02:35:25 | INFO | train_inner | {"epoch": 1, "update": 0.158, "loss": "2.498", "code_loss": "2.521", "value_loss_mse": "0.028", "code_ppl": "5.74", "wps": "18106.4", "ups": "0.08", "wpb": "237868", "bsz": "1024", "num_updates": "1950", "lr": "9.75e-05", "gnorm": "2.65", "loss_scale": "0.0625", "train_wall": "97", "gb_free": "12.9", "wall": "25053"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.004070281982421875, 0.0045928955078125, 0.0031108856201171875, 0.00424957275390625, 0.006931304931640625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00269317626953125, 0.004608154296875, 0.0032482147216796875, 0.0021648406982421875, 0.0127716064453125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.359375]
byte3 pred value: [0.004848480224609375, 0.07489013671875, 0.02484130859375, 0.0078125, 0.298095703125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.20703125]
byte4 pred value: [0.00600433349609375, 0.1297607421875, 0.0305023193359375, 0.0079345703125, 0.320556640625]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.69140625]
byte5 pred value: [0.00586700439453125, 0.170654296875, 0.021575927734375, 0.0069580078125, 0.6357421875]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.49609375]
byte6 pred value: [0.00453948974609375, 0.13671875, 0.01861572265625, 0.00582122802734375, 0.5185546875]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.6953125]
byte7 pred value: [0.01061248779296875, 0.167236328125, 0.025909423828125, 0.007904052734375, 0.3876953125]
byte8 tgt value: [0.06640625, 0.01171875, 0.0, 0.08984375, 0.3828125]
byte8 pred value: [0.1300048828125, 0.22265625, 0.1177978515625, 0.1356201171875, 0.347412109375]
tgt code: hexvar call r13 rsi pop
pred code: hexvar mov hexvar rbp pop
2021-10-11 02:37:40 | INFO | train_inner | {"epoch": 1, "update": 0.159, "loss": "2.454", "code_loss": "2.525", "value_loss_mse": "0.028", "code_ppl": "5.76", "wps": "18190", "ups": "0.07", "wpb": "246714", "bsz": "1024", "num_updates": "1960", "lr": "9.8e-05", "gnorm": "2.806", "loss_scale": "0.0625", "train_wall": "95", "gb_free": "12.9", "wall": "25189"}
2021-10-11 02:39:42 | INFO | train_inner | {"epoch": 1, "update": 0.16, "loss": "2.516", "code_loss": "2.535", "value_loss_mse": "0.029", "code_ppl": "5.79", "wps": "19509.6", "ups": "0.08", "wpb": "236848", "bsz": "1024", "num_updates": "1970", "lr": "9.85e-05", "gnorm": "2.675", "loss_scale": "0.0625", "train_wall": "72", "gb_free": "12.9", "wall": "25310"}
2021-10-11 02:41:57 | INFO | train_inner | {"epoch": 1, "update": 0.16, "loss": "2.508", "code_loss": "2.515", "value_loss_mse": "0.029", "code_ppl": "5.71", "wps": "18158.6", "ups": "0.07", "wpb": "246509", "bsz": "1024", "num_updates": "1980", "lr": "9.9e-05", "gnorm": "2.432", "loss_scale": "0.0625", "train_wall": "19", "gb_free": "12.9", "wall": "25446"}
2021-10-11 02:44:01 | INFO | train_inner | {"epoch": 1, "update": 0.161, "loss": "2.563", "code_loss": "2.518", "value_loss_mse": "0.029", "code_ppl": "5.73", "wps": "18725.8", "ups": "0.08", "wpb": "232458", "bsz": "1024", "num_updates": "1990", "lr": "9.95e-05", "gnorm": "2.283", "loss_scale": "0.0625", "train_wall": "16", "gb_free": "12.9", "wall": "25570"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.006587982177734375, 0.0014896392822265625, 0.0010080337524414062, 0.0016679763793945312, 0.0037078857421875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.008880615234375, 0.0013828277587890625, 0.0010318756103515625, 0.0015974044799804688, 0.0016937255859375]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.00803375244140625, 0.0174407958984375, 0.014007568359375, 0.0150146484375, 0.0194244384765625]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.006488800048828125, 0.0276947021484375, 0.025665283203125, 0.0254669189453125, 0.036285400390625]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.01450347900390625, 0.0272674560546875, 0.0235595703125, 0.0283355712890625, 0.0401611328125]
byte6 tgt value: [0.0, 0.04296875, 0.04296875, 0.04296875, 0.04296875]
byte6 pred value: [0.0154266357421875, 0.029205322265625, 0.0224609375, 0.0282135009765625, 0.034698486328125]
byte7 tgt value: [0.0, 0.5859375, 0.58203125, 0.58203125, 0.58203125]
byte7 pred value: [0.0201416015625, 0.5517578125, 0.51416015625, 0.499267578125, 0.63916015625]
byte8 tgt value: [0.00390625, 0.234375, 0.8984375, 0.95703125, 0.95703125]
byte8 pred value: [0.0982666015625, 0.544921875, 0.53271484375, 0.52392578125, 0.6171875]
tgt code: rax ^1 edi movsxd r13
pred code: eax ^1 hexvar mov rax
2021-10-11 02:46:15 | INFO | train_inner | {"epoch": 1, "update": 0.162, "loss": "2.513", "code_loss": "2.533", "value_loss_mse": "0.029", "code_ppl": "5.79", "wps": "18281.6", "ups": "0.08", "wpb": "243430", "bsz": "1024", "num_updates": "2000", "lr": "0.0001", "gnorm": "2.903", "loss_scale": "0.0625", "train_wall": "17", "gb_free": "12.9", "wall": "25703"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0011119842529296875, 0.0018033981323242188, 0.0013990402221679688, 0.015716552734375, 0.00455474853515625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0010404586791992188, 0.0013942718505859375, 0.0012445449829101562, 0.01111602783203125, 0.005161285400390625]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0032100677490234375, 0.0015611648559570312, 0.0034427642822265625, 0.00847625732421875, 0.01142120361328125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.006488800048828125, 0.00327301025390625, 0.00609588623046875, 0.007965087890625, 0.0115966796875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.00948333740234375, 0.0024623870849609375, 0.00881195068359375, 0.007549285888671875, 0.0885009765625]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.0137939453125, 0.0057525634765625, 0.01395416259765625, 0.01094818115234375, 0.0975341796875]
byte7 tgt value: [0.96875, 0.0, 0.96484375, 0.0, 0.0]
byte7 pred value: [0.75537109375, 0.059326171875, 0.7685546875, 0.016845703125, 0.08154296875]
byte8 tgt value: [0.20703125, 0.03125, 0.625, 0.015625, 0.23828125]
byte8 pred value: [0.482666015625, 0.12066650390625, 0.474365234375, 0.09088134765625, 0.1279296875]
tgt code: hexvar rax rdi r13 ^8
pred code: hexvar rip eax eax ^8
2021-10-11 02:48:24 | INFO | train_inner | {"epoch": 1, "update": 0.163, "loss": "2.522", "code_loss": "2.523", "value_loss_mse": "0.029", "code_ppl": "5.75", "wps": "17487.2", "ups": "0.08", "wpb": "226106", "bsz": "1024", "num_updates": "2010", "lr": "0.0001005", "gnorm": "2.52", "loss_scale": "0.0625", "train_wall": "16", "gb_free": "12.9", "wall": "25833"}
2021-10-11 02:50:32 | INFO | train_inner | {"epoch": 1, "update": 0.164, "loss": "2.487", "code_loss": "2.529", "value_loss_mse": "0.028", "code_ppl": "5.77", "wps": "19246.6", "ups": "0.08", "wpb": "246435", "bsz": "1024", "num_updates": "2020", "lr": "0.000101", "gnorm": "2.972", "loss_scale": "0.0625", "train_wall": "16", "gb_free": "12.9", "wall": "25961"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0309600830078125, 0.0025501251220703125, 0.00989532470703125, 0.00586700439453125, 0.0017747879028320312]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0192718505859375, 0.0020580291748046875, 0.007373809814453125, 0.006488800048828125, 0.001483917236328125]
byte3 tgt value: [0.0, 0.4296875, 0.0, 0.0, 0.0]
byte3 pred value: [0.0867919921875, 0.0391845703125, 0.01332855224609375, 0.063232421875, 0.0031108856201171875]
byte4 tgt value: [0.0, 0.3125, 0.0, 0.0, 0.0]
byte4 pred value: [0.077392578125, 0.042877197265625, 0.0144500732421875, 0.08154296875, 0.0037078857421875]
byte5 tgt value: [0.0, 0.5234375, 0.0, 0.0, 0.0]
byte5 pred value: [0.12042236328125, 0.08758544921875, 0.0269622802734375, 0.0775146484375, 0.00609588623046875]
byte6 tgt value: [0.0, 0.4765625, 0.0, 0.00390625, 0.01953125]
byte6 pred value: [0.0836181640625, 0.0738525390625, 0.0264129638671875, 0.05145263671875, 0.012969970703125]
byte7 tgt value: [0.0, 0.98046875, 0.0, 0.34765625, 0.59765625]
byte7 pred value: [0.1114501953125, 0.716796875, 0.0325927734375, 0.2890625, 0.37646484375]
byte8 tgt value: [0.0703125, 0.4375, 0.00390625, 0.38671875, 0.75]
byte8 pred value: [0.1298828125, 0.5126953125, 0.0850830078125, 0.361328125, 0.40185546875]
tgt code: mov hexvar * rax je
pred code: mov hexvar - rax mov
2021-10-11 02:52:41 | INFO | train_inner | {"epoch": 1, "update": 0.164, "loss": "2.496", "code_loss": "2.528", "value_loss_mse": "0.028", "code_ppl": "5.77", "wps": "18537.6", "ups": "0.08", "wpb": "238877", "bsz": "1024", "num_updates": "2030", "lr": "0.0001015", "gnorm": "2.918", "loss_scale": "0.0625", "train_wall": "16", "gb_free": "12.9", "wall": "26090"}
2021-10-11 02:54:47 | INFO | train_inner | {"epoch": 1, "update": 0.165, "loss": "2.492", "code_loss": "2.522", "value_loss_mse": "0.028", "code_ppl": "5.74", "wps": "18936.9", "ups": "0.08", "wpb": "238941", "bsz": "1024", "num_updates": "2040", "lr": "0.000102", "gnorm": "2.676", "loss_scale": "0.0625", "train_wall": "16", "gb_free": "12.9", "wall": "26216"}
2021-10-11 02:57:02 | INFO | train_inner | {"epoch": 1, "update": 0.166, "loss": "2.444", "code_loss": "2.52", "value_loss_mse": "0.028", "code_ppl": "5.74", "wps": "19183.6", "ups": "0.07", "wpb": "258022", "bsz": "1024", "num_updates": "2050", "lr": "0.0001025", "gnorm": "2.093", "loss_scale": "0.125", "train_wall": "17", "gb_free": "12.9", "wall": "26350"}
2021-10-11 02:59:01 | INFO | train_inner | {"epoch": 1, "update": 0.167, "loss": "2.465", "code_loss": "2.498", "value_loss_mse": "0.028", "code_ppl": "5.65", "wps": "18041.4", "ups": "0.08", "wpb": "216077", "bsz": "1024", "num_updates": "2060", "lr": "0.000103", "gnorm": "2.519", "loss_scale": "0.125", "train_wall": "15", "gb_free": "12.9", "wall": "26470"}
2021-10-11 03:01:00 | INFO | train_inner | {"epoch": 1, "update": 0.168, "loss": "2.465", "code_loss": "2.512", "value_loss_mse": "0.028", "code_ppl": "5.7", "wps": "18691.7", "ups": "0.08", "wpb": "221164", "bsz": "1024", "num_updates": "2070", "lr": "0.0001035", "gnorm": "2.723", "loss_scale": "0.125", "train_wall": "15", "gb_free": "12.9", "wall": "26588"}
2021-10-11 03:03:02 | INFO | train_inner | {"epoch": 1, "update": 0.168, "loss": "2.453", "code_loss": "2.493", "value_loss_mse": "0.028", "code_ppl": "5.63", "wps": "18784", "ups": "0.08", "wpb": "230555", "bsz": "1024", "num_updates": "2080", "lr": "0.000104", "gnorm": "2.556", "loss_scale": "0.125", "train_wall": "30", "gb_free": "12.9", "wall": "26711"}
[0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00800323486328125, 0.0021495819091796875, 0.00760650634765625, 0.002216339111328125, 0.0228424072265625]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.00841522216796875, 0.00453948974609375, 0.007965087890625, 0.003376007080078125, 0.0200653076171875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0106964111328125, 0.00885009765625, 0.00881195068359375, 0.006191253662109375, 0.029083251953125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0083770751953125, 0.004215240478515625, 0.00518035888671875, 0.0029697418212890625, 0.042724609375]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.01049041748046875, 0.005687713623046875, 0.007205963134765625, 0.00547027587890625, 0.0489501953125]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.01332855224609375, 0.0057525634765625, 0.006439208984375, 0.007205963134765625, 0.05340576171875]
byte8 tgt value: [0.1015625, 0.5625, 0.0078125, 0.21875, 0.0390625]
byte8 pred value: [0.11260986328125, 0.14404296875, 0.11614990234375, 0.10760498046875, 0.14111328125]
tgt code: rbx ebx sub hexvar r13d
pred code: rdx r12 mov hexvar hexvar
byte1 tgt value: [0.99609375, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.9716796875, 0.008514404296875, 0.0026721954345703125, 0.020843505859375, 0.01374053955078125]
byte2 tgt value: [0.99609375, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.98779296875, 0.00815582275390625, 0.0011835098266601562, 0.0108184814453125, 0.026611328125]
byte3 tgt value: [0.99609375, 0.49609375, 0.0, 0.43359375, 0.0]
byte3 pred value: [0.943359375, 0.50927734375, 0.0078125, 0.372314453125, 0.043212890625]
byte4 tgt value: [0.99609375, 0.99609375, 0.0, 0.42578125, 0.0]
byte4 pred value: [0.9404296875, 0.986328125, 0.01495361328125, 0.71044921875, 0.04046630859375]
byte5 tgt value: [0.99609375, 0.65234375, 0.0, 0.71875, 0.515625]
byte5 pred value: [0.9306640625, 0.7548828125, 0.0097808837890625, 0.33447265625, 0.52490234375]
byte6 tgt value: [0.99609375, 0.91015625, 0.0, 0.25390625, 0.890625]
byte6 pred value: [0.93408203125, 0.463134765625, 0.0070648193359375, 0.591796875, 0.75341796875]
byte7 tgt value: [0.99609375, 0.55078125, 0.0, 0.88671875, 0.01171875]
byte7 pred value: [0.865234375, 0.446044921875, 0.01512908935546875, 0.7607421875, 0.485595703125]
byte8 tgt value: [0.9375, 0.09375, 0.10546875, 0.578125, 0.75]
byte8 pred value: [0.892578125, 0.12213134765625, 0.13525390625, 0.4560546875, 0.517578125]
tgt code: hexvar - + mov rdx
pred code: hexvar + + mov rdx
byte1 tgt value: [0.0, 0.0, 0.66015625, 0.0, 0.0]
byte1 pred value: [0.001956939697265625, 0.00803375244140625, 0.00518035888671875, 0.0020275115966796875, 0.0230255126953125]
byte2 tgt value: [0.0, 0.0, 0.84375, 0.0, 0.0]
byte2 pred value: [0.0015916824340820312, 0.00963592529296875, 0.0053863525390625, 0.0013990402221679688, 0.01666259765625]
byte3 tgt value: [0.0, 0.0, 0.99609375, 0.0, 0.0]
byte3 pred value: [0.0029125213623046875, 0.263671875, 0.02752685546875, 0.009674072265625, 0.016845703125]
byte4 tgt value: [0.0, 0.0, 0.2265625, 0.0, 0.0]
byte4 pred value: [0.00284576416015625, 0.5166015625, 0.037750244140625, 0.01267242431640625, 0.0164031982421875]
byte5 tgt value: [0.0, 0.0, 0.8125, 0.0, 0.0]
byte5 pred value: [0.0279083251953125, 0.185791015625, 0.0258026123046875, 0.00963592529296875, 0.0247039794921875]
byte6 tgt value: [0.0, 0.0, 0.453125, 0.00390625, 0.0]
byte6 pred value: [0.029205322265625, 0.53125, 0.042724609375, 0.021697998046875, 0.0197906494140625]
byte7 tgt value: [0.0, 0.0, 0.7734375, 0.484375, 0.0]
byte7 pred value: [0.04296875, 0.384521484375, 0.45947265625, 0.54443359375, 0.037200927734375]
byte8 tgt value: [0.0390625, 0.09375, 0.92578125, 0.25, 0.0546875]
byte8 pred value: [0.118408203125, 0.50048828125, 0.457275390625, 0.482177734375, 0.149658203125]
tgt code: hexvar hexvar rdx esi hexvar
pred code: hexvar hexvar + eax hexvar
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0024623870849609375, 0.0017004013061523438, 0.00878143310546875, 0.0032100677490234375, 0.021331787109375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.001995086669921875, 0.0018606185913085938, 0.0033893585205078125, 0.004886627197265625, 0.021697998046875]
byte3 tgt value: [0.0, 0.34375, 0.0, 0.49609375, 0.0]
byte3 pred value: [0.004451751708984375, 0.141357421875, 0.027435302734375, 0.190673828125, 0.0218658447265625]
byte4 tgt value: [0.0, 0.8046875, 0.0, 0.99609375, 0.0]
byte4 pred value: [0.0062408447265625, 0.498046875, 0.050811767578125, 0.6796875, 0.0165252685546875]
byte5 tgt value: [0.0, 0.01953125, 0.0, 0.72265625, 0.0]
byte5 pred value: [0.004627227783203125, 0.286865234375, 0.050506591796875, 0.363525390625, 0.017303466796875]
byte6 tgt value: [0.0, 0.08203125, 0.0, 0.10546875, 0.0]
byte6 pred value: [0.00595855712890625, 0.0701904296875, 0.0259552001953125, 0.08282470703125, 0.0196075439453125]
byte7 tgt value: [0.0, 0.00390625, 0.0, 0.55078125, 0.0]
byte7 pred value: [0.0137939453125, 0.239013671875, 0.03216552734375, 0.2103271484375, 0.017578125]
byte8 tgt value: [0.015625, 0.1015625, 0.0, 0.125, 0.13671875]
byte8 pred value: [0.053192138671875, 0.32763671875, 0.07464599609375, 0.320068359375, 0.138916015625]
tgt code: jne hexvar mov hexvar
pred code: mov hexvar mov hexvar
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00494384765625, 0.0055999755859375, 0.00147247314453125, 0.0021820068359375, 0.00669097900390625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.004398345947265625, 0.004848480224609375, 0.00127410888671875, 0.0020275115966796875, 0.0063629150390625]
byte3 tgt value: [0.49609375, 0.49609375, 0.0, 0.0, 0.49609375]
byte3 pred value: [0.5126953125, 0.48388671875, 0.0022258758544921875, 0.002471923828125, 0.489013671875]
byte4 tgt value: [0.99609375, 0.99609375, 0.0, 0.0, 0.99609375]
byte4 pred value: [0.9794921875, 0.990234375, 0.0029582977294921875, 0.0035114288330078125, 0.99169921875]
byte5 tgt value: [0.95703125, 0.95703125, 0.0, 0.0, 0.95703125]
byte5 pred value: [0.81591796875, 0.806640625, 0.0029354095458984375, 0.004116058349609375, 0.8017578125]
byte6 tgt value: [0.3984375, 0.3984375, 0.0, 0.0, 0.3984375]
byte6 pred value: [0.62451171875, 0.66357421875, 0.0035648345947265625, 0.0045928955078125, 0.67333984375]
byte7 tgt value: [0.890625, 0.890625, 0.03125, 0.03125, 0.890625]
byte7 pred value: [0.52783203125, 0.59375, 0.01177978515625, 0.0099334716796875, 0.59765625]
byte8 tgt value: [0.375, 0.375, 0.375, 0.4375, 0.375]
byte8 pred value: [0.25927734375, 0.23388671875, 0.314697265625, 0.3408203125, 0.2117919921875]
tgt code: hexvar ^8 rsp al je
pred code: hexvar ^8 rsp hexvar mov
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0013942718505859375, 0.006488800048828125, 0.0369873046875, 0.004199981689453125, 0.0027256011962890625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0011425018310546875, 0.006290435791015625, 0.040252685546875, 0.00646209716796875, 0.0026416778564453125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0030879974365234375, 0.00885009765625, 0.04400634765625, 0.007205963134765625, 0.003692626953125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.004180908203125, 0.0115966796875, 0.0469970703125, 0.0116424560546875, 0.005641937255859375]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.004848480224609375, 0.01934814453125, 0.049041748046875, 0.1231689453125, 0.06085205078125]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.00591278076171875, 0.015838623046875, 0.06854248046875, 0.1632080078125, 0.07147216796875]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.044525146484375, 0.0162200927734375, 0.05560302734375, 0.2113037109375, 0.2110595703125]
byte8 tgt value: [0.03125, 0.03125, 0.40625, 0.046875, 0.05859375]
byte8 pred value: [0.171630859375, 0.0567626953125, 0.1007080078125, 0.247314453125, 0.249267578125]
tgt code: mov rax ^8 hexvar ^4
pred code: mov rsi ^8 hexvar ^4
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0015430450439453125, 0.0015192031860351562, 0.007755279541015625, 0.0013723373413085938, 0.0033512115478515625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0015125274658203125, 0.00183868408203125, 0.00908660888671875, 0.0017337799072265625, 0.003124237060546875]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.00208282470703125, 0.001979827880859375, 0.006931304931640625, 0.0016870498657226562, 0.024139404296875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0020198822021484375, 0.002521514892578125, 0.0106964111328125, 0.0016107559204101562, 0.05108642578125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.003337860107421875, 0.00391387939453125, 0.0074310302734375, 0.00269317626953125, 0.040008544921875]
byte6 tgt value: [0.0234375, 0.01171875, 0.0078125, 0.0234375, 0.0]
byte6 pred value: [0.01029205322265625, 0.01078033447265625, 0.00669097900390625, 0.01146697998046875, 0.0312042236328125]
byte7 tgt value: [0.5703125, 0.046875, 0.0625, 0.5703125, 0.69140625]
byte7 pred value: [0.390380859375, 0.395751953125, 0.027801513671875, 0.348876953125, 0.5166015625]
byte8 tgt value: [0.66796875, 0.5, 0.75, 0.26953125, 0.8125]
byte8 pred value: [0.442138671875, 0.40966796875, 0.66015625, 0.41064453125, 0.48095703125]
tgt code: rip + hexvar rbp ^8
pred code: + + + rax ^8
2021-10-11 03:05:09 | INFO | train_inner | {"epoch": 1, "update": 0.169, "loss": "2.439", "code_loss": "2.496", "value_loss_mse": "0.028", "code_ppl": "5.64", "wps": "19089.2", "ups": "0.08", "wpb": "241222", "bsz": "1024", "num_updates": "2090", "lr": "0.0001045", "gnorm": "2.476", "loss_scale": "0.125", "train_wall": "18", "gb_free": "12.9", "wall": "26837"}
2021-10-11 03:07:23 | INFO | train_inner | {"epoch": 1, "update": 0.17, "loss": "2.467", "code_loss": "2.51", "value_loss_mse": "0.028", "code_ppl": "5.7", "wps": "19044", "ups": "0.07", "wpb": "255309", "bsz": "1024", "num_updates": "2100", "lr": "0.000105", "gnorm": "2.391", "loss_scale": "0.125", "train_wall": "39", "gb_free": "12.9", "wall": "26971"}
2021-10-11 03:09:36 | INFO | train_inner | {"epoch": 1, "update": 0.171, "loss": "2.404", "code_loss": "2.499", "value_loss_mse": "0.027", "code_ppl": "5.65", "wps": "18936.1", "ups": "0.07", "wpb": "252845", "bsz": "1024", "num_updates": "2110", "lr": "0.0001055", "gnorm": "2.381", "loss_scale": "0.125", "train_wall": "87", "gb_free": "12.9", "wall": "27105"}
2021-10-11 03:11:44 | INFO | train_inner | {"epoch": 1, "update": 0.172, "loss": "2.487", "code_loss": "2.501", "value_loss_mse": "0.028", "code_ppl": "5.66", "wps": "18309.4", "ups": "0.08", "wpb": "234234", "bsz": "1024", "num_updates": "2120", "lr": "0.000106", "gnorm": "3.124", "loss_scale": "0.125", "train_wall": "82", "gb_free": "14.8", "wall": "27233"}
2021-10-11 03:13:50 | INFO | train_inner | {"epoch": 1, "update": 0.172, "loss": "2.522", "code_loss": "2.528", "value_loss_mse": "0.029", "code_ppl": "5.77", "wps": "18439.4", "ups": "0.08", "wpb": "232630", "bsz": "1024", "num_updates": "2130", "lr": "0.0001065", "gnorm": "2.535", "loss_scale": "0.125", "train_wall": "87", "gb_free": "12.9", "wall": "27359"}
2021-10-11 03:16:00 | INFO | train_inner | {"epoch": 1, "update": 0.173, "loss": "2.442", "code_loss": "2.516", "value_loss_mse": "0.028", "code_ppl": "5.72", "wps": "19445.1", "ups": "0.08", "wpb": "251899", "bsz": "1024", "num_updates": "2140", "lr": "0.000107", "gnorm": "2.015", "loss_scale": "0.125", "train_wall": "24", "gb_free": "12.9", "wall": "27489"}
2021-10-11 03:18:00 | INFO | train_inner | {"epoch": 1, "update": 0.174, "loss": "2.456", "code_loss": "2.485", "value_loss_mse": "0.028", "code_ppl": "5.6", "wps": "18480", "ups": "0.08", "wpb": "221030", "bsz": "1024", "num_updates": "2150", "lr": "0.0001075", "gnorm": "2.758", "loss_scale": "0.125", "train_wall": "42", "gb_free": "12.9", "wall": "27608"}
2021-10-11 03:20:12 | INFO | train_inner | {"epoch": 1, "update": 0.175, "loss": "2.451", "code_loss": "2.495", "value_loss_mse": "0.028", "code_ppl": "5.64", "wps": "19024.6", "ups": "0.08", "wpb": "251120", "bsz": "1024", "num_updates": "2160", "lr": "0.000108", "gnorm": "2.192", "loss_scale": "0.125", "train_wall": "37", "gb_free": "12.9", "wall": "27740"}
2021-10-11 03:22:22 | INFO | train_inner | {"epoch": 1, "update": 0.176, "loss": "2.375", "code_loss": "2.503", "value_loss_mse": "0.027", "code_ppl": "5.67", "wps": "18968.9", "ups": "0.08", "wpb": "247591", "bsz": "1024", "num_updates": "2170", "lr": "0.0001085", "gnorm": "2.956", "loss_scale": "0.125", "train_wall": "17", "gb_free": "12.9", "wall": "27871"}
2021-10-11 03:24:41 | INFO | train_inner | {"epoch": 1, "update": 0.176, "loss": "2.427", "code_loss": "2.53", "value_loss_mse": "0.027", "code_ppl": "5.78", "wps": "18384.9", "ups": "0.07", "wpb": "254851", "bsz": "1024", "num_updates": "2180", "lr": "0.000109", "gnorm": "2.421", "loss_scale": "0.125", "train_wall": "18", "gb_free": "12.9", "wall": "28009"}
2021-10-11 03:26:47 | INFO | train_inner | {"epoch": 1, "update": 0.177, "loss": "2.425", "code_loss": "2.493", "value_loss_mse": "0.027", "code_ppl": "5.63", "wps": "19769.5", "ups": "0.08", "wpb": "250227", "bsz": "1024", "num_updates": "2190", "lr": "0.0001095", "gnorm": "2.245", "loss_scale": "0.125", "train_wall": "16", "gb_free": "12.9", "wall": "28136"}
2021-10-11 03:28:50 | INFO | train_inner | {"epoch": 1, "update": 0.178, "loss": "2.45", "code_loss": "2.501", "value_loss_mse": "0.028", "code_ppl": "5.66", "wps": "18200.4", "ups": "0.08", "wpb": "224218", "bsz": "1024", "num_updates": "2200", "lr": "0.00011", "gnorm": "2.491", "loss_scale": "0.125", "train_wall": "15", "gb_free": "12.9", "wall": "28259"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00023233890533447266, 0.0014667510986328125, 0.0006289482116699219, 0.01142120361328125, 0.0010118484497070312]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00033664703369140625, 0.0012645721435546875, 0.0007381439208984375, 0.0101318359375, 0.0011034011840820312]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0035114288330078125, 0.0036067962646484375, 0.0027370452880859375, 0.01009368896484375, 0.0020198822021484375]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0029468536376953125, 0.00234222412109375, 0.00206756591796875, 0.0062408447265625, 0.0013456344604492188]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0163421630859375, 0.00595855712890625, 0.007694244384765625, 0.00937652587890625, 0.00577545166015625]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.01302337646484375, 0.006439208984375, 0.0083160400390625, 0.008544921875, 0.00572967529296875]
byte7 tgt value: [0.0, 0.0, 0.0, 0.42578125, 0.0]
byte7 pred value: [0.03656005859375, 0.006587982177734375, 0.0228424072265625, 0.368408203125, 0.011688232421875]
byte8 tgt value: [0.0, 0.00390625, 0.0, 0.83984375, 0.18359375]
byte8 pred value: [0.382080078125, 0.0987548828125, 0.374267578125, 0.810546875, 0.1884765625]
tgt code: ^4 edx rdi dl dl
pred code: ^4 dl + dl eax
2021-10-11 03:30:59 | INFO | train_inner | {"epoch": 1, "update": 0.179, "loss": "2.425", "code_loss": "2.501", "value_loss_mse": "0.027", "code_ppl": "5.66", "wps": "18436.6", "ups": "0.08", "wpb": "237031", "bsz": "1024", "num_updates": "2210", "lr": "0.0001105", "gnorm": "2.674", "loss_scale": "0.125", "train_wall": "16", "gb_free": "12.9", "wall": "28388"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.004772186279296875, 0.0021648406982421875, 0.09075927734375, 0.07720947265625, 0.0024242401123046875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00586700439453125, 0.0022602081298828125, 0.09283447265625, 0.124755859375, 0.0023593902587890625]
byte3 tgt value: [0.49609375, 0.0, 0.49609375, 0.49609375, 0.0]
byte3 pred value: [0.51953125, 0.0034427642822265625, 0.498291015625, 0.48486328125, 0.006984710693359375]
byte4 tgt value: [0.99609375, 0.0, 0.99609375, 0.99609375, 0.0]
byte4 pred value: [0.9921875, 0.0032100677490234375, 0.81689453125, 0.771484375, 0.00605010986328125]
byte5 tgt value: [0.94140625, 0.0, 0.94140625, 0.94140625, 0.0]
byte5 pred value: [0.86962890625, 0.00254058837890625, 0.69873046875, 0.67236328125, 0.03167724609375]
byte6 tgt value: [0.37109375, 0.0, 0.37109375, 0.37109375, 0.0]
byte6 pred value: [0.68359375, 0.00473785400390625, 0.492431640625, 0.456787109375, 0.0252227783203125]
byte7 tgt value: [0.984375, 0.0, 0.984375, 0.984375, 0.0]
byte7 pred value: [0.60498046875, 0.0222015380859375, 0.424560546875, 0.361083984375, 0.0535888671875]
byte8 tgt value: [0.0, 0.0625, 0.3125, 0.3125, 0.0]
byte8 pred value: [0.481201171875, 0.166259765625, 0.41943359375, 0.41552734375, 0.17578125]
tgt code: rbx rsp ^4 rdi ^8
pred code: rax rsp ^8 rdi ^8
2021-10-11 03:33:10 | INFO | train_inner | {"epoch": 1, "update": 0.18, "loss": "2.445", "code_loss": "2.498", "value_loss_mse": "0.028", "code_ppl": "5.65", "wps": "17877.3", "ups": "0.08", "wpb": "234589", "bsz": "1024", "num_updates": "2220", "lr": "0.000111", "gnorm": "2.545", "loss_scale": "0.125", "train_wall": "17", "gb_free": "12.9", "wall": "28519"}
2021-10-11 03:35:17 | INFO | train_inner | {"epoch": 1, "update": 0.18, "loss": "2.429", "code_loss": "2.485", "value_loss_mse": "0.027", "code_ppl": "5.6", "wps": "18053.8", "ups": "0.08", "wpb": "228080", "bsz": "1024", "num_updates": "2230", "lr": "0.0001115", "gnorm": "2.375", "loss_scale": "0.125", "train_wall": "16", "gb_free": "12.9", "wall": "28645"}
2021-10-11 03:37:22 | INFO | train_inner | {"epoch": 1, "update": 0.181, "loss": "2.44", "code_loss": "2.45", "value_loss_mse": "0.028", "code_ppl": "5.47", "wps": "18046.8", "ups": "0.08", "wpb": "225708", "bsz": "1024", "num_updates": "2240", "lr": "0.000112", "gnorm": "2.715", "loss_scale": "0.125", "train_wall": "16", "gb_free": "15.9", "wall": "28770"}
2021-10-11 03:39:26 | INFO | train_inner | {"epoch": 1, "update": 0.182, "loss": "2.42", "code_loss": "2.485", "value_loss_mse": "0.027", "code_ppl": "5.6", "wps": "18341.5", "ups": "0.08", "wpb": "229018", "bsz": "1024", "num_updates": "2250", "lr": "0.0001125", "gnorm": "2.792", "loss_scale": "0.125", "train_wall": "16", "gb_free": "12.9", "wall": "28895"}
2021-10-11 03:41:41 | INFO | train_inner | {"epoch": 1, "update": 0.183, "loss": "2.401", "code_loss": "2.497", "value_loss_mse": "0.027", "code_ppl": "5.64", "wps": "18187", "ups": "0.07", "wpb": "244630", "bsz": "1024", "num_updates": "2260", "lr": "0.000113", "gnorm": "2.211", "loss_scale": "0.125", "train_wall": "17", "gb_free": "12.9", "wall": "29030"}
2021-10-11 03:43:54 | INFO | train_inner | {"epoch": 1, "update": 0.184, "loss": "2.4", "code_loss": "2.504", "value_loss_mse": "0.027", "code_ppl": "5.67", "wps": "18831.2", "ups": "0.08", "wpb": "249600", "bsz": "1024", "num_updates": "2270", "lr": "0.0001135", "gnorm": "2.016", "loss_scale": "0.125", "train_wall": "17", "gb_free": "12.9", "wall": "29162"}
2021-10-11 03:45:59 | INFO | train_inner | {"epoch": 1, "update": 0.185, "loss": "2.404", "code_loss": "2.465", "value_loss_mse": "0.027", "code_ppl": "5.52", "wps": "18939.4", "ups": "0.08", "wpb": "236749", "bsz": "1024", "num_updates": "2280", "lr": "0.000114", "gnorm": "2.256", "loss_scale": "0.125", "train_wall": "17", "gb_free": "12.9", "wall": "29287"}
2021-10-11 03:48:05 | INFO | train_inner | {"epoch": 1, "update": 0.185, "loss": "2.381", "code_loss": "2.465", "value_loss_mse": "0.027", "code_ppl": "5.52", "wps": "18476.8", "ups": "0.08", "wpb": "233853", "bsz": "1024", "num_updates": "2290", "lr": "0.0001145", "gnorm": "2.317", "loss_scale": "0.125", "train_wall": "18", "gb_free": "12.9", "wall": "29414"}
2021-10-11 03:50:13 | INFO | train_inner | {"epoch": 1, "update": 0.186, "loss": "2.412", "code_loss": "2.484", "value_loss_mse": "0.027", "code_ppl": "5.59", "wps": "19064.9", "ups": "0.08", "wpb": "243674", "bsz": "1024", "num_updates": "2300", "lr": "0.000115", "gnorm": "2.264", "loss_scale": "0.125", "train_wall": "18", "gb_free": "12.9", "wall": "29542"}
2021-10-11 03:52:27 | INFO | train_inner | {"epoch": 1, "update": 0.187, "loss": "2.43", "code_loss": "2.474", "value_loss_mse": "0.028", "code_ppl": "5.55", "wps": "18663.6", "ups": "0.07", "wpb": "250224", "bsz": "1024", "num_updates": "2310", "lr": "0.0001155", "gnorm": "2.117", "loss_scale": "0.125", "train_wall": "17", "gb_free": "12.9", "wall": "29676"}
2021-10-11 03:54:39 | INFO | train_inner | {"epoch": 1, "update": 0.188, "loss": "2.458", "code_loss": "2.466", "value_loss_mse": "0.028", "code_ppl": "5.52", "wps": "18224.1", "ups": "0.08", "wpb": "240998", "bsz": "1024", "num_updates": "2320", "lr": "0.000116", "gnorm": "2.926", "loss_scale": "0.125", "train_wall": "17", "gb_free": "12.9", "wall": "29808"}
2021-10-11 03:56:43 | INFO | train_inner | {"epoch": 1, "update": 0.189, "loss": "2.422", "code_loss": "2.455", "value_loss_mse": "0.027", "code_ppl": "5.48", "wps": "19517.1", "ups": "0.08", "wpb": "240629", "bsz": "1024", "num_updates": "2330", "lr": "0.0001165", "gnorm": "2.497", "loss_scale": "0.125", "train_wall": "16", "gb_free": "12.9", "wall": "29931"}
2021-10-11 03:58:53 | INFO | train_inner | {"epoch": 1, "update": 0.189, "loss": "2.359", "code_loss": "2.443", "value_loss_mse": "0.027", "code_ppl": "5.44", "wps": "19282", "ups": "0.08", "wpb": "251091", "bsz": "1024", "num_updates": "2340", "lr": "0.000117", "gnorm": "2.538", "loss_scale": "0.125", "train_wall": "37", "gb_free": "12.9", "wall": "30061"}
2021-10-11 04:01:07 | INFO | train_inner | {"epoch": 1, "update": 0.19, "loss": "2.361", "code_loss": "2.467", "value_loss_mse": "0.027", "code_ppl": "5.53", "wps": "18516", "ups": "0.07", "wpb": "248605", "bsz": "1024", "num_updates": "2350", "lr": "0.0001175", "gnorm": "2.124", "loss_scale": "0.125", "train_wall": "17", "gb_free": "12.9", "wall": "30196"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0013561248779296875, 0.06890869140625, 0.28369140625, 0.01078033447265625, 0.68896484375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0014047622680664062, 0.0638427734375, 0.3193359375, 0.00844573974609375, 0.64013671875]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.040008544921875, 0.047607421875, 0.25927734375, 0.01374053955078125, 0.642578125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0738525390625, 0.041473388671875, 0.2880859375, 0.02069091796875, 0.7138671875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0880126953125, 0.0987548828125, 0.340576171875, 0.01812744140625, 0.7099609375]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.09771728515625, 0.109130859375, 0.402587890625, 0.01812744140625, 0.705078125]
byte7 tgt value: [0.54296875, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.40625, 0.093505859375, 0.3701171875, 0.01666259765625, 0.7119140625]
byte8 tgt value: [0.46875, 0.2265625, 0.359375, 0.09765625, 0.03125]
byte8 pred value: [0.38330078125, 0.1761474609375, 0.430908203125, 0.14111328125, 0.6083984375]
tgt code: ^8 rdi rbx ^1 je
pred code: ^8 rsi hexvar ^8 mov
2021-10-11 04:03:18 | INFO | train_inner | {"epoch": 1, "update": 0.191, "loss": "2.371", "code_loss": "2.47", "value_loss_mse": "0.027", "code_ppl": "5.54", "wps": "18737.9", "ups": "0.08", "wpb": "246019", "bsz": "1024", "num_updates": "2360", "lr": "0.000118", "gnorm": "2.221", "loss_scale": "0.125", "train_wall": "16", "gb_free": "12.9", "wall": "30327"}
2021-10-11 04:05:27 | INFO | train_inner | {"epoch": 1, "update": 0.192, "loss": "2.378", "code_loss": "2.474", "value_loss_mse": "0.027", "code_ppl": "5.56", "wps": "18899.3", "ups": "0.08", "wpb": "242569", "bsz": "1024", "num_updates": "2370", "lr": "0.0001185", "gnorm": "2.333", "loss_scale": "0.125", "train_wall": "16", "gb_free": "12.9", "wall": "30455"}
2021-10-11 04:07:42 | INFO | train_inner | {"epoch": 1, "update": 0.193, "loss": "2.355", "code_loss": "2.467", "value_loss_mse": "0.026", "code_ppl": "5.53", "wps": "18582.5", "ups": "0.07", "wpb": "251651", "bsz": "1024", "num_updates": "2380", "lr": "0.000119", "gnorm": "2.263", "loss_scale": "0.125", "train_wall": "17", "gb_free": "12.9", "wall": "30591"}
2021-10-11 04:09:56 | INFO | train_inner | {"epoch": 1, "update": 0.193, "loss": "2.394", "code_loss": "2.462", "value_loss_mse": "0.027", "code_ppl": "5.51", "wps": "17164", "ups": "0.07", "wpb": "230302", "bsz": "1024", "num_updates": "2390", "lr": "0.0001195", "gnorm": "2.577", "loss_scale": "0.125", "train_wall": "17", "gb_free": "12.9", "wall": "30725"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.01395416259765625, 0.0015363693237304688, 0.0015668869018554688, 0.054901123046875, 0.001789093017578125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.01233673095703125, 0.0011835098266601562, 0.0009002685546875, 0.05059814453125, 0.0013408660888671875]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0142822265625, 0.0029582977294921875, 0.0018100738525390625, 0.04559326171875, 0.0242767333984375]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0170440673828125, 0.001964569091796875, 0.0019121170043945312, 0.044097900390625, 0.02606201171875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.041839599609375, 0.0026531219482421875, 0.0029582977294921875, 0.09588623046875, 0.026763916015625]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.00390625]
byte6 pred value: [0.045257568359375, 0.0034160614013671875, 0.004467010498046875, 0.0810546875, 0.064208984375]
byte7 tgt value: [0.99609375, 0.0, 0.0, 0.0, 0.41796875]
byte7 pred value: [0.048309326171875, 0.004180908203125, 0.006290435791015625, 0.094482421875, 0.36328125]
byte8 tgt value: [0.99609375, 0.390625, 0.390625, 0.0078125, 0.85546875]
byte8 pred value: [0.08062744140625, 0.09637451171875, 0.1033935546875, 0.166259765625, 0.47021484375]
tgt code: mov ecx rbx cqo rdi
pred code: mov r12 rdi mov esi
2021-10-11 04:12:00 | INFO | train_inner | {"epoch": 1, "update": 0.194, "loss": "2.349", "code_loss": "2.46", "value_loss_mse": "0.026", "code_ppl": "5.5", "wps": "19212.1", "ups": "0.08", "wpb": "238428", "bsz": "1024", "num_updates": "2400", "lr": "0.00012", "gnorm": "2.539", "loss_scale": "0.125", "train_wall": "16", "gb_free": "12.9", "wall": "30849"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0011653900146484375, 0.003692626953125, 0.019989013671875, 0.0010242462158203125, 0.03338623046875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0011835098266601562, 0.00284576416015625, 0.021209716796875, 0.00106048583984375, 0.030792236328125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0017337799072265625, 0.0032100677490234375, 0.0225372314453125, 0.00147247314453125, 0.0304412841796875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0012350082397460938, 0.0023593902587890625, 0.0261077880859375, 0.0013780593872070312, 0.033782958984375]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0018606185913085938, 0.007755279541015625, 0.056976318359375, 0.001674652099609375, 0.05145263671875]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.004055023193359375, 0.00701141357421875, 0.053985595703125, 0.0037078857421875, 0.053314208984375]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.046112060546875, 0.046905517578125, 0.05780029296875, 0.0830078125, 0.058563232421875]
byte8 tgt value: [0.34375, 0.59375, 0.0, 0.4375, 0.00390625]
byte8 pred value: [0.2454833984375, 0.6875, 0.09368896484375, 0.2646484375, 0.1436767578125]
tgt code: r13 rbx mov lea rsp
pred code: rsi rsi mov mov rsp
2021-10-11 04:14:06 | INFO | train_inner | {"epoch": 1, "update": 0.195, "loss": "2.326", "code_loss": "2.439", "value_loss_mse": "0.026", "code_ppl": "5.42", "wps": "18857.8", "ups": "0.08", "wpb": "236685", "bsz": "1024", "num_updates": "2410", "lr": "0.0001205", "gnorm": "2.357", "loss_scale": "0.125", "train_wall": "21", "gb_free": "12.9", "wall": "30975"}
2021-10-11 04:16:12 | INFO | train_inner | {"epoch": 1, "update": 0.196, "loss": "2.402", "code_loss": "2.464", "value_loss_mse": "0.027", "code_ppl": "5.52", "wps": "18637.7", "ups": "0.08", "wpb": "234912", "bsz": "1024", "num_updates": "2420", "lr": "0.000121", "gnorm": "2.308", "loss_scale": "0.125", "train_wall": "73", "gb_free": "12.9", "wall": "31101"}
2021-10-11 04:18:17 | INFO | train_inner | {"epoch": 1, "update": 0.197, "loss": "2.354", "code_loss": "2.452", "value_loss_mse": "0.026", "code_ppl": "5.47", "wps": "18907.2", "ups": "0.08", "wpb": "237421", "bsz": "1024", "num_updates": "2430", "lr": "0.0001215", "gnorm": "2.368", "loss_scale": "0.125", "train_wall": "83", "gb_free": "12.9", "wall": "31226"}
2021-10-11 04:20:26 | INFO | train_inner | {"epoch": 1, "update": 0.197, "loss": "2.353", "code_loss": "2.441", "value_loss_mse": "0.026", "code_ppl": "5.43", "wps": "18632.5", "ups": "0.08", "wpb": "238931", "bsz": "1024", "num_updates": "2440", "lr": "0.000122", "gnorm": "2.552", "loss_scale": "0.125", "train_wall": "17", "gb_free": "12.9", "wall": "31354"}
2021-10-11 04:22:32 | INFO | train_inner | {"epoch": 1, "update": 0.198, "loss": "2.344", "code_loss": "2.456", "value_loss_mse": "0.026", "code_ppl": "5.49", "wps": "19384.7", "ups": "0.08", "wpb": "245194", "bsz": "1024", "num_updates": "2450", "lr": "0.0001225", "gnorm": "2.657", "loss_scale": "0.125", "train_wall": "18", "gb_free": "12.9", "wall": "31481"}
2021-10-11 04:24:45 | INFO | train_inner | {"epoch": 1, "update": 0.199, "loss": "2.368", "code_loss": "2.465", "value_loss_mse": "0.027", "code_ppl": "5.52", "wps": "18328.9", "ups": "0.08", "wpb": "243704", "bsz": "1024", "num_updates": "2460", "lr": "0.000123", "gnorm": "2.183", "loss_scale": "0.125", "train_wall": "17", "gb_free": "17", "wall": "31614"}
2021-10-11 04:26:52 | INFO | train_inner | {"epoch": 1, "update": 0.2, "loss": "2.299", "code_loss": "2.43", "value_loss_mse": "0.026", "code_ppl": "5.39", "wps": "19582.7", "ups": "0.08", "wpb": "248832", "bsz": "1024", "num_updates": "2470", "lr": "0.0001235", "gnorm": "2.273", "loss_scale": "0.125", "train_wall": "18", "gb_free": "12.9", "wall": "31741"}
2021-10-11 04:29:00 | INFO | train_inner | {"epoch": 1, "update": 0.201, "loss": "2.347", "code_loss": "2.437", "value_loss_mse": "0.026", "code_ppl": "5.42", "wps": "17980", "ups": "0.08", "wpb": "230258", "bsz": "1024", "num_updates": "2480", "lr": "0.000124", "gnorm": "2.156", "loss_scale": "0.125", "train_wall": "16", "gb_free": "12.9", "wall": "31869"}
2021-10-11 04:31:21 | INFO | train_inner | {"epoch": 1, "update": 0.201, "loss": "2.322", "code_loss": "2.454", "value_loss_mse": "0.026", "code_ppl": "5.48", "wps": "18601.4", "ups": "0.07", "wpb": "262574", "bsz": "1024", "num_updates": "2490", "lr": "0.0001245", "gnorm": "2.169", "loss_scale": "0.125", "train_wall": "18", "gb_free": "12.9", "wall": "32010"}
2021-10-11 04:33:19 | INFO | train_inner | {"epoch": 1, "update": 0.202, "loss": "2.32", "code_loss": "2.444", "value_loss_mse": "0.026", "code_ppl": "5.44", "wps": "18863.4", "ups": "0.09", "wpb": "221507", "bsz": "1024", "num_updates": "2500", "lr": "0.000125", "gnorm": "2.475", "loss_scale": "0.125", "train_wall": "15", "gb_free": "12.9", "wall": "32128"}
2021-10-11 04:35:37 | INFO | train_inner | {"epoch": 1, "update": 0.203, "loss": "2.319", "code_loss": "2.428", "value_loss_mse": "0.026", "code_ppl": "5.38", "wps": "18653.3", "ups": "0.07", "wpb": "256690", "bsz": "1024", "num_updates": "2510", "lr": "0.0001255", "gnorm": "2.39", "loss_scale": "0.125", "train_wall": "18", "gb_free": "12.9", "wall": "32265"}
2021-10-11 04:37:36 | INFO | train_inner | {"epoch": 1, "update": 0.204, "loss": "2.34", "code_loss": "2.415", "value_loss_mse": "0.026", "code_ppl": "5.33", "wps": "19197.1", "ups": "0.08", "wpb": "229427", "bsz": "1024", "num_updates": "2520", "lr": "0.000126", "gnorm": "2.449", "loss_scale": "0.125", "train_wall": "15", "gb_free": "12.9", "wall": "32385"}
2021-10-11 04:39:48 | INFO | train_inner | {"epoch": 1, "update": 0.205, "loss": "2.371", "code_loss": "2.453", "value_loss_mse": "0.027", "code_ppl": "5.48", "wps": "19044.6", "ups": "0.08", "wpb": "252208", "bsz": "1024", "num_updates": "2530", "lr": "0.0001265", "gnorm": "2.473", "loss_scale": "0.125", "train_wall": "17", "gb_free": "12.9", "wall": "32517"}
2021-10-11 04:41:53 | INFO | train_inner | {"epoch": 1, "update": 0.205, "loss": "2.309", "code_loss": "2.422", "value_loss_mse": "0.026", "code_ppl": "5.36", "wps": "19385.6", "ups": "0.08", "wpb": "242179", "bsz": "1024", "num_updates": "2540", "lr": "0.000127", "gnorm": "2.186", "loss_scale": "0.125", "train_wall": "18", "gb_free": "12.9", "wall": "32642"}
2021-10-11 04:44:03 | INFO | train_inner | {"epoch": 1, "update": 0.206, "loss": "2.364", "code_loss": "2.457", "value_loss_mse": "0.027", "code_ppl": "5.49", "wps": "18656.6", "ups": "0.08", "wpb": "242678", "bsz": "1024", "num_updates": "2550", "lr": "0.0001275", "gnorm": "1.989", "loss_scale": "0.125", "train_wall": "68", "gb_free": "12.9", "wall": "32772"}
2021-10-11 04:46:11 | INFO | train_inner | {"epoch": 1, "update": 0.207, "loss": "2.327", "code_loss": "2.449", "value_loss_mse": "0.026", "code_ppl": "5.46", "wps": "18141.2", "ups": "0.08", "wpb": "230850", "bsz": "1024", "num_updates": "2560", "lr": "0.000128", "gnorm": "2.126", "loss_scale": "0.25", "train_wall": "89", "gb_free": "12.9", "wall": "32899"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.001941680908203125, 0.0008358955383300781, 0.0005359649658203125, 0.0028228759765625, 0.005344390869140625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00250244140625, 0.001129150390625, 0.00055694580078125, 0.0036220550537109375, 0.00524139404296875]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0087432861328125, 0.0035114288330078125, 0.0018968582153320312, 0.0033626556396484375, 0.00579833984375]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.01473236083984375, 0.0031108856201171875, 0.002124786376953125, 0.00313568115234375, 0.004756927490234375]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0125274658203125, 0.00494384765625, 0.00945281982421875, 0.00482940673828125, 0.00679779052734375]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.00971221923828125, 0.004230499267578125, 0.013427734375, 0.0059814453125, 0.00844573974609375]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.01132965087890625, 0.00955963134765625, 0.166015625, 0.00763702392578125, 0.0094146728515625]
byte8 tgt value: [0.19140625, 0.19140625, 0.00390625, 0.125, 0.125]
byte8 pred value: [0.141357421875, 0.1708984375, 0.290283203125, 0.1668701171875, 0.1279296875]
tgt code: hexvar jne call rbx
pred code: hexvar call call rbx
2021-10-11 04:48:19 | INFO | train_inner | {"epoch": 1, "update": 0.208, "loss": "2.322", "code_loss": "2.44", "value_loss_mse": "0.026", "code_ppl": "5.43", "wps": "19246.8", "ups": "0.08", "wpb": "247059", "bsz": "1024", "num_updates": "2570", "lr": "0.0001285", "gnorm": "2.007", "loss_scale": "0.25", "train_wall": "71", "gb_free": "12.9", "wall": "33028"}
2021-10-11 04:50:16 | INFO | train_inner | {"epoch": 1, "update": 0.209, "loss": "2.334", "code_loss": "2.437", "value_loss_mse": "0.026", "code_ppl": "5.41", "wps": "18240.8", "ups": "0.09", "wpb": "212510", "bsz": "1024", "num_updates": "2580", "lr": "0.000129", "gnorm": "2.433", "loss_scale": "0.25", "train_wall": "55", "gb_free": "12.9", "wall": "33144"}
2021-10-11 04:52:14 | INFO | train_inner | {"epoch": 1, "update": 0.209, "loss": "2.352", "code_loss": "2.421", "value_loss_mse": "0.027", "code_ppl": "5.36", "wps": "19233.6", "ups": "0.08", "wpb": "227555", "bsz": "1024", "num_updates": "2590", "lr": "0.0001295", "gnorm": "2.446", "loss_scale": "0.25", "train_wall": "49", "gb_free": "12.9", "wall": "33263"}
2021-10-11 04:54:18 | INFO | train_inner | {"epoch": 1, "update": 0.21, "loss": "2.329", "code_loss": "2.422", "value_loss_mse": "0.026", "code_ppl": "5.36", "wps": "18801.3", "ups": "0.08", "wpb": "232422", "bsz": "1024", "num_updates": "2600", "lr": "0.00013", "gnorm": "2.227", "loss_scale": "0.25", "train_wall": "25", "gb_free": "12.9", "wall": "33386"}
2021-10-11 04:56:24 | INFO | train_inner | {"epoch": 1, "update": 0.211, "loss": "2.349", "code_loss": "2.429", "value_loss_mse": "0.026", "code_ppl": "5.39", "wps": "17804.6", "ups": "0.08", "wpb": "225756", "bsz": "1024", "num_updates": "2610", "lr": "0.0001305", "gnorm": "2.496", "loss_scale": "0.25", "train_wall": "85", "gb_free": "12.9", "wall": "33513"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0026531219482421875, 0.0022792816162109375, 0.0020427703857421875, 0.00669097900390625, 0.003124237060546875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0025615692138671875, 0.00243377685546875, 0.0017004013061523438, 0.007965087890625, 0.0022869110107421875]
byte3 tgt value: [0.0, 0.1171875, 0.0, 0.0, 0.1171875]
byte3 pred value: [0.01422882080078125, 0.06097412109375, 0.0019044876098632812, 0.00511932373046875, 0.03204345703125]
byte4 tgt value: [0.0, 0.48828125, 0.0, 0.0, 0.48828125]
byte4 pred value: [0.0226287841796875, 0.1087646484375, 0.001720428466796875, 0.004962921142578125, 0.0784912109375]
byte5 tgt value: [0.0, 0.57421875, 0.0, 0.0, 0.57421875]
byte5 pred value: [0.0299835205078125, 0.15966796875, 0.0020751953125, 0.005199432373046875, 0.10284423828125]
byte6 tgt value: [0.0, 0.31640625, 0.0, 0.0, 0.32421875]
byte6 pred value: [0.0287017822265625, 0.1077880859375, 0.002704620361328125, 0.007518768310546875, 0.09124755859375]
byte7 tgt value: [0.0, 0.0234375, 0.0, 0.0, 0.0078125]
byte7 pred value: [0.0295867919921875, 0.1866455078125, 0.00555419921875, 0.007724761962890625, 0.105224609375]
byte8 tgt value: [0.09765625, 0.484375, 0.03125, 0.03125, 0.375]
byte8 pred value: [0.1368408203125, 0.270751953125, 0.06964111328125, 0.055816650390625, 0.159912109375]
tgt code: mov esi mov ecx test
pred code: mov hexvar mov rax pop
2021-10-11 04:58:38 | INFO | train_inner | {"epoch": 1, "update": 0.212, "loss": "2.336", "code_loss": "2.441", "value_loss_mse": "0.026", "code_ppl": "5.43", "wps": "18371.2", "ups": "0.07", "wpb": "246234", "bsz": "1024", "num_updates": "2620", "lr": "0.000131", "gnorm": "2.404", "loss_scale": "0.25", "train_wall": "103", "gb_free": "12.9", "wall": "33647"}
[0.00963592529296875, 0.0032100677490234375, 0.0011119842529296875, 0.0015010833740234375, 0.0022335052490234375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00878143310546875, 0.0035381317138671875, 0.0007915496826171875, 0.0008935928344726562, 0.0023784637451171875]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0182952880859375, 0.0180511474609375, 0.0276947021484375, 0.02886962890625, 0.00279998779296875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0304412841796875, 0.01934814453125, 0.06817626953125, 0.07861328125, 0.00257110595703125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.050048828125, 0.01519012451171875, 0.0299224853515625, 0.0271759033203125, 0.003040313720703125]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.00390625]
byte6 pred value: [0.07135009765625, 0.0299224853515625, 0.05633544921875, 0.059326171875, 0.00997161865234375]
byte7 tgt value: [0.0, 0.0, 0.56640625, 0.6015625, 0.671875]
byte7 pred value: [0.0504150390625, 0.021820068359375, 0.4716796875, 0.45947265625, 0.155029296875]
byte8 tgt value: [0.08984375, 0.0234375, 0.1875, 0.64453125, 0.734375]
byte8 pred value: [0.11163330078125, 0.12188720703125, 0.4970703125, 0.468505859375, 0.2144775390625]
tgt code: r12d + add rdx hexvar
pred code: hexvar + mov rdi hexvar
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.02069091796875, 0.00482940673828125, 0.01490020751953125, 0.01560211181640625, 0.015899658203125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.03125, 0.004314422607421875, 0.0074615478515625, 0.01507568359375, 0.0165863037109375]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0230255126953125, 0.0079345703125, 0.027374267578125, 0.0311431884765625, 0.0180206298828125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.033966064453125, 0.007785797119140625, 0.03875732421875, 0.056640625, 0.0242767333984375]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.035552978515625, 0.1553955078125, 0.05633544921875, 0.04193115234375, 0.035552978515625]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.0262603759765625, 0.1585693359375, 0.032470703125, 0.038177490234375, 0.0236053466796875]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.03228759765625, 0.1239013671875, 0.037384033203125, 0.058013916015625, 0.04132080078125]
byte8 tgt value: [0.03125, 0.20703125, 0.0, 0.0, 0.203125]
byte8 pred value: [0.1668701171875, 0.141845703125, 0.0943603515625, 0.0869140625, 0.1390380859375]
tgt code: rsp hexvar mov mov
pred code: rsp hexvar mov sub
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0207672119140625, 0.037750244140625, 0.002834320068359375, 0.00572967529296875, 0.01678466796875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.021087646484375, 0.043701171875, 0.0024623870849609375, 0.00787353515625, 0.0169219970703125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.49609375, 0.0]
byte3 pred value: [0.12200927734375, 0.05242919921875, 0.0022430419921875, 0.49560546875, 0.0248870849609375]
byte4 tgt value: [0.0, 0.0, 0.0, 0.99609375, 0.0]
byte4 pred value: [0.1480712890625, 0.044097900390625, 0.0024433135986328125, 0.9833984375, 0.0235595703125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.80859375, 0.0]
byte5 pred value: [0.202880859375, 0.06597900390625, 0.0191650390625, 0.8408203125, 0.0252685546875]
byte6 tgt value: [0.0, 0.0, 0.0, 0.703125, 0.0]
byte6 pred value: [0.218505859375, 0.06982421875, 0.020721435546875, 0.85205078125, 0.026153564453125]
byte7 tgt value: [0.0, 0.0, 0.0, 0.86328125, 0.0]
byte7 pred value: [0.270263671875, 0.0615234375, 0.0226287841796875, 0.71240234375, 0.0252227783203125]
byte8 tgt value: [0.05859375, 0.0, 0.0, 0.0, 0.0]
byte8 pred value: [0.28076171875, 0.12890625, 0.08990478515625, 0.1429443359375, 0.0894775390625]
tgt code: + pop ^4 rbx +
pred code: + mov ^4 ^4 +
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0011606216430664062, 0.00323486328125, 0.0010862350463867188, 0.0022869110107421875, 0.00591278076171875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0015192031860351562, 0.0033512115478515625, 0.0011739730834960938, 0.002811431884765625, 0.004299163818359375]
byte3 tgt value: [0.38671875, 0.0, 0.0, 0.46875, 0.0]
byte3 pred value: [0.3251953125, 0.0041351318359375, 0.002620697021484375, 0.2178955078125, 0.006984710693359375]
byte4 tgt value: [0.95703125, 0.0, 0.0, 0.4375, 0.0]
byte4 pred value: [0.775390625, 0.00591278076171875, 0.00426483154296875, 0.52978515625, 0.01024627685546875]
byte5 tgt value: [0.7421875, 0.0, 0.0, 0.3515625, 0.0]
byte5 pred value: [0.72412109375, 0.00806427001953125, 0.006191253662109375, 0.55810546875, 0.017578125]
byte6 tgt value: [0.87890625, 0.0, 0.0, 0.74609375, 0.0]
byte6 pred value: [0.84765625, 0.00867462158203125, 0.007843017578125, 0.48193359375, 0.01229095458984375]
byte7 tgt value: [0.7109375, 0.0, 0.0, 0.08203125, 0.0]
byte7 pred value: [0.5166015625, 0.010528564453125, 0.0121917724609375, 0.50341796875, 0.011505126953125]
byte8 tgt value: [0.3125, 0.03125, 0.1953125, 0.0703125, 0.359375]
byte8 pred value: [0.328857421875, 0.0618896484375, 0.1153564453125, 0.29931640625, 0.0987548828125]
tgt code: xor eax ret mov hexvar
pred code: mov eax ret mov hexvar
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0014495849609375, 0.00524139404296875, 0.002758026123046875, 0.0035648345947265625, 0.0018463134765625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0014162063598632812, 0.006984710693359375, 0.0030269622802734375, 0.0031719207763671875, 0.00238800048828125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.038116455078125, 0.0059356689453125, 0.004150390625, 0.00464630126953125, 0.00257110595703125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0701904296875, 0.0054473876953125, 0.00518035888671875, 0.0043487548828125, 0.0037364959716796875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0751953125, 0.00847625732421875, 0.004314422607421875, 0.004150390625, 0.0139007568359375]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.052825927734375, 0.0090179443359375, 0.00395965576171875, 0.0034027099609375, 0.01406097412109375]
byte7 tgt value: [0.60546875, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.493408203125, 0.0110321044921875, 0.0054473876953125, 0.004756927490234375, 0.01337432861328125]
byte8 tgt value: [0.1875, 0.01953125, 0.14453125, 0.16796875, 0.234375]
byte8 pred value: [0.392333984375, 0.10174560546875, 0.154052734375, 0.11358642578125, 0.115966796875]
tgt code: eax je ^8 mov +
pred code: rdi mov ^8 mov +
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0023975372314453125, 0.00878143310546875, 0.00555419921875, 0.00809478759765625, 0.0029926300048828125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0021076202392578125, 0.01016998291015625, 0.00734710693359375, 0.00878143310546875, 0.0022525787353515625]
byte3 tgt value: [0.0, 0.0, 0.25, 0.0, 0.0]
byte3 pred value: [0.0036640167236328125, 0.00948333740234375, 0.197021484375, 0.010406494140625, 0.002140045166015625]
byte4 tgt value: [0.0, 0.0, 0.7265625, 0.0, 0.0]
byte4 pred value: [0.007038116455078125, 0.012481689453125, 0.4052734375, 0.0119171142578125, 0.002452850341796875]
byte5 tgt value: [0.0, 0.0, 0.2578125, 0.0, 0.0]
byte5 pred value: [0.0103302001953125, 0.0089874267578125, 0.415283203125, 0.00881195068359375, 0.01560211181640625]
byte6 tgt value: [0.00390625, 0.0, 0.65625, 0.0, 0.0]
byte6 pred value: [0.0312042236328125, 0.009674072265625, 0.47119140625, 0.0090179443359375, 0.014617919921875]
byte7 tgt value: [0.9140625, 0.0, 0.0234375, 0.0, 0.0]
byte7 pred value: [0.802734375, 0.009674072265625, 0.1964111328125, 0.00963592529296875, 0.027008056640625]
byte8 tgt value: [0.58984375, 0.21875, 0.20703125, 0.21875, 0.078125]
byte8 pred value: [0.44482421875, 0.09979248046875, 0.275146484375, 0.11199951171875, 0.12347412109375]
tgt code: eax lea + hexvar lea
pred code: hexvar lea + + mov
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: 2021-10-11 05:00:43 | INFO | train_inner | {"epoch": 1, "update": 0.213, "loss": "2.295", "code_loss": "2.414", "value_loss_mse": "0.026", "code_ppl": "5.33", "wps": "18621.5", "ups": "0.08", "wpb": "231514", "bsz": "1024", "num_updates": "2630", "lr": "0.0001315", "gnorm": "2.437", "loss_scale": "0.25", "train_wall": "72", "gb_free": "12.9", "wall": "33771"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0038547515869140625, 0.076416015625, 0.0032100677490234375, 0.0017480850219726562, 0.0016613006591796875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0041351318359375, 0.08599853515625, 0.003185272216796875, 0.0014104843139648438, 0.001918792724609375]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0060272216796875, 0.09173583984375, 0.07806396484375, 0.003765106201171875, 0.0028781890869140625]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.00494384765625, 0.0738525390625, 0.12322998046875, 0.005001068115234375, 0.0032482147216796875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0070648193359375, 0.093994140625, 0.097412109375, 0.087890625, 0.003337860107421875]
byte6 tgt value: [0.0390625, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.0274810791015625, 0.0743408203125, 0.1044921875, 0.08599853515625, 0.003429412841796875]
byte7 tgt value: [0.4296875, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.32470703125, 0.07476806640625, 0.11126708984375, 0.0792236328125, 0.00821685791015625]
byte8 tgt value: [0.48828125, 0.00390625, 0.0, 0.0, 0.1875]
byte8 pred value: [0.38134765625, 0.1295166015625, 0.142333984375, 0.155029296875, 0.12445068359375]
tgt code: r10 rip hexvar ^2 mov
pred code: rax rip hexvar ^1 mov
2021-10-11 05:02:43 | INFO | train_inner | {"epoch": 1, "update": 0.213, "loss": "2.306", "code_loss": "2.414", "value_loss_mse": "0.026", "code_ppl": "5.33", "wps": "19136.2", "ups": "0.08", "wpb": "231107", "bsz": "1024", "num_updates": "2640", "lr": "0.000132", "gnorm": "2.422", "loss_scale": "0.25", "train_wall": "45", "gb_free": "12.9", "wall": "33892"}
2021-10-11 05:04:49 | INFO | train_inner | {"epoch": 1, "update": 0.214, "loss": "2.291", "code_loss": "2.432", "value_loss_mse": "0.026", "code_ppl": "5.4", "wps": "19198.8", "ups": "0.08", "wpb": "241627", "bsz": "1024", "num_updates": "2650", "lr": "0.0001325", "gnorm": "2.199", "loss_scale": "0.25", "train_wall": "19", "gb_free": "12.9", "wall": "34018"}
2021-10-11 05:06:55 | INFO | train_inner | {"epoch": 1, "update": 0.215, "loss": "2.312", "code_loss": "2.406", "value_loss_mse": "0.026", "code_ppl": "5.3", "wps": "18350.4", "ups": "0.08", "wpb": "230944", "bsz": "1024", "num_updates": "2660", "lr": "0.000133", "gnorm": "2.192", "loss_scale": "0.25", "train_wall": "16", "gb_free": "12.9", "wall": "34144"}
2021-10-11 05:09:05 | INFO | train_inner | {"epoch": 1, "update": 0.216, "loss": "2.288", "code_loss": "2.419", "value_loss_mse": "0.026", "code_ppl": "5.35", "wps": "19709.9", "ups": "0.08", "wpb": "255139", "bsz": "1024", "num_updates": "2670", "lr": "0.0001335", "gnorm": "2.232", "loss_scale": "0.25", "train_wall": "16", "gb_free": "12.9", "wall": "34273"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.005428314208984375, 0.0011739730834960938, 0.00646209716796875, 0.00021314620971679688, 0.0018672943115234375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00424957275390625, 0.0017747879028320312, 0.0053863525390625, 0.0003905296325683594, 0.0026416778564453125]
byte3 tgt value: [0.375, 0.0, 0.375, 0.0, 0.375]
byte3 pred value: [0.181884765625, 0.0018177032470703125, 0.275634765625, 0.00243377685546875, 0.0830078125]
byte4 tgt value: [0.89453125, 0.0, 0.89453125, 0.0, 0.89453125]
byte4 pred value: [0.888671875, 0.0020751953125, 0.8046875, 0.00634002685546875, 0.443115234375]
byte5 tgt value: [0.51953125, 0.0, 0.51953125, 0.0, 0.51953125]
byte5 pred value: [0.681640625, 0.0059814453125, 0.277587890625, 0.004150390625, 0.312744140625]
byte6 tgt value: [0.21484375, 0.0, 0.21875, 0.0, 0.21484375]
byte6 pred value: [0.1834716796875, 0.01666259765625, 0.1966552734375, 0.00766754150390625, 0.11083984375]
byte7 tgt value: [0.6328125, 0.65234375, 0.28515625, 0.0, 0.6328125]
byte7 pred value: [0.56201171875, 0.67138671875, 0.405029296875, 0.0831298828125, 0.373291015625]
byte8 tgt value: [0.26953125, 0.046875, 0.2421875, 0.15625, 0.875]
byte8 pred value: [0.44140625, 0.1700439453125, 0.5068359375, 0.460693359375, 0.57080078125]
tgt code: rdi rbp ^8 rbx ^8
pred code: rbx rsp ^8 + ^8
2021-10-11 05:11:18 | INFO | train_inner | {"epoch": 1, "update": 0.217, "loss": "2.317", "code_loss": "2.418", "value_loss_mse": "0.026", "code_ppl": "5.35", "wps": "19038.7", "ups": "0.07", "wpb": "254576", "bsz": "1024", "num_updates": "2680", "lr": "0.000134", "gnorm": "2.335", "loss_scale": "0.25", "train_wall": "41", "gb_free": "12.9", "wall": "34407"}
2021-10-11 05:13:26 | INFO | train_inner | {"epoch": 1, "update": 0.217, "loss": "2.316", "code_loss": "2.402", "value_loss_mse": "0.026", "code_ppl": "5.29", "wps": "17985.1", "ups": "0.08", "wpb": "228822", "bsz": "1024", "num_updates": "2690", "lr": "0.0001345", "gnorm": "2.171", "loss_scale": "0.25", "train_wall": "86", "gb_free": "12.9", "wall": "34534"}
2021-10-11 05:15:33 | INFO | train_inner | {"epoch": 1, "update": 0.218, "loss": "2.359", "code_loss": "2.408", "value_loss_mse": "0.027", "code_ppl": "5.31", "wps": "18376", "ups": "0.08", "wpb": "233706", "bsz": "1024", "num_updates": "2700", "lr": "0.000135", "gnorm": "2.646", "loss_scale": "0.25", "train_wall": "94", "gb_free": "12.9", "wall": "34661"}
[0.00070953369140625, 0.001201629638671875, 0.00127410888671875, 0.0015916824340820312, 0.0036067962646484375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.000720977783203125, 0.0008296966552734375, 0.0011425018310546875, 0.0011968612670898438, 0.0029354095458984375]
byte3 tgt value: [0.0, 0.125, 0.0, 0.0, 0.0]
byte3 pred value: [0.0034961700439453125, 0.0567626953125, 0.0013885498046875, 0.0012302398681640625, 0.004055023193359375]
byte4 tgt value: [0.0, 0.546875, 0.0, 0.0, 0.0]
byte4 pred value: [0.00453948974609375, 0.08831787109375, 0.0017957687377929688, 0.001987457275390625, 0.004215240478515625]
byte5 tgt value: [0.0, 0.4453125, 0.0, 0.0, 0.0]
byte5 pred value: [0.0202178955078125, 0.12322998046875, 0.090087890625, 0.06890869140625, 0.1724853515625]
byte6 tgt value: [0.0, 0.7109375, 0.0, 0.0, 0.0]
byte6 pred value: [0.0374755859375, 0.286865234375, 0.132080078125, 0.0999755859375, 0.2410888671875]
byte7 tgt value: [0.0, 0.765625, 0.0, 0.0, 0.0]
byte7 pred value: [0.042724609375, 0.525390625, 0.10467529296875, 0.0810546875, 0.171875]
byte8 tgt value: [0.03125, 0.53515625, 0.0, 0.0, 0.0]
byte8 pred value: [0.08062744140625, 0.379150390625, 0.093017578125, 0.07489013671875, 0.1239013671875]
tgt code: lea ecx lea hexvar rax
pred code: mov eax mov + ebx
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00690460205078125, 0.0020427703857421875, 0.08819580078125, 0.06109619140625, 0.0011205673217773438]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00734710693359375, 0.0025501251220703125, 0.09124755859375, 0.036773681640625, 0.0015916824340820312]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.47265625]
byte3 pred value: [0.005619049072265625, 0.007755279541015625, 0.09967041015625, 0.185302734375, 0.07684326171875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.15625]
byte4 pred value: [0.00536346435546875, 0.01137542724609375, 0.11279296875, 0.2371826171875, 0.051666259765625]
byte5 tgt value: [0.0625, 0.0, 0.0, 0.0, 0.82421875]
byte5 pred value: [0.35888671875, 0.047882080078125, 0.1026611328125, 0.2109375, 0.251220703125]
byte6 tgt value: [0.48046875, 0.0, 0.0, 0.0, 0.0078125]
byte6 pred value: [0.328857421875, 0.026458740234375, 0.110107421875, 0.1207275390625, 0.035675048828125]
byte7 tgt value: [0.6171875, 0.0, 0.0, 0.0, 0.21484375]
byte7 pred value: [0.402099609375, 0.058990478515625, 0.11419677734375, 0.2083740234375, 0.3037109375]
byte8 tgt value: [0.63671875, 0.17578125, 0.0, 0.02734375, 0.24609375]
byte8 pred value: [0.263671875, 0.15576171875, 0.14208984375, 0.1680908203125, 0.429443359375]
tgt code: mov ^4 xor rbp rbp
pred code: mov ^8 mov rbp rbp
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.006072998046875, 0.0008864402770996094, 0.0006022453308105469, 0.0011034011840820312, 0.0004172325134277344]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.004199981689453125, 0.0010690689086914062, 0.0006747245788574219, 0.0009183883666992188, 0.0005860328674316406]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0028896331787109375, 0.0015192031860351562, 0.0018749237060546875, 0.00536346435546875, 0.0013456344604492188]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.00142669677734375, 0.0011119842529296875, 0.0017547607421875, 0.006313323974609375, 0.0015735626220703125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0043487548828125, 0.0041351318359375, 0.002368927001953125, 0.00908660888671875, 0.0026111602783203125]
byte6 tgt value: [0.015625, 0.0, 0.0, 0.01171875, 0.0]
byte6 pred value: [0.0167236328125, 0.004364013671875, 0.0035247802734375, 0.0135345458984375, 0.003482818603515625]
byte7 tgt value: [0.81640625, 0.0, 0.0, 0.98046875, 0.0]
byte7 pred value: [0.732421875, 0.0050811767578125, 0.00919342041015625, 0.61328125, 0.01374053955078125]
byte8 tgt value: [0.12109375, 0.03125, 0.46875, 0.125, 0.46875]
byte8 pred value: [0.187744140625, 0.0460205078125, 0.234375, 0.474365234375, 0.2305908203125]
tgt code: hexvar r13 xor edx mov
pred code: hexvar hexvar mov rsi mov
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0008330345153808594, 0.0008168220520019531, 0.00313568115234375, 0.001949310302734375, 0.001438140869140625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0009398460388183594, 0.0008559226989746094, 0.0030994415283203125, 0.0024929046630859375, 0.0015010833740234375]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0013828277587890625, 0.01129150390625, 0.003635406494140625, 0.0041351318359375, 0.00323486328125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0013780593872070312, 0.0136871337890625, 0.0035114288330078125, 0.004070281982421875, 0.00284576416015625]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.001964569091796875, 0.0216217041015625, 0.003749847412109375, 0.0029582977294921875, 0.004199981689453125]
byte6 tgt value: [0.0, 0.00390625, 0.0, 0.0, 0.0]
byte6 pred value: [0.0032978057861328125, 0.034027099609375, 0.003376007080078125, 0.0031719207763671875, 0.007175445556640625]
byte7 tgt value: [0.0, 0.39453125, 0.0, 0.0, 0.0]
byte7 pred value: [0.0079345703125, 0.42626953125, 0.004772186279296875, 0.00634002685546875, 0.06610107421875]
byte8 tgt value: [0.0625, 0.1875, 0.23046875, 0.0078125, 0.0625]
byte8 pred value: [0.1531982421875, 0.44580078125, 0.102294921875, 0.0765380859375, 0.2462158203125]
tgt code: push mov test rbp pop
pred code: mov mov mov r14 mov
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.063720703125, 0.0007123947143554688, 0.2281494140625, 0.0059814453125, 0.0010404586791992188]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.057708740234375, 0.0008864402770996094, 0.254638671875, 0.004055023193359375, 0.001178741455078125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.32421875, 0.0]
byte3 pred value: [0.06536865234375, 0.00266265869140625, 0.16943359375, 0.344482421875, 0.01129150390625]
byte4 tgt value: [0.0, 0.0, 0.0, 0.99609375, 0.0]
byte4 pred value: [0.08062744140625, 0.0020275115966796875, 0.179931640625, 0.8076171875, 0.0137939453125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.5703125, 0.0]
byte5 pred value: [0.0938720703125, 0.0031108856201171875, 0.3837890625, 0.72802734375, 0.03271484375]
byte6 tgt value: [0.0, 0.0, 0.0, 0.09765625, 0.0]
byte6 pred value: [0.1483154296875, 0.005260467529296875, 0.460205078125, 0.1087646484375, 0.01146697998046875]
byte7 tgt value: [0.0, 0.0, 0.0, 0.62890625, 0.0]
byte7 pred value: [0.09686279296875, 0.064208984375, 0.3896484375, 0.67578125, 0.03033447265625]
byte8 tgt value: [0.0, 0.0546875, 0.0, 0.30859375, 0.19921875]
byte8 pred value: [0.1700439453125, 0.23095703125, 0.350341796875, 0.69140625, 0.178955078125]
tgt code: mov + hexvar r13 +
pred code: mov + hexvar r15 +
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.006744384765625, 0.0018529891967773438, 0.005535125732421875, 0.00327301025390625, 0.0013666152954101562]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0082550048828125, 0.00279998779296875, 0.005641937255859375, 0.002368927001953125, 0.001941680908203125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.11614990234375, 0.003223419189453125, 0.00577545166015625, 0.11474609375, 0.00269317626953125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.11578369140625, 0.0031604766845703125, 0.004810333251953125, 0.09844970703125, 0.0034961700439453125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.207275390625, 0.0034427642822265625, 0.005100250244140625, 0.1605224609375, 0.0038547515869140625]
byte6 tgt value: [0.0, 0.0234375, 0.0, 0.0, 0.00390625]
byte6 pred value: [0.31689453125, 0.0177154541015625, 0.007259368896484375, 0.308349609375, 0.01525115966796875]
byte7 tgt value: [0.0, 0.05859375, 0.0, 0.0, 0.09765625]
byte7 pred value: [0.2213134765625, 0.348388671875, 0.005100250244140625, 0.25634765625, 0.4755859375]
byte8 tgt value: [0.13671875, 0.01953125, 0.0, 0.140625, 0.45703125]
byte8 pred value: [0.289794921875, 0.47900390625, 0.03662109375, 0.338134765625, 0.49169921875]
tgt code: mov rip rdx mov rax
pred code: mov rip rbp mov rax2021-10-11 05:17:40 | INFO | train_inner | {"epoch": 1, "update": 0.219, "loss": "2.315", "code_loss": "2.425", "value_loss_mse": "0.026", "code_ppl": "5.37", "wps": "18901.2", "ups": "0.08", "wpb": "241475", "bsz": "1024", "num_updates": "2710", "lr": "0.0001355", "gnorm": "2.413", "loss_scale": "0.25", "train_wall": "80", "gb_free": "12.9", "wall": "34789"}
2021-10-11 05:19:46 | INFO | train_inner | {"epoch": 1, "update": 0.22, "loss": "2.238", "code_loss": "2.401", "value_loss_mse": "0.025", "code_ppl": "5.28", "wps": "18685.3", "ups": "0.08", "wpb": "235136", "bsz": "1024", "num_updates": "2720", "lr": "0.000136", "gnorm": "2.402", "loss_scale": "0.25", "train_wall": "69", "gb_free": "12.9", "wall": "34915"}
2021-10-11 05:21:54 | INFO | train_inner | {"epoch": 1, "update": 0.221, "loss": "2.29", "code_loss": "2.43", "value_loss_mse": "0.026", "code_ppl": "5.39", "wps": "18950.2", "ups": "0.08", "wpb": "241577", "bsz": "1024", "num_updates": "2730", "lr": "0.0001365", "gnorm": "2.247", "loss_scale": "0.25", "train_wall": "87", "gb_free": "12.9", "wall": "35042"}
2021-10-11 05:23:59 | INFO | train_inner | {"epoch": 1, "update": 0.222, "loss": "2.296", "code_loss": "2.4", "value_loss_mse": "0.026", "code_ppl": "5.28", "wps": "18692.5", "ups": "0.08", "wpb": "233165", "bsz": "1024", "num_updates": "2740", "lr": "0.000137", "gnorm": "2.334", "loss_scale": "0.25", "train_wall": "25", "gb_free": "12.9", "wall": "35167"}
2021-10-11 05:26:01 | INFO | train_inner | {"epoch": 1, "update": 0.222, "loss": "2.268", "code_loss": "2.374", "value_loss_mse": "0.025", "code_ppl": "5.18", "wps": "18768.7", "ups": "0.08", "wpb": "229885", "bsz": "1024", "num_updates": "2750", "lr": "0.0001375", "gnorm": "2.156", "loss_scale": "0.25", "train_wall": "17", "gb_free": "12.9", "wall": "35290"}
byte1 tgt value: [0.99609375, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.042327880859375, 0.00035691261291503906, 0.1527099609375, 0.00234222412109375, 0.00250244140625]
byte2 tgt value: [0.99609375, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.042633056640625, 0.0007066726684570312, 0.14990234375, 0.00257110595703125, 0.0025310516357421875]
byte3 tgt value: [0.99609375, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.03582763671875, 0.0024433135986328125, 0.10247802734375, 0.004810333251953125, 0.0050811767578125]
byte4 tgt value: [0.99609375, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0509033203125, 0.00359344482421875, 0.14794921875, 0.005344390869140625, 0.006717681884765625]
byte5 tgt value: [0.99609375, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.06793212890625, 0.004791259765625, 0.1864013671875, 0.00653839111328125, 0.00809478759765625]
byte6 tgt value: [0.99609375, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.050140380859375, 0.0106964111328125, 0.164306640625, 0.00679779052734375, 0.00997161865234375]
byte7 tgt value: [0.99609375, 0.2578125, 0.0, 0.0, 0.0]
byte7 pred value: [0.093505859375, 0.323486328125, 0.2352294921875, 0.008514404296875, 0.01009368896484375]
byte8 tgt value: [0.99609375, 0.546875, 0.01953125, 0.03515625, 0.03515625]
byte8 pred value: [0.2166748046875, 0.525390625, 0.340087890625, 0.09912109375, 0.093505859375]
tgt code: rsp eax hexvar mov rbx
pred code: + rdi hexvar mov rbx
2021-10-11 05:28:14 | INFO | train_inner | {"epoch": 1, "update": 0.223, "loss": "2.315", "code_loss": "2.403", "value_loss_mse": "0.026", "code_ppl": "5.29", "wps": "18621.3", "ups": "0.07", "wpb": "248390", "bsz": "1024", "num_updates": "2760", "lr": "0.000138", "gnorm": "2.277", "loss_scale": "0.25", "train_wall": "17", "gb_free": "12.9", "wall": "35423"}
2021-10-11 05:30:25 | INFO | train_inner | {"epoch": 1, "update": 0.224, "loss": "2.274", "code_loss": "2.373", "value_loss_mse": "0.026", "code_ppl": "5.18", "wps": "18136.9", "ups": "0.08", "wpb": "237133", "bsz": "1024", "num_updates": "2770", "lr": "0.0001385", "gnorm": "2.568", "loss_scale": "0.25", "train_wall": "17", "gb_free": "12.9", "wall": "35554"}
2021-10-11 05:32:35 | INFO | train_inner | {"epoch": 1, "update": 0.225, "loss": "2.317", "code_loss": "2.416", "value_loss_mse": "0.026", "code_ppl": "5.34", "wps": "19459.6", "ups": "0.08", "wpb": "251875", "bsz": "1024", "num_updates": "2780", "lr": "0.000139", "gnorm": "2.441", "loss_scale": "0.25", "train_wall": "16", "gb_free": "12.9", "wall": "35683"}
2021-10-11 05:34:35 | INFO | train_inner | {"epoch": 1, "update": 0.226, "loss": "2.288", "code_loss": "2.398", "value_loss_mse": "0.026", "code_ppl": "5.27", "wps": "18396.3", "ups": "0.08", "wpb": "222262", "bsz": "1024", "num_updates": "2790", "lr": "0.0001395", "gnorm": "2.213", "loss_scale": "0.25", "train_wall": "15", "gb_free": "12.9", "wall": "35804"}
2021-10-11 05:36:53 | INFO | train_inner | {"epoch": 1, "update": 0.226, "loss": "2.284", "code_loss": "2.407", "value_loss_mse": "0.026", "code_ppl": "5.3", "wps": "18504.2", "ups": "0.07", "wpb": "254675", "bsz": "1024", "num_updates": "2800", "lr": "0.00014", "gnorm": "1.877", "loss_scale": "0.25", "train_wall": "17", "gb_free": "12.9", "wall": "35942"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.051666259765625, 0.046630859375, 0.001674652099609375, 0.0048675537109375, 0.059417724609375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.044921875, 0.05633544921875, 0.0015916824340820312, 0.006565093994140625, 0.06231689453125]
byte3 tgt value: [0.0, 0.0, 0.08203125, 0.49609375, 0.0]
byte3 pred value: [0.049774169921875, 0.08038330078125, 0.2459716796875, 0.306640625, 0.06280517578125]
byte4 tgt value: [0.0, 0.0, 0.80078125, 0.99609375, 0.0]
byte4 pred value: [0.0416259765625, 0.0987548828125, 0.70556640625, 0.611328125, 0.06732177734375]
byte5 tgt value: [0.0, 0.0, 0.75, 0.8984375, 0.0]
byte5 pred value: [0.0439453125, 0.11029052734375, 0.76708984375, 0.447021484375, 0.0635986328125]
byte6 tgt value: [0.0, 0.0, 0.96484375, 0.1328125, 0.0]
byte6 pred value: [0.04107666015625, 0.06671142578125, 0.826171875, 0.25634765625, 0.06951904296875]
byte7 tgt value: [0.0, 0.0, 0.98828125, 0.23828125, 0.0]
byte7 pred value: [0.0257568359375, 0.051666259765625, 0.62939453125, 0.390869140625, 0.06097412109375]
byte8 tgt value: [0.0, 0.0234375, 0.25, 0.03125, 0.09375]
byte8 pred value: [0.091064453125, 0.1044921875, 0.456787109375, 0.2054443359375, 0.11614990234375]
tgt code: mov mov hexvar rax +
pred code: mov mov hexvar hexvar +
2021-10-11 05:39:06 | INFO | train_inner | {"epoch": 1, "update": 0.227, "loss": "2.261", "code_loss": "2.387", "value_loss_mse": "0.025", "code_ppl": "5.23", "wps": "19185.1", "ups": "0.08", "wpb": "255270", "bsz": "1024", "num_updates": "2810", "lr": "0.0001405", "gnorm": "2.129", "loss_scale": "0.25", "train_wall": "17", "gb_free": "12.9", "wall": "36075"}
2021-10-11 05:41:14 | INFO | train_inner | {"epoch": 1, "update": 0.228, "loss": "2.279", "code_loss": "2.407", "value_loss_mse": "0.026", "code_ppl": "5.3", "wps": "19161.5", "ups": "0.08", "wpb": "244367", "bsz": "1024", "num_updates": "2820", "lr": "0.000141", "gnorm": "2.212", "loss_scale": "0.25", "train_wall": "16", "gb_free": "12.9", "wall": "36202"}
2021-10-11 05:43:30 | INFO | train_inner | {"epoch": 1, "update": 0.229, "loss": "2.244", "code_loss": "2.394", "value_loss_mse": "0.025", "code_ppl": "5.26", "wps": "18877.1", "ups": "0.07", "wpb": "257789", "bsz": "1024", "num_updates": "2830", "lr": "0.0001415", "gnorm": "2.244", "loss_scale": "0.25", "train_wall": "18", "gb_free": "12.9", "wall": "36339"}
2021-10-11 05:45:46 | INFO | train_inner | {"epoch": 1, "update": 0.23, "loss": "2.233", "code_loss": "2.383", "value_loss_mse": "0.025", "code_ppl": "5.22", "wps": "18393.8", "ups": "0.07", "wpb": "249242", "bsz": "1024", "num_updates": "2840", "lr": "0.000142", "gnorm": "1.91", "loss_scale": "0.25", "train_wall": "17", "gb_free": "12.9", "wall": "36474"}
2021-10-11 05:47:58 | INFO | train_inner | {"epoch": 1, "update": 0.23, "loss": "2.289", "code_loss": "2.401", "value_loss_mse": "0.026", "code_ppl": "5.28", "wps": "18226.5", "ups": "0.08", "wpb": "241238", "bsz": "1024", "num_updates": "2850", "lr": "0.0001425", "gnorm": "2.423", "loss_scale": "0.25", "train_wall": "17", "gb_free": "12.9", "wall": "36607"}
2021-10-11 05:49:55 | INFO | train_inner | {"epoch": 1, "update": 0.231, "loss": "2.248", "code_loss": "2.367", "value_loss_mse": "0.025", "code_ppl": "5.16", "wps": "19281.8", "ups": "0.09", "wpb": "224966", "bsz": "1024", "num_updates": "2860", "lr": "0.000143", "gnorm": "2.121", "loss_scale": "0.25", "train_wall": "16", "gb_free": "12.9", "wall": "36723"}
2021-10-11 05:52:09 | INFO | train_inner | {"epoch": 1, "update": 0.232, "loss": "2.258", "code_loss": "2.365", "value_loss_mse": "0.025", "code_ppl": "5.15", "wps": "17180.7", "ups": "0.07", "wpb": "230938", "bsz": "1024", "num_updates": "2870", "lr": "0.0001435", "gnorm": "2.098", "loss_scale": "0.25", "train_wall": "17", "gb_free": "12.9", "wall": "36858"}
2021-10-11 05:54:17 | INFO | train_inner | {"epoch": 1, "update": 0.233, "loss": "2.211", "code_loss": "2.371", "value_loss_mse": "0.025", "code_ppl": "5.17", "wps": "18397.1", "ups": "0.08", "wpb": "234503", "bsz": "1024", "num_updates": "2880", "lr": "0.000144", "gnorm": "1.971", "loss_scale": "0.25", "train_wall": "16", "gb_free": "12.9", "wall": "36985"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00841522216796875, 0.0028553009033203125, 0.00864410400390625, 0.05718994140625, 0.01525115966796875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.01142120361328125, 0.00313568115234375, 0.007904052734375, 0.07684326171875, 0.01332855224609375]
byte3 tgt value: [0.0, 0.4765625, 0.0, 0.0, 0.0]
byte3 pred value: [0.01312255859375, 0.439453125, 0.00841522216796875, 0.1134033203125, 0.097412109375]
byte4 tgt value: [0.0, 0.7265625, 0.0, 0.0, 0.0]
byte4 pred value: [0.023956298828125, 0.78857421875, 0.006877899169921875, 0.1270751953125, 0.1441650390625]
byte5 tgt value: [0.0, 0.8046875, 0.0, 0.0, 0.0]
byte5 pred value: [0.018341064453125, 0.81689453125, 0.006389617919921875, 0.1260986328125, 0.1412353515625]
byte6 tgt value: [0.0, 0.6015625, 0.0, 0.0, 0.0]
byte6 pred value: [0.0169830322265625, 0.525390625, 0.0057525634765625, 0.07421875, 0.1044921875]
byte7 tgt value: [0.0, 0.10546875, 0.0, 0.0, 0.0]
byte7 pred value: [0.015838623046875, 0.2474365234375, 0.00661468505859375, 0.06756591796875, 0.1610107421875]
byte8 tgt value: [0.125, 0.8125, 0.03125, 0.09375, 0.00390625]
byte8 pred value: [0.1463623046875, 0.46240234375, 0.0816650390625, 0.199951171875, 0.28955078125]
tgt code: eax call xor hexvar lea
pred code: edi xor xor hexvar lea
2021-10-11 05:56:25 | INFO | train_inner | {"epoch": 1, "update": 0.234, "loss": "2.245", "code_loss": "2.374", "value_loss_mse": "0.025", "code_ppl": "5.18", "wps": "18959.8", "ups": "0.08", "wpb": "244116", "bsz": "1024", "num_updates": "2890", "lr": "0.0001445", "gnorm": "2.591", "loss_scale": "0.25", "train_wall": "49", "gb_free": "13", "wall": "37114"}
2021-10-11 05:58:29 | INFO | train_inner | {"epoch": 1, "update": 0.234, "loss": "2.201", "code_loss": "2.38", "value_loss_mse": "0.025", "code_ppl": "5.21", "wps": "19790.1", "ups": "0.08", "wpb": "245052", "bsz": "1024", "num_updates": "2900", "lr": "0.000145", "gnorm": "2.288", "loss_scale": "0.25", "train_wall": "52", "gb_free": "12.9", "wall": "37238"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.765625]
byte1 pred value: [0.0029010772705078125, 0.018798828125, 0.0022258758544921875, 0.0035381317138671875, 0.119384765625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.234375]
byte2 pred value: [0.0029239654541015625, 0.0235137939453125, 0.002349853515625, 0.0063629150390625, 0.109130859375]
byte3 tgt value: [0.0, 0.0, 0.0, 0.09765625, 0.546875]
byte3 pred value: [0.0027904510498046875, 0.02423095703125, 0.0026836395263671875, 0.2073974609375, 0.1248779296875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.99609375, 0.859375]
byte4 pred value: [0.0026416778564453125, 0.03289794921875, 0.003040313720703125, 0.6650390625, 0.1680908203125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.4453125, 0.70703125]
byte5 pred value: [0.0030040740966796875, 0.033782958984375, 0.0028781890869140625, 0.56494140625, 0.2110595703125]
byte6 tgt value: [0.0, 0.0, 0.0, 0.28515625, 0.64453125]
byte6 pred value: [0.004314422607421875, 0.034698486328125, 0.00392913818359375, 0.223388671875, 0.2347412109375]
byte7 tgt value: [0.0, 0.0, 0.0, 0.00390625, 0.62109375]
byte7 pred value: [0.00679779052734375, 0.034027099609375, 0.0041351318359375, 0.369873046875, 0.255615234375]
byte8 tgt value: [0.00390625, 0.23828125, 0.65625, 0.125, 0.6328125]
byte8 pred value: [0.1187744140625, 0.131103515625, 0.1329345703125, 0.2313232421875, 0.2340087890625]
tgt code: rax rdi + ^8 ret
pred code: + rdi + ^8 mov
2021-10-11 06:00:40 | INFO | train_inner | {"epoch": 1, "update": 0.235, "loss": "2.239", "code_loss": "2.392", "value_loss_mse": "0.025", "code_ppl": "5.25", "wps": "18388.2", "ups": "0.08", "wpb": "239900", "bsz": "1024", "num_updates": "2910", "lr": "0.0001455", "gnorm": "2.192", "loss_scale": "0.25", "train_wall": "17", "gb_free": "12.9", "wall": "37368"}
2021-10-11 06:02:50 | INFO | train_inner | {"epoch": 1, "update": 0.236, "loss": "2.227", "code_loss": "2.362", "value_loss_mse": "0.025", "code_ppl": "5.14", "wps": "19720.3", "ups": "0.08", "wpb": "256272", "bsz": "1024", "num_updates": "2920", "lr": "0.000146", "gnorm": "2.053", "loss_scale": "0.25", "train_wall": "24", "gb_free": "12.9", "wall": "37498"}
2021-10-11 06:04:54 | INFO | train_inner | {"epoch": 1, "update": 0.237, "loss": "2.259", "code_loss": "2.374", "value_loss_mse": "0.025", "code_ppl": "5.18", "wps": "18219.6", "ups": "0.08", "wpb": "226308", "bsz": "1024", "num_updates": "2930", "lr": "0.0001465", "gnorm": "2.099", "loss_scale": "0.25", "train_wall": "51", "gb_free": "12.9", "wall": "37623"}
2021-10-11 06:07:01 | INFO | train_inner | {"epoch": 1, "update": 0.238, "loss": "2.246", "code_loss": "2.36", "value_loss_mse": "0.025", "code_ppl": "5.13", "wps": "18865.7", "ups": "0.08", "wpb": "239488", "bsz": "1024", "num_updates": "2940", "lr": "0.000147", "gnorm": "2.23", "loss_scale": "0.25", "train_wall": "89", "gb_free": "12.9", "wall": "37749"}
2021-10-11 06:09:08 | INFO | train_inner | {"epoch": 1, "update": 0.238, "loss": "2.179", "code_loss": "2.331", "value_loss_mse": "0.024", "code_ppl": "5.03", "wps": "19144.4", "ups": "0.08", "wpb": "244131", "bsz": "1024", "num_updates": "2950", "lr": "0.0001475", "gnorm": "2.33", "loss_scale": "0.25", "train_wall": "75", "gb_free": "12.9", "wall": "37877"}
2021-10-11 06:11:13 | INFO | train_inner | {"epoch": 1, "update": 0.239, "loss": "2.237", "code_loss": "2.356", "value_loss_mse": "0.025", "code_ppl": "5.12", "wps": "18763.2", "ups": "0.08", "wpb": "233139", "bsz": "1024", "num_updates": "2960", "lr": "0.000148", "gnorm": "2.286", "loss_scale": "0.25", "train_wall": "43", "gb_free": "12.9", "wall": "38001"}
2021-10-11 06:13:22 | INFO | train_inner | {"epoch": 1, "update": 0.24, "loss": "2.223", "code_loss": "2.362", "value_loss_mse": "0.025", "code_ppl": "5.14", "wps": "19091.6", "ups": "0.08", "wpb": "247635", "bsz": "1024", "num_updates": "2970", "lr": "0.0001485", "gnorm": "2.04", "loss_scale": "0.25", "train_wall": "17", "gb_free": "12.9", "wall": "38131"}
2021-10-11 06:15:27 | INFO | train_inner | {"epoch": 1, "update": 0.241, "loss": "2.224", "code_loss": "2.345", "value_loss_mse": "0.025", "code_ppl": "5.08", "wps": "18750.4", "ups": "0.08", "wpb": "233523", "bsz": "1024", "num_updates": "2980", "lr": "0.000149", "gnorm": "2.219", "loss_scale": "0.25", "train_wall": "16", "gb_free": "12.9", "wall": "38255"}
2021-10-11 06:17:36 | INFO | train_inner | {"epoch": 1, "update": 0.242, "loss": "2.185", "code_loss": "2.354", "value_loss_mse": "0.024", "code_ppl": "5.11", "wps": "18911.6", "ups": "0.08", "wpb": "245172", "bsz": "1024", "num_updates": "2990", "lr": "0.0001495", "gnorm": "2.15", "loss_scale": "0.25", "train_wall": "16", "gb_free": "12.9", "wall": "38385"}
2021-10-11 06:19:34 | INFO | train_inner | {"epoch": 1, "update": 0.242, "loss": "2.224", "code_loss": "2.342", "value_loss_mse": "0.025", "code_ppl": "5.07", "wps": "18898.9", "ups": "0.09", "wpb": "221578", "bsz": "1024", "num_updates": "3000", "lr": "0.00015", "gnorm": "2.189", "loss_scale": "0.25", "train_wall": "15", "gb_free": "12.9", "wall": "38502"}
2021-10-11 06:21:37 | INFO | train_inner | {"epoch": 1, "update": 0.243, "loss": "2.223", "code_loss": "2.314", "value_loss_mse": "0.025", "code_ppl": "4.97", "wps": "18594.1", "ups": "0.08", "wpb": "229075", "bsz": "1024", "num_updates": "3010", "lr": "0.0001505", "gnorm": "2.619", "loss_scale": "0.25", "train_wall": "16", "gb_free": "12.9", "wall": "38626"}
2021-10-11 06:23:34 | INFO | train_inner | {"epoch": 1, "update": 0.244, "loss": "2.134", "code_loss": "2.313", "value_loss_mse": "0.024", "code_ppl": "4.97", "wps": "18365.9", "ups": "0.09", "wpb": "215894", "bsz": "1024", "num_updates": "3020", "lr": "0.000151", "gnorm": "2.423", "loss_scale": "0.25", "train_wall": "17", "gb_free": "12.9", "wall": "38743"}
2021-10-11 06:25:41 | INFO | train_inner | {"epoch": 1, "update": 0.245, "loss": "2.243", "code_loss": "2.357", "value_loss_mse": "0.025", "code_ppl": "5.12", "wps": "18663.3", "ups": "0.08", "wpb": "236339", "bsz": "1024", "num_updates": "3030", "lr": "0.0001515", "gnorm": "2.495", "loss_scale": "0.25", "train_wall": "16", "gb_free": "12.9", "wall": "38870"}

byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0011920928955078125, 0.0015611648559570312, 0.0031719207763671875, 0.005706787109375, 0.00464630126953125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0013885498046875, 0.0014896392822265625, 0.0022258758544921875, 0.0053863525390625, 0.0041656494140625]
byte3 tgt value: [0.0, 0.0, 0.0859375, 0.0, 0.49609375]
byte3 pred value: [0.0025501251220703125, 0.0032596588134765625, 0.304443359375, 0.1131591796875, 0.1607666015625]
byte4 tgt value: [0.0, 0.0, 0.9609375, 0.0, 0.99609375]
byte4 pred value: [0.00464630126953125, 0.005687713623046875, 0.72998046875, 0.2393798828125, 0.352294921875]
byte5 tgt value: [0.0, 0.0, 0.8203125, 0.0, 0.81640625]
byte5 pred value: [0.004180908203125, 0.005260467529296875, 0.744140625, 0.265380859375, 0.378173828125]
byte6 tgt value: [0.0, 0.0, 0.76171875, 0.0, 0.21484375]
byte6 pred value: [0.004116058349609375, 0.00536346435546875, 0.79296875, 0.2452392578125, 0.3486328125]
byte7 tgt value: [0.0, 0.0, 0.26171875, 0.0, 0.421875]
byte7 pred value: [0.00453948974609375, 0.00731658935546875, 0.4287109375, 0.1842041015625, 0.22802734375]
byte8 tgt value: [0.03515625, 0.234375, 0.75, 0.21875, 0.90625]
byte8 pred value: [0.1414794921875, 0.1353759765625, 0.5078125, 0.29638671875, 0.3505859375]
tgt code: jbe hexvar eax jne rip
pred code: mov hexvar eax jne +
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.004772186279296875, 0.0024051666259765625, 0.025909423828125, 0.0007700920104980469, 0.0008134841918945312]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00359344482421875, 0.0024242401123046875, 0.021453857421875, 0.0006289482116699219, 0.0006961822509765625]
byte3 tgt value: [0.0, 0.0, 0.0, 0.38671875, 0.0]
byte3 pred value: [0.00323486328125, 0.0240936279296875, 0.0224151611328125, 0.029876708984375, 0.0341796875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.078125, 0.0]
byte4 pred value: [0.00319671630859375, 0.01678466796875, 0.0226287841796875, 0.0119171142578125, 0.018829345703125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.25, 0.0]
byte5 pred value: [0.0066680908203125, 0.0193023681640625, 0.028106689453125, 0.0205230712890625, 0.022979736328125]
byte6 tgt value: [0.0, 0.0, 0.0, 0.421875, 0.0]
byte6 pred value: [0.0106964111328125, 0.02880859375, 0.0310821533203125, 0.040985107421875, 0.04351806640625]
byte7 tgt value: [0.0, 0.0, 0.0, 0.1171875, 0.453125]
byte7 pred value: [0.00800323486328125, 0.040374755859375, 0.036285400390625, 0.40576171875, 0.4306640625]
byte8 tgt value: [0.0, 0.2109375, 0.00390625, 0.09765625, 0.6875]
byte8 pred value: [0.036773681640625, 0.1666259765625, 0.06719970703125, 0.457763671875, 0.43359375]
tgt code: r13 rax sub lea +
pred code: rbp rsi mov mov +
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00254058837890625, 0.0026531219482421875, 0.0027370452880859375, 0.0017004013061523438, 0.012481689453125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0014553070068359375, 0.0020198822021484375, 0.0021820068359375, 0.0015363693237304688, 0.0121917724609375]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.33984375]
byte3 pred value: [0.0070648193359375, 0.07159423828125, 0.0038242340087890625, 0.0033111572265625, 0.2054443359375]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.1796875]
byte4 pred value: [0.0035800933837890625, 0.05145263671875, 0.0035114288330078125, 0.0027675628662109375, 0.07421875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.35546875]
byte5 pred value: [0.0115966796875, 0.1259765625, 0.00482940673828125, 0.004520416259765625, 0.3330078125]
byte6 tgt value: [0.01953125, 0.0, 0.0, 0.0, 0.22265625]
byte6 pred value: [0.0266571044921875, 0.05072021484375, 0.005100250244140625, 0.00511932373046875, 0.1217041015625]
byte7 tgt value: [0.93359375, 0.0, 0.0, 0.0, 0.63671875]
byte7 pred value: [0.90185546875, 0.0701904296875, 0.00609588623046875, 0.006412506103515625, 0.1873779296875]
byte8 tgt value: [0.19921875, 0.16015625, 0.15625, 0.15625, 0.0625]
byte8 pred value: [0.666015625, 0.28466796875, 0.10302734375, 0.10540771484375, 0.1982421875]
tgt code: jne hexvar hexvar rdi rbx
pred code: mov hexvar hexvar rdi rbx
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0020198822021484375, 0.0027141571044921875, 0.003040313720703125, 0.0016107559204101562, 0.00844573974609375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.003223419189453125, 0.0034694671630859375, 0.004848480224609375, 0.0016164779663085938, 0.00841522216796875]
byte3 tgt value: [0.49609375, 0.0, 0.49609375, 0.0, 0.0]
byte3 pred value: [0.5, 0.006587982177734375, 0.5087890625, 0.004215240478515625, 0.0154876708984375]
byte4 tgt value: [0.99609375, 0.0, 0.99609375, 0.0, 0.0]
byte4 pred value: [0.9775390625, 0.00714874267578125, 0.98193359375, 0.003429412841796875, 0.0180511474609375]
byte5 tgt value: [0.9921875, 0.0, 0.9921875, 0.0, 0.0]
byte5 pred value: [0.85205078125, 0.01467132568359375, 0.85498046875, 0.12249755859375, 0.0701904296875]
byte6 tgt value: [0.8125, 0.0, 0.8125, 0.0, 0.0]
byte6 pred value: [0.80126953125, 0.01238250732421875, 0.80615234375, 0.100341796875, 0.063720703125]
byte7 tgt value: [0.296875, 0.0, 0.296875, 0.0, 0.0]
byte7 pred value: [0.791015625, 0.02630615234375, 0.77685546875, 0.11181640625, 0.07989501953125]
byte8 tgt value: [0.90625, 0.21875, 0.90625, 0.0625, 0.34765625]
byte8 pred value: [0.84912109375, 0.092529296875, 0.8515625, 0.15478515625, 0.091064453125]
tgt code: r11d rax eax ^4 -
pred code: esi hexvar eax ^4 +
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0020275115966796875, 0.007755279541015625, 0.0009474754333496094, 0.0022430419921875, 0.001987457275390625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0029926300048828125, 0.0110321044921875, 0.0010728836059570312, 0.003185272216796875, 0.0029239654541015625]
byte3 tgt value: [0.49609375, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.33642578125, 0.01473236083984375, 0.001934051513671875, 0.0100555419921875, 0.00787353515625]
byte4 tgt value: [0.21875, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.182373046875, 0.0211639404296875, 0.001956939697265625, 0.01214599609375, 0.00989532470703125]
byte5 tgt value: [0.94921875, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.67138671875, 0.11920166015625, 0.1715087890625, 0.07720947265625, 0.0634765625]
byte6 tgt value: [0.49609375, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.7705078125, 0.1268310546875, 0.1829833984375, 0.061767578125, 0.050048828125]
byte7 tgt value: [0.8359375, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.6904296875, 0.1646728515625, 0.158447265625, 0.0867919921875, 0.06549072265625]
byte8 tgt value: [0.26171875, 0.17578125, 0.08203125, 0.0, 0.17578125]
byte8 pred value: [0.306640625, 0.237548828125, 0.2301025390625, 0.142333984375, 0.13037109375]
tgt code: eax rdx je edx al
pred code: eax rax je hexvar hexvar
byte1 tgt value: [0.84375, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.60400390625, 0.00263214111328125, 0.0016164779663085938, 0.00787353515625, 0.0008726119995117188]
byte2 tgt value: [0.640625, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.59326171875, 0.0029468536376953125, 0.00206756591796875, 0.00891876220703125, 0.0009660720825195312]
byte3 tgt value: [0.109375, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.51708984375, 0.1497802734375, 0.002834320068359375, 0.0119171142578125, 0.0022430419921875]
byte4 tgt value: [0.76953125, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.41259765625, 0.148193359375, 0.0018463134765625, 0.01146697998046875, 0.002414703369140625]
byte5 tgt value: [0.43359375, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.470947265625, 0.2410888671875, 0.005039215087890625, 0.014556884765625, 0.0031108856201171875]
byte6 tgt value: [0.375, 0.00390625, 0.0, 0.0, 0.0]
byte6 pred value: [0.492431640625, 0.294921875, 0.00621795654296875, 0.0121002197265625, 0.0041351318359375]
byte7 tgt value: [0.01171875, 0.02734375, 0.0, 0.0, 0.0]
byte7 pred value: [0.47216796875, 0.435302734375, 0.0237274169921875, 0.0106964111328125, 0.00971221923828125]
byte8 tgt value: [0.58203125, 0.25, 0.00390625, 0.015625, 0.125]
byte8 pred value: 2021-10-11 06:27:44 | INFO | train_inner | {"epoch": 1, "update": 0.246, "loss": "2.186", "code_loss": "2.332", "value_loss_mse": "0.024", "code_ppl": "5.03", "wps": "19277.7", "ups": "0.08", "wpb": "237208", "bsz": "1024", "num_updates": "3040", "lr": "0.000152", "gnorm": "2.283", "loss_scale": "0.25", "train_wall": "15", "gb_free": "12.9", "wall": "38993"}
2021-10-11 06:29:46 | INFO | train_inner | {"epoch": 1, "update": 0.246, "loss": "2.23", "code_loss": "2.331", "value_loss_mse": "0.025", "code_ppl": "5.03", "wps": "18161.5", "ups": "0.08", "wpb": "222000", "bsz": "1024", "num_updates": "3050", "lr": "0.0001525", "gnorm": "2.769", "loss_scale": "0.25", "train_wall": "15", "gb_free": "12.9", "wall": "39115"}
2021-10-11 06:31:54 | INFO | train_inner | {"epoch": 1, "update": 0.247, "loss": "2.221", "code_loss": "2.324", "value_loss_mse": "0.025", "code_ppl": "5.01", "wps": "19277.6", "ups": "0.08", "wpb": "246442", "bsz": "1024", "num_updates": "3060", "lr": "0.000153", "gnorm": "2.441", "loss_scale": "0.25", "train_wall": "16", "gb_free": "12.9", "wall": "39243"}
2021-10-11 06:34:00 | INFO | train_inner | {"epoch": 1, "update": 0.248, "loss": "2.159", "code_loss": "2.3", "value_loss_mse": "0.024", "code_ppl": "4.92", "wps": "18883.5", "ups": "0.08", "wpb": "237338", "bsz": "1024", "num_updates": "3070", "lr": "0.0001535", "gnorm": "2.293", "loss_scale": "0.25", "train_wall": "21", "gb_free": "12.9", "wall": "39369"}
2021-10-11 06:36:09 | INFO | train_inner | {"epoch": 1, "update": 0.249, "loss": "2.172", "code_loss": "2.303", "value_loss_mse": "0.024", "code_ppl": "4.94", "wps": "18939.4", "ups": "0.08", "wpb": "244860", "bsz": "1024", "num_updates": "3080", "lr": "0.000154", "gnorm": "2.397", "loss_scale": "0.5", "train_wall": "26", "gb_free": "12.9", "wall": "39498"}
2021-10-11 06:38:10 | INFO | train_inner | {"epoch": 1, "update": 0.25, "loss": "2.185", "code_loss": "2.292", "value_loss_mse": "0.024", "code_ppl": "4.9", "wps": "18978.9", "ups": "0.08", "wpb": "229301", "bsz": "1024", "num_updates": "3090", "lr": "0.0001545", "gnorm": "2.368", "loss_scale": "0.5", "train_wall": "18", "gb_free": "12.9", "wall": "39619"}
2021-10-11 06:40:19 | INFO | train_inner | {"epoch": 1, "update": 0.25, "loss": "2.168", "code_loss": "2.299", "value_loss_mse": "0.024", "code_ppl": "4.92", "wps": "19200.2", "ups": "0.08", "wpb": "248662", "bsz": "1024", "num_updates": "3100", "lr": "0.000155", "gnorm": "2.291", "loss_scale": "0.5", "train_wall": "56", "gb_free": "12.9", "wall": "39748"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00469970703125, 0.007694244384765625, 0.01422882080078125, 0.0007410049438476562, 0.0235137939453125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.005100250244140625, 0.00916290283203125, 0.0115509033203125, 0.0015916824340820312, 0.0282745361328125]
byte3 tgt value: [0.0, 0.09765625, 0.0, 0.0, 0.09765625]
byte3 pred value: [0.04083251953125, 0.262939453125, 0.07147216796875, 0.002811431884765625, 0.06683349609375]
byte4 tgt value: [0.0, 0.40234375, 0.0, 0.0, 0.40234375]
byte4 pred value: [0.091552734375, 0.46337890625, 0.1195068359375, 0.00359344482421875, 0.08270263671875]
byte5 tgt value: [0.0, 0.7578125, 0.0, 0.0, 0.7578125]
byte5 pred value: [0.09893798828125, 0.60498046875, 0.09857177734375, 0.0028896331787109375, 0.05499267578125]
byte6 tgt value: [0.0, 0.94140625, 0.0, 0.0, 0.94140625]
byte6 pred value: [0.116943359375, 0.84521484375, 0.1273193359375, 0.006824493408203125, 0.06829833984375]
byte7 tgt value: [0.0, 0.12890625, 0.0, 0.1796875, 0.1953125]
byte7 pred value: [0.1826171875, 0.0953369140625, 0.0699462890625, 0.110107421875, 0.07989501953125]
byte8 tgt value: [0.08984375, 0.1171875, 0.1796875, 0.80078125, 0.125]
byte8 pred value: [0.37939453125, 0.3564453125, 0.16259765625, 0.353515625, 0.1380615234375]
tgt code: - hexvar ebx r13d lea
pred code: + + hexvar hexvar mov
2021-10-11 06:42:38 | INFO | train_inner | {"epoch": 1, "update": 0.251, "loss": "2.169", "code_loss": "2.311", "value_loss_mse": "0.024", "code_ppl": "4.96", "wps": "18857.8", "ups": "0.07", "wpb": "260986", "bsz": "1024", "num_updates": "3110", "lr": "0.0001555", "gnorm": "2.357", "loss_scale": "0.5", "train_wall": "91", "gb_free": "12.9", "wall": "39887"}
2021-10-11 06:44:48 | INFO | train_inner | {"epoch": 1, "update": 0.252, "loss": "2.086", "code_loss": "2.276", "value_loss_mse": "0.023", "code_ppl": "4.84", "wps": "19012.4", "ups": "0.08", "wpb": "246707", "bsz": "1024", "num_updates": "3120", "lr": "0.000156", "gnorm": "2.393", "loss_scale": "0.5", "train_wall": "84", "gb_free": "12.9", "wall": "40016"}
2021-10-11 06:46:43 | INFO | train_inner | {"epoch": 1, "update": 0.253, "loss": "2.133", "code_loss": "2.281", "value_loss_mse": "0.024", "code_ppl": "4.86", "wps": "18915.1", "ups": "0.09", "wpb": "219014", "bsz": "1024", "num_updates": "3130", "lr": "0.0001565", "gnorm": "2.284", "loss_scale": "0.5", "train_wall": "49", "gb_free": "12.9", "wall": "40132"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0007014274597167969, 0.0012693405151367188, 0.005641937255859375, 0.001220703125, 0.0009112358093261719]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0007467269897460938, 0.0012645721435546875, 0.003551483154296875, 0.0008692741394042969, 0.0008525848388671875]
byte3 tgt value: [0.0, 0.0, 0.265625, 0.0, 0.0]
byte3 pred value: [0.0012063980102539062, 0.0213623046875, 0.219970703125, 0.09686279296875, 0.0012111663818359375]
byte4 tgt value: [0.0, 0.0, 0.171875, 0.0, 0.0]
byte4 pred value: [0.0009660720825195312, 0.022369384765625, 0.13671875, 0.07464599609375, 0.0011739730834960938]
byte5 tgt value: [0.0, 0.0, 0.62890625, 0.0, 0.0]
byte5 pred value: [0.00646209716796875, 0.03131103515625, 0.6064453125, 0.1619873046875, 0.0018463134765625]
byte6 tgt value: [0.0, 0.0, 0.15234375, 0.00390625, 0.0]
byte6 pred value: [0.006072998046875, 0.0165863037109375, 0.10595703125, 0.061309814453125, 0.0038547515869140625]
byte7 tgt value: [0.0, 0.0, 0.359375, 0.7734375, 0.0]
byte7 pred value: [0.0102081298828125, 0.04803466796875, 0.475341796875, 0.6708984375, 0.04595947265625]
byte8 tgt value: [0.0, 0.1953125, 0.125, 0.09375, 0.5625]
byte8 pred value: [0.1044921875, 0.249755859375, 0.294921875, 0.54345703125, 0.23974609375]
tgt code: test rsp lea + mov
pred code: mov rsp mov + mov
2021-10-11 06:48:51 | INFO | train_inner | {"epoch": 1, "update": 0.254, "loss": "2.124", "code_loss": "2.285", "value_loss_mse": "0.024", "code_ppl": "4.87", "wps": "19013.1", "ups": "0.08", "wpb": "242753", "bsz": "1024", "num_updates": "3140", "lr": "0.000157", "gnorm": "2.743", "loss_scale": "0.5", "train_wall": "16", "gb_free": "12.9", "wall": "40260"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.006122589111328125, 0.001995086669921875, 0.005100250244140625, 0.0119171142578125, 0.002590179443359375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.007175445556640625, 0.00269317626953125, 0.004398345947265625, 0.009521484375, 0.0026836395263671875]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.49609375]
byte3 pred value: [0.004848480224609375, 0.0021572113037109375, 0.006511688232421875, 0.0094146728515625, 0.492919921875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.99609375]
byte4 pred value: [0.00453948974609375, 0.0016813278198242188, 0.0062408447265625, 0.00867462158203125, 0.98291015625]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.6953125]
byte5 pred value: [0.005428314208984375, 0.002010345458984375, 0.007843017578125, 0.0102081298828125, 0.7880859375]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.6875]
byte6 pred value: [0.00498199462890625, 0.00257110595703125, 0.00841522216796875, 0.00916290283203125, 0.57421875]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.05078125]
byte7 pred value: [0.007518768310546875, 0.006488800048828125, 0.00821685791015625, 0.015716552734375, 0.261474609375]
byte8 tgt value: [0.0546875, 0.0625, 0.0546875, 0.0546875, 0.125]
byte8 pred value: [0.0869140625, 0.049774169921875, 0.083740234375, 0.09234619140625, 0.0880126953125]
tgt code: xor add + push
pred code: test add + mov
2021-10-11 06:50:52 | INFO | train_inner | {"epoch": 1, "update": 0.254, "loss": "2.128", "code_loss": "2.261", "value_loss_mse": "0.024", "code_ppl": "4.79", "wps": "18210", "ups": "0.08", "wpb": "219498", "bsz": "1024", "num_updates": "3150", "lr": "0.0001575", "gnorm": "2.461", "loss_scale": "0.5", "train_wall": "61", "gb_free": "12.9", "wall": "40380"}
2021-10-11 06:53:00 | INFO | train_inner | {"epoch": 1, "update": 0.255, "loss": "2.132", "code_loss": "2.282", "value_loss_mse": "0.024", "code_ppl": "4.86", "wps": "18103.8", "ups": "0.08", "wpb": "232022", "bsz": "1024", "num_updates": "3160", "lr": "0.000158", "gnorm": "2.468", "loss_scale": "0.5", "train_wall": "97", "gb_free": "12.9", "wall": "40509"}
2021-10-11 06:55:02 | INFO | train_inner | {"epoch": 1, "update": 0.256, "loss": "2.151", "code_loss": "2.265", "value_loss_mse": "0.024", "code_ppl": "4.81", "wps": "19164.7", "ups": "0.08", "wpb": "234970", "bsz": "1024", "num_updates": "3170", "lr": "0.0001585", "gnorm": "2.485", "loss_scale": "0.5", "train_wall": "28", "gb_free": "12.9", "wall": "40631"}
2021-10-11 06:57:13 | INFO | train_inner | {"epoch": 1, "update": 0.257, "loss": "2.137", "code_loss": "2.3", "value_loss_mse": "0.024", "code_ppl": "4.92", "wps": "18389.5", "ups": "0.08", "wpb": "239504", "bsz": "1024", "num_updates": "3180", "lr": "0.000159", "gnorm": "2.54", "loss_scale": "0.5", "train_wall": "55", "gb_free": "13.9", "wall": "40761"}
2021-10-11 06:59:19 | INFO | train_inner | {"epoch": 1, "update": 0.258, "loss": "2.117", "code_loss": "2.262", "value_loss_mse": "0.024", "code_ppl": "4.8", "wps": "19588.7", "ups": "0.08", "wpb": "247264", "bsz": "1024", "num_updates": "3190", "lr": "0.0001595", "gnorm": "2.053", "loss_scale": "0.5", "train_wall": "49", "gb_free": "12.9", "wall": "40888"}
2021-10-11 07:01:34 | INFO | train_inner | {"epoch": 1, "update": 0.259, "loss": "2.113", "code_loss": "2.254", "value_loss_mse": "0.024", "code_ppl": "4.77", "wps": "18417.5", "ups": "0.07", "wpb": "248938", "bsz": "1024", "num_updates": "3200", "lr": "0.00016", "gnorm": "2.165", "loss_scale": "0.5", "train_wall": "21", "gb_free": "12.9", "wall": "41023"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0018606185913085938, 0.005405426025390625, 0.0024623870849609375, 0.00498199462890625, 0.00894927978515625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0017547607421875, 0.004962921142578125, 0.0018892288208007812, 0.004383087158203125, 0.00861358642578125]
byte3 tgt value: [0.0, 0.49609375, 0.0, 0.0, 0.2578125]
byte3 pred value: [0.0013780593872070312, 0.5361328125, 0.006412506103515625, 0.004665374755859375, 0.330810546875]
byte4 tgt value: [0.0, 0.99609375, 0.0, 0.0, 0.3828125]
byte4 pred value: [0.0018529891967773438, 0.98779296875, 0.0016870498657226562, 0.0037212371826171875, 0.337646484375]
byte5 tgt value: [0.0, 0.96484375, 0.0, 0.0, 0.34375]
byte5 pred value: [0.0018606185913085938, 0.849609375, 0.0083160400390625, 0.003063201904296875, 0.347900390625]
byte6 tgt value: [0.0, 0.1796875, 0.0625, 0.0, 0.859375]
byte6 pred value: [0.0018310546875, 0.2462158203125, 0.0232391357421875, 0.0037078857421875, 0.78662109375]
byte7 tgt value: [0.0, 0.67578125, 0.375, 0.0, 0.5703125]
byte7 pred value: [0.00572967529296875, 0.8349609375, 0.301513671875, 0.003429412841796875, 0.487548828125]
byte8 tgt value: [0.125, 0.125, 0.05078125, 0.03125, 0.375]
byte8 pred value: [0.08154296875, 0.1041259765625, 0.0855712890625, 0.050506591796875, 0.4453125]
tgt code: ^8 rax mov rax ^8
pred code: ^8 rax mov hexvar ^8
2021-10-11 07:03:36 | INFO | train_inner | {"epoch": 1, "update": 0.259, "loss": "2.104", "code_loss": "2.258", "value_loss_mse": "0.023", "code_ppl": "4.78", "wps": "19606.3", "ups": "0.08", "wpb": "238883", "bsz": "1024", "num_updates": "3210", "lr": "0.0001605", "gnorm": "2.385", "loss_scale": "0.5", "train_wall": "15", "gb_free": "12.9", "wall": "41145"}
2021-10-11 07:05:40 | INFO | train_inner | {"epoch": 1, "update": 0.26, "loss": "2.109", "code_loss": "2.258", "value_loss_mse": "0.024", "code_ppl": "4.78", "wps": "18934.4", "ups": "0.08", "wpb": "234966", "bsz": "1024", "num_updates": "3220", "lr": "0.000161", "gnorm": "2.921", "loss_scale": "0.5", "train_wall": "23", "gb_free": "12.9", "wall": "41269"}
2021-10-11 07:07:55 | INFO | train_inner | {"epoch": 1, "update": 0.261, "loss": "2.157", "code_loss": "2.289", "value_loss_mse": "0.024", "code_ppl": "4.89", "wps": "18138", "ups": "0.07", "wpb": "245622", "bsz": "1024", "num_updates": "3230", "lr": "0.0001615", "gnorm": "2.41", "loss_scale": "0.5", "train_wall": "77", "gb_free": "12.9", "wall": "41404"}
2021-10-11 07:10:01 | INFO | train_inner | {"epoch": 1, "update": 0.262, "loss": "2.129", "code_loss": "2.254", "value_loss_mse": "0.024", "code_ppl": "4.77", "wps": "18807.7", "ups": "0.08", "wpb": "235603", "bsz": "1024", "num_updates": "3240", "lr": "0.000162", "gnorm": "2.298", "loss_scale": "0.5", "train_wall": "48", "gb_free": "12.9", "wall": "41529"}
2021-10-11 07:12:06 | INFO | train_inner | {"epoch": 1, "update": 0.263, "loss": "2.151", "code_loss": "2.261", "value_loss_mse": "0.024", "code_ppl": "4.79", "wps": "18366.3", "ups": "0.08", "wpb": "230086", "bsz": "1024", "num_updates": "3250", "lr": "0.0001625", "gnorm": "2.385", "loss_scale": "0.5", "train_wall": "39", "gb_free": "12.9", "wall": "41655"}
2021-10-11 07:14:17 | INFO | train_inner | {"epoch": 1, "update": 0.263, "loss": "2.11", "code_loss": "2.243", "value_loss_mse": "0.024", "code_ppl": "4.74", "wps": "17931.4", "ups": "0.08", "wpb": "234333", "bsz": "1024", "num_updates": "3260", "lr": "0.000163", "gnorm": "1.945", "loss_scale": "0.5", "train_wall": "17", "gb_free": "12.9", "wall": "41785"}
2021-10-11 07:16:23 | INFO | train_inner | {"epoch": 1, "update": 0.264, "loss": "2.072", "code_loss": "2.241", "value_loss_mse": "0.023", "code_ppl": "4.73", "wps": "19059.9", "ups": "0.08", "wpb": "241069", "bsz": "1024", "num_updates": "3270", "lr": "0.0001635", "gnorm": "2.45", "loss_scale": "0.5", "train_wall": "16", "gb_free": "12.9", "wall": "41912"}
2021-10-11 07:18:28 | INFO | train_inner | {"epoch": 1, "update": 0.265, "loss": "2.049", "code_loss": "2.227", "value_loss_mse": "0.023", "code_ppl": "4.68", "wps": "18859.4", "ups": "0.08", "wpb": "236212", "bsz": "1024", "num_updates": "3280", "lr": "0.000164", "gnorm": "2.14", "loss_scale": "0.5", "train_wall": "19", "gb_free": "12.9", "wall": "42037"}
2021-10-11 07:20:24 | INFO | train_inner | {"epoch": 1, "update": 0.266, "loss": "2.089", "code_loss": "2.2", "value_loss_mse": "0.023", "code_ppl": "4.59", "wps": "18638.2", "ups": "0.09", "wpb": "216256", "bsz": "1024", "num_updates": "3290", "lr": "0.0001645", "gnorm": "2.496", "loss_scale": "0.5", "train_wall": "24", "gb_free": "12.9", "wall": "42153"}
2021-10-11 07:22:39 | INFO | train_inner | {"epoch": 1, "update": 0.267, "loss": "2.121", "code_loss": "2.229", "value_loss_mse": "0.024", "code_ppl": "4.69", "wps": "18843.1", "ups": "0.07", "wpb": "253312", "bsz": "1024", "num_updates": "3300", "lr": "0.000165", "gnorm": "2.418", "loss_scale": "0.5", "train_wall": "70", "gb_free": "12.9", "wall": "42288"}
2021-10-11 07:24:47 | INFO | train_inner | {"epoch": 1, "update": 0.267, "loss": "2.093", "code_loss": "2.239", "value_loss_mse": "0.023", "code_ppl": "4.72", "wps": "18841.4", "ups": "0.08", "wpb": "240602", "bsz": "1024", "num_updates": "3310", "lr": "0.0001655", "gnorm": "2.804", "loss_scale": "0.5", "train_wall": "68", "gb_free": "12.9", "wall": "42415"}
2021-10-11 07:26:58 | INFO | train_inner | {"epoch": 1, "update": 0.268, "loss": "2.099", "code_loss": "2.223", "value_loss_mse": "0.023", "code_ppl": "4.67", "wps": "18434", "ups": "0.08", "wpb": "242385", "bsz": "1024", "num_updates": "3320", "lr": "0.000166", "gnorm": "2.469", "loss_scale": "0.5", "train_wall": "108", "gb_free": "12.9", "wall": "42547"}
2021-10-11 07:29:06 | INFO | train_inner | {"epoch": 1, "update": 0.269, "loss": "2.087", "code_loss": "2.235", "value_loss_mse": "0.023", "code_ppl": "4.71", "wps": "19175.3", "ups": "0.08", "wpb": "245690", "bsz": "1024", "num_updates": "3330", "lr": "0.0001665", "gnorm": "2.309", "loss_scale": "0.5", "train_wall": "49", "gb_free": "12.9", "wall": "42675"}
2021-10-11 07:31:09 | INFO | train_inner | {"epoch": 1, "update": 0.27, "loss": "2.091", "code_loss": "2.201", "value_loss_mse": "0.023", "code_ppl": "4.6", "wps": "18910", "ups": "0.08", "wpb": "232027", "bsz": "1024", "num_updates": "3340", "lr": "0.000167", "gnorm": "2.15", "loss_scale": "0.5", "train_wall": "68", "gb_free": "12.9", "wall": "42798"}
2021-10-11 07:33:13 | INFO | train_inner | {"epoch": 1, "update": 0.271, "loss": "2.078", "code_loss": "2.2", "value_loss_mse": "0.023", "code_ppl": "4.6", "wps": "18649.7", "ups": "0.08", "wpb": "230749", "bsz": "1024", "num_updates": "3350", "lr": "0.0001675", "gnorm": "2.53", "loss_scale": "0.5", "train_wall": "21", "gb_free": "12.9", "wall": "42921"}
2021-10-11 07:35:13 | INFO | train_inner | {"epoch": 1, "update": 0.271, "loss": "2.062", "code_loss": "2.185", "value_loss_mse": "0.023", "code_ppl": "4.55", "wps": "18445.7", "ups": "0.08", "wpb": "222513", "bsz": "1024", "num_updates": "3360", "lr": "0.000168", "gnorm": "2.55", "loss_scale": "0.5", "train_wall": "16", "gb_free": "12.9", "wall": "43042"}
2021-10-11 07:37:25 | INFO | train_inner | {"epoch": 1, "update": 0.272, "loss": "2.097", "code_loss": "2.22", "value_loss_mse": "0.024", "code_ppl": "4.66", "wps": "19059.1", "ups": "0.08", "wpb": "251297", "bsz": "1024", "num_updates": "3370", "lr": "0.0001685", "gnorm": "2.502", "loss_scale": "0.5", "train_wall": "27", "gb_free": "12.9", "wall": "43174"}
2021-10-11 07:39:30 | INFO | train_inner | {"epoch": 1, "update": 0.273, "loss": "2.079", "code_loss": "2.176", "value_loss_mse": "0.023", "code_ppl": "4.52", "wps": "19126.4", "ups": "0.08", "wpb": "239776", "bsz": "1024", "num_updates": "3380", "lr": "0.000169", "gnorm": "2.235", "loss_scale": "0.5", "train_wall": "29", "gb_free": "12.9", "wall": "43299"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0011510848999023438, 0.0014896392822265625, 0.0019044876098632812, 0.0038700103759765625, 0.008544921875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00130462646484375, 0.0017480850219726562, 0.002132415771484375, 0.0021572113037109375, 0.0097808837890625]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0012159347534179688, 0.0015430450439453125, 0.001628875732421875, 0.040252685546875, 0.01116180419921875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0016546249389648438, 0.001361846923828125, 0.0014438629150390625, 0.07489013671875, 0.0083770751953125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0015010833740234375, 0.0018749237060546875, 0.001926422119140625, 0.023468017578125, 0.0235137939453125]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.0036792755126953125, 0.0020580291748046875, 0.0024433135986328125, 0.044525146484375, 0.0246124267578125]
byte7 tgt value: [0.0, 0.0, 0.0, 0.99609375, 0.0]
byte7 pred value: [0.028594970703125, 0.003795623779296875, 0.00400543212890625, 0.90771484375, 0.0322265625]
byte8 tgt value: [0.125, 0.03125, 0.125, 0.625, 0.00390625]
byte8 pred value: [0.11199951171875, 0.072265625, 0.060638427734375, 0.447509765625, 0.056640625]
tgt code: mov r12d ^8 + nop
pred code: mov rbx ^8 + nop
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0017957687377929688, 0.001178741455078125, 0.001155853271484375, 0.0009365081787109375, 0.0009288787841796875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.002620697021484375, 0.0015363693237304688, 0.001483917236328125, 0.001239776611328125, 0.0010900497436523438]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.00847625732421875, 0.004924774169921875, 0.0022525787353515625, 0.0016613006591796875, 0.001628875732421875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.00812530517578125, 0.0036640167236328125, 0.002216339111328125, 0.0023326873779296875, 0.001972198486328125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.01406097412109375, 0.0068511962890625, 0.0027256011962890625, 0.00319671630859375, 0.003185272216796875]
byte6 tgt value: [0.0, 0.00390625, 0.0, 0.0, 0.0]
byte6 pred value: [0.0125732421875, 0.0102081298828125, 0.0033111572265625, 0.004486083984375, 0.005039215087890625]
byte7 tgt value: [0.0, 0.8203125, 0.0, 0.0, 0.0]
byte7 pred value: [0.0141754150390625, 0.1224365234375, 0.004314422607421875, 0.007404327392578125, 0.01512908935546875]
byte8 tgt value: [0.09765625, 0.17578125, 0.109375, 0.21875, 0.0625]
byte8 pred value: [0.1685791015625, 0.17529296875, 0.0999755859375, 0.1370849609375, 0.08990478515625]
tgt code: lea eax lea mov rdi
pred code: lea eax lea lea rdi
2021-10-11 07:41:32 | INFO | train_inner | {"epoch": 1, "update": 0.274, "loss": "2.048", "code_loss": "2.178", "value_loss_mse": "0.023", "code_ppl": "4.52", "wps": "18271.3", "ups": "0.08", "wpb": "222301", "bsz": "1024", "num_updates": "3390", "lr": "0.0001695", "gnorm": "2.378", "loss_scale": "0.5", "train_wall": "39", "gb_free": "12.9", "wall": "43421"}
2021-10-11 07:43:38 | INFO | train_inner | {"epoch": 1, "update": 0.275, "loss": "2.049", "code_loss": "2.193", "value_loss_mse": "0.023", "code_ppl": "4.57", "wps": "19265", "ups": "0.08", "wpb": "241875", "bsz": "1024", "num_updates": "3400", "lr": "0.00017", "gnorm": "2.455", "loss_scale": "0.5", "train_wall": "69", "gb_free": "12.9", "wall": "43546"}
2021-10-11 07:45:37 | INFO | train_inner | {"epoch": 1, "update": 0.275, "loss": "2.086", "code_loss": "2.174", "value_loss_mse": "0.023", "code_ppl": "4.51", "wps": "18046.5", "ups": "0.08", "wpb": "215008", "bsz": "1024", "num_updates": "3410", "lr": "0.0001705", "gnorm": "2.569", "loss_scale": "0.5", "train_wall": "62", "gb_free": "12.9", "wall": "43665"}
[0.442626953125, 0.45556640625, 0.09619140625, 0.057586669921875, 0.1026611328125]
tgt code: rdi hexvar + rdi rsi
pred code: rbx hexvar + hexvar hexvar
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0018892288208007812, 0.00701141357421875, 0.002414703369140625, 0.0016937255859375, 0.0083770751953125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0015916824340820312, 0.00555419921875, 0.0026111602783203125, 0.0018310546875, 0.00864410400390625]
byte3 tgt value: [0.0, 0.38671875, 0.0, 0.38671875, 0.0]
byte3 pred value: [0.01016998291015625, 0.042083740234375, 0.2493896484375, 0.23828125, 0.035675048828125]
byte4 tgt value: [0.0, 0.25, 0.0, 0.25, 0.0]
byte4 pred value: [0.006771087646484375, 0.03436279296875, 0.197265625, 0.1630859375, 0.0302734375]
byte5 tgt value: [0.0, 0.78515625, 0.0, 0.78515625, 0.0]
byte5 pred value: [0.011871337890625, 0.07720947265625, 0.5302734375, 0.45361328125, 0.06304931640625]
byte6 tgt value: [0.0, 0.80078125, 0.01171875, 0.703125, 0.0]
byte6 pred value: [0.01049041748046875, 0.063232421875, 0.64794921875, 0.55517578125, 0.06280517578125]
byte7 tgt value: [0.0, 0.3203125, 0.2265625, 0.8515625, 0.0]
byte7 pred value: [0.01306915283203125, 0.056243896484375, 0.61279296875, 0.5654296875, 0.048492431640625]
byte8 tgt value: [0.2265625, 0.375, 0.41796875, 0.57421875, 0.30859375]
byte8 pred value: [0.1844482421875, 0.10211181640625, 0.46240234375, 0.468994140625, 0.11260986328125]
tgt code: ^1 rip hexvar mov rax
pred code: ^8 rip hexvar mov rbp
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00041413307189941406, 0.001972198486328125, 0.00080108642578125, 0.009521484375, 0.0008039474487304688]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0005130767822265625, 0.0018606185913085938, 0.0008425712585449219, 0.007785797119140625, 0.0007734298706054688]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0011119842529296875, 0.0025806427001953125, 0.018157958984375, 0.019378662109375, 0.001201629638671875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0013151168823242188, 0.0038089752197265625, 0.052337646484375, 0.02508544921875, 0.00127410888671875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0021820068359375, 0.005535125732421875, 0.044586181640625, 0.12451171875, 0.0025119781494140625]
byte6 tgt value: [0.0, 0.0, 0.00390625, 0.0, 0.0]
byte6 pred value: [0.006389617919921875, 0.00530242919921875, 0.042877197265625, 0.09466552734375, 0.0027370452880859375]
byte7 tgt value: [0.0, 0.0, 0.66015625, 0.0, 0.00390625]
byte7 pred value: [0.092041015625, 0.0099334716796875, 0.603515625, 0.1405029296875, 0.007175445556640625]
byte8 tgt value: [0.03125, 0.015625, 0.5, 0.01171875, 0.0]
byte8 pred value: [0.288330078125, 0.030914306640625, 0.455810546875, 0.2237548828125, 0.126953125]
tgt code: rsi rdx rbx + hexvar
pred code: rbx rbx rip + hexvar
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0026721954345703125, 0.00131988525390625, 0.0013828277587890625, 0.00260162353515625, 0.0008525848388671875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0018310546875, 0.001220703125, 0.002002716064453125, 0.001941680908203125, 0.0008106231689453125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0027904510498046875, 0.0028667449951171875, 0.003635406494140625, 0.002414703369140625, 0.001926422119140625]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.004024505615234375, 0.004962921142578125, 0.00490570068359375, 0.0012254714965820312, 0.00274658203125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.00443267822265625, 0.0035800933837890625, 0.0059814453125, 0.004055023193359375, 0.0027675628662109375]
byte6 tgt value: [0.0, 0.0, 0.0, 0.015625, 0.0]
byte6 pred value: [0.01009368896484375, 0.0029468536376953125, 0.01332855224609375, 0.0197906494140625, 0.003635406494140625]
byte7 tgt value: [0.99609375, 0.0, 0.0, 0.609375, 0.0]
byte7 pred value: [0.91357421875, 0.006389617919921875, 0.0411376953125, 0.634765625, 0.010986328125]
byte8 tgt value: [0.1796875, 0.09375, 0.03125, 0.16796875, 0.09375]
byte8 pred value: [0.260986328125, 0.023956298828125, 0.107421875, 0.1458740234375, 0.03314208984375]
tgt code: mov rip rsi hexvar hexvar
pred code: mov rip rsi hexvar hexvar
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0005679130554199219, 0.00263214111328125, 0.0037364959716796875, 0.004116058349609375, 0.0013780593872070312]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0005550384521484375, 0.00266265869140625, 0.004924774169921875, 0.003749847412109375, 0.0011606216430664062]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.00128936767578125, 0.0211181640625, 0.00933837890625, 0.1871337890625, 0.18212890625]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0010204315185546875, 0.038604736328125, 0.007518768310546875, 0.204833984375, 0.22021484375]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.00766754150390625, 0.0170440673828125, 0.008514404296875, 0.264892578125, 0.2958984375]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.01507568359375, 0.035736083984375, 0.01061248779296875, 0.485595703125, 0.57666015625]
byte7 tgt value: [0.0, 0.99609375, 0.0, 0.20703125, 0.12890625]
byte7 pred value: [0.0074615478515625, 0.9443359375, 0.00701141357421875, 0.258056640625, 0.3134765625]
byte8 tgt value: [0.05859375, 0.99609375, 0.05859375, 0.7890625, 0.5]
byte8 pred value: [0.1331787109375, 0.93408203125, 0.10858154296875, 0.435791015625, 0.51611328125]
tgt code: mov rip hexvar mov eax
pred code: mov rip hexvar mov eax
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.003147125244140625, 0.003482818603515625, 0.0006022453308105469, 0.0008897781372070312, 0.003482818603515625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0032596588134765625, 0.00266265869140625, 0.0007066726684570312, 0.001056671142578125, 0.0032863616943359375]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.004398345947265625, 0.0038089752197265625, 0.0015192031860351562, 0.001972198486328125, 0.005260467529296875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0030040740966796875, 0.00263214111328125, 0.001201629638671875, 0.0014896392822265625, 0.0037212371826171875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0100555419921875, 0.0068511962890625, 0.001941680908203125, 0.00208282470703125, 0.008575439453125]
byte6 tgt value: [0.0, 0.0, 0.0078125, 0.0, 0.0]
byte6 pred value: [0.006439208984375, 0.004398345947265625, 0.004848480224609375, 0.00821685791015625, 0.00595855712890625]
byte7 tgt value: [0.0, 0.01171875, 0.07421875, 0.0, 0.01171875]
byte7 pred value: [0.00841522216796875, 0.00572967529296875, 0.043212890625, 0.102294921875, 0.0083160400390625]
byte8 tgt value: [0.03125, 0.43359375, 0.3125, 0.21875, 0.46484375]
byte8 pred value: [0.0994873046875, 0.1187744140625, 0.2763671875, 0.29150390625, 0.07794189453125]
tgt code: hexvar mov rdi ^1 mov
pred code: hexvar mov rdi ^8 mov
byte1 tgt value: [0.0, 0.0, 0.0, 0.3671875, 0.0]
byte1 pred value: [0.00307464599609375, 0.005344390869140625, 0.0022525787353515625, 0.28271484375, 0.00800323486328125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.55859375, 0.0]
byte2 pred value: [0.003124237060546875, 0.0034427642822265625, 0.0032100677490234375, 0.32861328125, 0.009124755859375]
byte3 tgt value: [0.3203125, 0.49609375, 0.0, 0.07421875, 0.0]
byte3 pred value: [0.26904296875, 0.5234375, 0.0022335052490234375, 0.395751953125, 0.007122039794921875]
byte4 tgt value: [0.765625, 0.99609375, 0.0, 0.97265625, 0.0]
byte4 pred value: [0.494140625, 0.97900390625, 0.001949310302734375, 0.5380859375, 0.00760650634765625]
byte5 tgt value: [0.87890625, 0.953125, 0.0, 0.69921875, 0.0]
byte5 pred value: [0.45947265625, 0.7529296875, 0.001956939697265625, 0.50830078125, 0.014617919921875]
byte6 tgt value: [0.54296875, 0.296875, 0.0, 0.625, 0.0]
byte6 pred value: [0.468017578125, 0.1749267578125, 0.0025501251220703125, 0.5693359375, 0.0161590576171875]
byte7 tgt value: 2021-10-11 07:47:47 | INFO | train_inner | {"epoch": 1, "update": 0.276, "loss": "2.11", "code_loss": "2.168", "value_loss_mse": "0.024", "code_ppl": "4.5", "wps": "18543.8", "ups": "0.08", "wpb": "242166", "bsz": "1024", "num_updates": "3420", "lr": "0.000171", "gnorm": "2.491", "loss_scale": "0.5", "train_wall": "88", "gb_free": "12.9", "wall": "43796"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.004680633544921875, 0.0006718635559082031, 0.0012111663818359375, 0.004230499267578125, 0.0030879974365234375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.004364013671875, 0.0006566047668457031, 0.0011920928955078125, 0.00392913818359375, 0.003337860107421875]
byte3 tgt value: [0.0, 0.0, 0.0, 0.12890625, 0.0]
byte3 pred value: [0.0775146484375, 0.001628875732421875, 0.0020999908447265625, 0.11920166015625, 0.00464630126953125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.359375, 0.0]
byte4 pred value: [0.0830078125, 0.00147247314453125, 0.0013780593872070312, 0.11474609375, 0.00391387939453125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.12109375, 0.0]
byte5 pred value: [0.036712646484375, 0.0020503997802734375, 0.0028667449951171875, 0.07080078125, 0.00327301025390625]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0546875, 0.0]
byte6 pred value: [0.042877197265625, 0.0018100738525390625, 0.0022602081298828125, 0.058990478515625, 0.0033893585205078125]
byte7 tgt value: [0.0, 0.0, 0.0, 0.10546875, 0.0]
byte7 pred value: [0.11395263671875, 0.0026111602783203125, 0.0027256011962890625, 0.1339111328125, 0.0043487548828125]
byte8 tgt value: [0.2109375, 0.0, 0.0078125, 0.5, 0.0625]
byte8 pred value: [0.2509765625, 0.03326416015625, 0.043701171875, 0.5166015625, 0.07666015625]
tgt code: r12 lea rbx + hexvar
pred code: hexvar mov rbp + *
2021-10-11 07:49:48 | INFO | train_inner | {"epoch": 1, "update": 0.277, "loss": "2.05", "code_loss": "2.179", "value_loss_mse": "0.023", "code_ppl": "4.53", "wps": "19326.4", "ups": "0.08", "wpb": "233578", "bsz": "1024", "num_updates": "3430", "lr": "0.0001715", "gnorm": "2.562", "loss_scale": "0.5", "train_wall": "43", "gb_free": "12.9", "wall": "43917"}
2021-10-11 07:51:58 | INFO | train_inner | {"epoch": 1, "update": 0.278, "loss": "2.049", "code_loss": "2.169", "value_loss_mse": "0.023", "code_ppl": "4.5", "wps": "18875.3", "ups": "0.08", "wpb": "245491", "bsz": "1024", "num_updates": "3440", "lr": "0.000172", "gnorm": "2.32", "loss_scale": "0.5", "train_wall": "17", "gb_free": "12.9", "wall": "44047"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.93359375, 0.0]
byte1 pred value: [0.004962921142578125, 0.0004935264587402344, 0.0009217262268066406, 0.457275390625, 0.0026531219482421875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.80078125, 0.0]
byte2 pred value: [0.003185272216796875, 0.0004858970642089844, 0.0010652542114257812, 0.4775390625, 0.003337860107421875]
byte3 tgt value: [0.12109375, 0.0, 0.12109375, 0.66796875, 0.0]
byte3 pred value: [0.248046875, 0.005039215087890625, 0.2646484375, 0.4560546875, 0.003749847412109375]
byte4 tgt value: [0.97265625, 0.0, 0.97265625, 0.53515625, 0.0]
byte4 pred value: [0.8916015625, 0.011962890625, 0.81640625, 0.36474609375, 0.0021915435791015625]
byte5 tgt value: [0.80859375, 0.80859375, 0.80859375, 0.40234375, 0.0]
byte5 pred value: [0.8974609375, 0.94921875, 0.85107421875, 0.47900390625, 0.0035247802734375]
byte6 tgt value: [0.859375, 0.859375, 0.8515625, 0.26953125, 0.0]
byte6 pred value: [0.88916015625, 0.9208984375, 0.8427734375, 0.387939453125, 0.003692626953125]
byte7 tgt value: [0.70703125, 0.70703125, 0.33984375, 0.13671875, 0.0]
byte7 pred value: [0.65673828125, 0.81298828125, 0.59326171875, 0.4697265625, 0.00391387939453125]
byte8 tgt value: [0.75, 0.75, 0.375, 0.00390625, 0.15625]
byte8 pred value: [0.576171875, 0.7978515625, 0.439453125, 0.53564453125, 0.10931396484375]
tgt code: edi hexvar rsp xor edi
pred code: hexvar hexvar rsp mov hexvar
2021-10-11 07:54:06 | INFO | train_inner | {"epoch": 1, "update": 0.279, "loss": "2.089", "code_loss": "2.193", "value_loss_mse": "0.023", "code_ppl": "4.57", "wps": "19400.8", "ups": "0.08", "wpb": "247053", "bsz": "1024", "num_updates": "3450", "lr": "0.0001725", "gnorm": "2.525", "loss_scale": "0.5", "train_wall": "16", "gb_free": "12.9", "wall": "44174"}
2021-10-11 07:56:10 | INFO | train_inner | {"epoch": 1, "update": 0.279, "loss": "2.066", "code_loss": "2.149", "value_loss_mse": "0.023", "code_ppl": "4.44", "wps": "18000.4", "ups": "0.08", "wpb": "223952", "bsz": "1024", "num_updates": "3460", "lr": "0.000173", "gnorm": "2.891", "loss_scale": "0.5", "train_wall": "16", "gb_free": "12.9", "wall": "44299"}
2021-10-11 07:58:10 | INFO | train_inner | {"epoch": 1, "update": 0.28, "loss": "2.028", "code_loss": "2.16", "value_loss_mse": "0.023", "code_ppl": "4.47", "wps": "18687.7", "ups": "0.08", "wpb": "224045", "bsz": "1024", "num_updates": "3470", "lr": "0.0001735", "gnorm": "2.497", "loss_scale": "0.5", "train_wall": "15", "gb_free": "12.9", "wall": "44419"}
2021-10-11 08:00:18 | INFO | train_inner | {"epoch": 1, "update": 0.281, "loss": "2.051", "code_loss": "2.163", "value_loss_mse": "0.023", "code_ppl": "4.48", "wps": "18032.3", "ups": "0.08", "wpb": "231674", "bsz": "1024", "num_updates": "3480", "lr": "0.000174", "gnorm": "2.557", "loss_scale": "0.5", "train_wall": "16", "gb_free": "12.9", "wall": "44547"}
2021-10-11 08:02:29 | INFO | train_inner | {"epoch": 1, "update": 0.282, "loss": "2.055", "code_loss": "2.19", "value_loss_mse": "0.023", "code_ppl": "4.56", "wps": "19440.4", "ups": "0.08", "wpb": "253210", "bsz": "1024", "num_updates": "3490", "lr": "0.0001745", "gnorm": "2.601", "loss_scale": "0.5", "train_wall": "16", "gb_free": "12.9", "wall": "44677"}
2021-10-11 08:04:39 | INFO | train_inner | {"epoch": 1, "update": 0.283, "loss": "2.033", "code_loss": "2.178", "value_loss_mse": "0.023", "code_ppl": "4.52", "wps": "18661.5", "ups": "0.08", "wpb": "242672", "bsz": "1024", "num_updates": "3500", "lr": "0.000175", "gnorm": "2.583", "loss_scale": "0.5", "train_wall": "16", "gb_free": "12.9", "wall": "44807"}
2021-10-11 08:06:50 | INFO | train_inner | {"epoch": 1, "update": 0.283, "loss": "2.043", "code_loss": "2.159", "value_loss_mse": "0.023", "code_ppl": "4.47", "wps": "18791.5", "ups": "0.08", "wpb": "246790", "bsz": "1024", "num_updates": "3510", "lr": "0.0001755", "gnorm": "2.509", "loss_scale": "0.5", "train_wall": "17", "gb_free": "12.9", "wall": "44939"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.005161285400390625, 0.001506805419921875, 0.007404327392578125, 0.0009813308715820312, 0.0011205673217773438]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.007205963134765625, 0.0015125274658203125, 0.006290435791015625, 0.0013246536254882812, 0.00128936767578125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.357421875, 0.004398345947265625, 0.033721923828125, 0.05072021484375, 0.051361083984375]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.21484375, 0.0026531219482421875, 0.035003662109375, 0.05108642578125, 0.047882080078125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.496826171875, 0.004329681396484375, 0.06646728515625, 0.10430908203125, 0.09600830078125]
byte6 tgt value: [0.0, 0.0, 0.0, 0.00390625, 0.00390625]
byte6 pred value: [0.1611328125, 0.004486083984375, 0.03155517578125, 0.0328369140625, 0.034027099609375]
byte7 tgt value: [0.0, 0.0, 0.0, 0.42578125, 0.42578125]
byte7 pred value: [0.09503173828125, 0.00634002685546875, 0.061981201171875, 0.44091796875, 0.456787109375]
byte8 tgt value: [0.1953125, 0.00390625, 0.99609375, 0.32421875, 0.03125]
byte8 pred value: [0.66845703125, 0.308349609375, 0.149169921875, 0.486083984375, 0.464599609375]
tgt code: rdi rdi sub ^8 hexvar
pred code: hexvar r13 mov ^8 hexvar
2021-10-11 08:08:55 | INFO | train_inner | {"epoch": 1, "update": 0.284, "loss": "2.028", "code_loss": "2.145", "value_loss_mse": "0.023", "code_ppl": "4.42", "wps": "18867.7", "ups": "0.08", "wpb": "236483", "bsz": "1024", "num_updates": "3520", "lr": "0.000176", "gnorm": "2.387", "loss_scale": "0.5", "train_wall": "16", "gb_free": "12.9", "wall": "45064"}
2021-10-11 08:11:09 | INFO | train_inner | {"epoch": 1, "update": 0.285, "loss": "2.062", "code_loss": "2.148", "value_loss_mse": "0.023", "code_ppl": "4.43", "wps": "17639", "ups": "0.08", "wpb": "234979", "bsz": "1024", "num_updates": "3530", "lr": "0.0001765", "gnorm": "2.833", "loss_scale": "0.5", "train_wall": "17", "gb_free": "12.9", "wall": "45197"}
2021-10-11 08:13:11 | INFO | train_inner | {"epoch": 1, "update": 0.286, "loss": "2.006", "code_loss": "2.128", "value_loss_mse": "0.022", "code_ppl": "4.37", "wps": "18820.6", "ups": "0.08", "wpb": "230944", "bsz": "1024", "num_updates": "3540", "lr": "0.000177", "gnorm": "2.435", "loss_scale": "0.5", "train_wall": "15", "gb_free": "12.9", "wall": "45320"}
2021-10-11 08:15:19 | INFO | train_inner | {"epoch": 1, "update": 0.287, "loss": "1.988", "code_loss": "2.153", "value_loss_mse": "0.022", "code_ppl": "4.45", "wps": "17964.8", "ups": "0.08", "wpb": "229850", "bsz": "1024", "num_updates": "3550", "lr": "0.0001775", "gnorm": "3.116", "loss_scale": "0.5", "train_wall": "19", "gb_free": "12.9", "wall": "45448"}
2021-10-11 08:17:25 | INFO | train_inner | {"epoch": 1, "update": 0.287, "loss": "2.011", "code_loss": "2.138", "value_loss_mse": "0.022", "code_ppl": "4.4", "wps": "18825.3", "ups": "0.08", "wpb": "236314", "bsz": "1024", "num_updates": "3560", "lr": "0.000178", "gnorm": "2.724", "loss_scale": "0.5", "train_wall": "16", "gb_free": "12.9", "wall": "45573"}
2021-10-11 08:19:34 | INFO | train_inner | {"epoch": 1, "update": 0.288, "loss": "2.021", "code_loss": "2.16", "value_loss_mse": "0.023", "code_ppl": "4.47", "wps": "19558.3", "ups": "0.08", "wpb": "253219", "bsz": "1024", "num_updates": "3570", "lr": "0.0001785", "gnorm": "2.493", "loss_scale": "0.5", "train_wall": "40", "gb_free": "12.9", "wall": "45703"}
2021-10-11 08:21:44 | INFO | train_inner | {"epoch": 1, "update": 0.289, "loss": "2.011", "code_loss": "2.157", "value_loss_mse": "0.022", "code_ppl": "4.46", "wps": "19312.9", "ups": "0.08", "wpb": "250352", "bsz": "1024", "num_updates": "3580", "lr": "0.000179", "gnorm": "2.518", "loss_scale": "0.5", "train_wall": "17", "gb_free": "12.9", "wall": "45833"}
2021-10-11 08:23:47 | INFO | train_inner | {"epoch": 1, "update": 0.29, "loss": "1.992", "code_loss": "2.132", "value_loss_mse": "0.022", "code_ppl": "4.38", "wps": "18474.8", "ups": "0.08", "wpb": "226912", "bsz": "1024", "num_updates": "3590", "lr": "0.0001795", "gnorm": "3.015", "loss_scale": "1", "train_wall": "16", "gb_free": "12.9", "wall": "45955"}
2021-10-11 08:25:53 | INFO | train_inner | {"epoch": 1, "update": 0.291, "loss": "2.027", "code_loss": "2.127", "value_loss_mse": "0.023", "code_ppl": "4.37", "wps": "18550.6", "ups": "0.08", "wpb": "233926", "bsz": "1024", "num_updates": "3600", "lr": "0.00018", "gnorm": "2.47", "loss_scale": "1", "train_wall": "57", "gb_free": "12.9", "wall": "46081"}
2021-10-11 08:27:53 | INFO | train_inner | {"epoch": 1, "update": 0.291, "loss": "2.033", "code_loss": "2.134", "value_loss_mse": "0.023", "code_ppl": "4.39", "wps": "19353.2", "ups": "0.08", "wpb": "232467", "bsz": "1024", "num_updates": "3610", "lr": "0.0001805", "gnorm": "2.891", "loss_scale": "1", "train_wall": "58", "gb_free": "12.9", "wall": "46202"}
2021-10-11 08:28:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 08:30:20 | INFO | train_inner | {"epoch": 1, "update": 0.292, "loss": "2.005", "code_loss": "2.139", "value_loss_mse": "0.022", "code_ppl": "4.4", "wps": "17083.7", "ups": "0.07", "wpb": "250829", "bsz": "1024", "num_updates": "3620", "lr": "0.000181", "gnorm": "2.438", "loss_scale": "1", "train_wall": "62", "gb_free": "12.9", "wall": "46348"}
2021-10-11 08:32:38 | INFO | train_inner | {"epoch": 1, "update": 0.293, "loss": "1.987", "code_loss": "2.111", "value_loss_mse": "0.022", "code_ppl": "4.32", "wps": "17357.5", "ups": "0.07", "wpb": "240448", "bsz": "1024", "num_updates": "3630", "lr": "0.0001815", "gnorm": "2.126", "loss_scale": "1", "train_wall": "113", "gb_free": "12.9", "wall": "46487"}
2021-10-11 08:34:44 | INFO | train_inner | {"epoch": 1, "update": 0.294, "loss": "2.017", "code_loss": "2.102", "value_loss_mse": "0.023", "code_ppl": "4.29", "wps": "18848.8", "ups": "0.08", "wpb": "237405", "bsz": "1024", "num_updates": "3640", "lr": "0.000182", "gnorm": "2.39", "loss_scale": "1", "train_wall": "56", "gb_free": "12.9", "wall": "46613"}
2021-10-11 08:36:41 | INFO | train_inner | {"epoch": 1, "update": 0.295, "loss": "1.991", "code_loss": "2.099", "value_loss_mse": "0.022", "code_ppl": "4.28", "wps": "18521.4", "ups": "0.09", "wpb": "216780", "bsz": "1024", "num_updates": "3650", "lr": "0.0001825", "gnorm": "2.707", "loss_scale": "1", "train_wall": "15", "gb_free": "12.9", "wall": "46730"}
2021-10-11 08:38:49 | INFO | train_inner | {"epoch": 1, "update": 0.296, "loss": "1.977", "code_loss": "2.104", "value_loss_mse": "0.022", "code_ppl": "4.3", "wps": "19341", "ups": "0.08", "wpb": "246390", "bsz": "1024", "num_updates": "3660", "lr": "0.000183", "gnorm": "2.157", "loss_scale": "1", "train_wall": "29", "gb_free": "12.9", "wall": "46857"}
2021-10-11 08:41:00 | INFO | train_inner | {"epoch": 1, "update": 0.296, "loss": "1.969", "code_loss": "2.101", "value_loss_mse": "0.022", "code_ppl": "4.29", "wps": "18409.5", "ups": "0.08", "wpb": "242448", "bsz": "1024", "num_updates": "3670", "lr": "0.0001835", "gnorm": "2.202", "loss_scale": "1", "train_wall": "21", "gb_free": "12.9", "wall": "46989"}
2021-10-11 08:43:01 | INFO | train_inner | {"epoch": 1, "update": 0.297, "loss": "1.996", "code_loss": "2.102", "value_loss_mse": "0.022", "code_ppl": "4.29", "wps": "18563.9", "ups": "0.08", "wpb": "223056", "bsz": "1024", "num_updates": "3680", "lr": "0.000184", "gnorm": "2.77", "loss_scale": "1", "train_wall": "15", "gb_free": "12.9", "wall": "47109"}
2021-10-11 08:45:09 | INFO | train_inner | {"epoch": 1, "update": 0.298, "loss": "1.995", "code_loss": "2.098", "value_loss_mse": "0.022", "code_ppl": "4.28", "wps": "18369.7", "ups": "0.08", "wpb": "235186", "bsz": "1024", "num_updates": "3690", "lr": "0.0001845", "gnorm": "2.71", "loss_scale": "1", "train_wall": "61", "gb_free": "12.9", "wall": "47237"}
2021-10-11 08:47:13 | INFO | train_inner | {"epoch": 1, "update": 0.299, "loss": "1.965", "code_loss": "2.088", "value_loss_mse": "0.022", "code_ppl": "4.25", "wps": "19048.3", "ups": "0.08", "wpb": "237370", "bsz": "1024", "num_updates": "3700", "lr": "0.000185", "gnorm": "2.38", "loss_scale": "1", "train_wall": "78", "gb_free": "12.9", "wall": "47362"}
2021-10-11 08:49:15 | INFO | train_inner | {"epoch": 1, "update": 0.3, "loss": "2.031", "code_loss": "2.1", "value_loss_mse": "0.023", "code_ppl": "4.29", "wps": "18878.7", "ups": "0.08", "wpb": "229851", "bsz": "1024", "num_updates": "3710", "lr": "0.0001855", "gnorm": "2.642", "loss_scale": "1", "train_wall": "55", "gb_free": "12.9", "wall": "47484"}
2021-10-11 08:50:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 08:51:36 | INFO | train_inner | {"epoch": 1, "update": 0.3, "loss": "1.952", "code_loss": "2.113", "value_loss_mse": "0.022", "code_ppl": "4.33", "wps": "17409.5", "ups": "0.07", "wpb": "246346", "bsz": "1024", "num_updates": "3720", "lr": "0.000186", "gnorm": "2.678", "loss_scale": "1", "train_wall": "61", "gb_free": "12.9", "wall": "47625"}
2021-10-11 08:53:43 | INFO | train_inner | {"epoch": 1, "update": 0.301, "loss": "1.952", "code_loss": "2.069", "value_loss_mse": "0.022", "code_ppl": "4.2", "wps": "18097.1", "ups": "0.08", "wpb": "229427", "bsz": "1024", "num_updates": "3730", "lr": "0.0001865", "gnorm": "2.711", "loss_scale": "1", "train_wall": "19", "gb_free": "12.9", "wall": "47752"}
2021-10-11 08:55:48 | INFO | train_inner | {"epoch": 1, "update": 0.302, "loss": "1.992", "code_loss": "2.093", "value_loss_mse": "0.022", "code_ppl": "4.27", "wps": "18052.7", "ups": "0.08", "wpb": "224608", "bsz": "1024", "num_updates": "3740", "lr": "0.000187", "gnorm": "2.743", "loss_scale": "1", "train_wall": "15", "gb_free": "12.9", "wall": "47876"}
2021-10-11 08:57:54 | INFO | train_inner | {"epoch": 1, "update": 0.303, "loss": "2.008", "code_loss": "2.089", "value_loss_mse": "0.023", "code_ppl": "4.26", "wps": "18342.2", "ups": "0.08", "wpb": "231559", "bsz": "1024", "num_updates": "3750", "lr": "0.0001875", "gnorm": "2.818", "loss_scale": "1", "train_wall": "16", "gb_free": "12.9", "wall": "48003"}
2021-10-11 08:59:57 | INFO | train_inner | {"epoch": 1, "update": 0.304, "loss": "1.982", "code_loss": "2.074", "value_loss_mse": "0.022", "code_ppl": "4.21", "wps": "18461.7", "ups": "0.08", "wpb": "227546", "bsz": "1024", "num_updates": "3760", "lr": "0.000188", "gnorm": "2.365", "loss_scale": "1", "train_wall": "15", "gb_free": "12.9", "wall": "48126"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00557708740234375, 0.0011968612670898438, 0.0008230209350585938, 0.0004513263702392578, 0.0013942718505859375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.006168365478515625, 0.001201629638671875, 0.0012302398681640625, 0.0007266998291015625, 0.0011243820190429688]
byte3 tgt value: [0.0, 0.125, 0.0, 0.0, 0.0]
byte3 pred value: [0.01287078857421875, 0.0223236083984375, 0.0020904541015625, 0.00128936767578125, 0.00812530517578125]
byte4 tgt value: [0.0, 0.37890625, 0.0, 0.0, 0.0]
byte4 pred value: [0.01953125, 0.043853759765625, 0.00323486328125, 0.0017747879028320312, 0.0137939453125]
byte5 tgt value: [0.1953125, 0.30078125, 0.0, 0.0, 0.0]
byte5 pred value: [0.388916015625, 0.057373046875, 0.0036640167236328125, 0.00260162353515625, 0.337646484375]
byte6 tgt value: [0.72265625, 0.0859375, 0.0, 0.0, 0.0]
byte6 pred value: [0.31005859375, 0.0369873046875, 0.0032596588134765625, 0.0050811767578125, 0.2418212890625]
byte7 tgt value: [0.0703125, 0.08984375, 0.0, 0.0, 0.0]
byte7 pred value: [0.4482421875, 0.6474609375, 0.004215240478515625, 0.0271148681640625, 0.34423828125]
byte8 tgt value: [0.5, 0.1875, 0.1015625, 0.21875, 0.0390625]
byte8 pred value: [0.3388671875, 0.5546875, 0.1597900390625, 0.178955078125, 0.377197265625]
tgt code: hexvar cmp rdx eax rsi
pred code: hexvar mov rdx hexvar rbp
2021-10-11 09:02:12 | INFO | train_inner | {"epoch": 1, "update": 0.305, "loss": "1.967", "code_loss": "2.105", "value_loss_mse": "0.022", "code_ppl": "4.3", "wps": "19348.2", "ups": "0.07", "wpb": "260150", "bsz": "1024", "num_updates": "3770", "lr": "0.0001885", "gnorm": "2.398", "loss_scale": "1", "train_wall": "52", "gb_free": "12.9", "wall": "48260"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0005955696105957031, 0.0007066726684570312, 0.0011882781982421875, 0.00142669677734375, 0.0008759498596191406]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0010862350463867188, 0.0009365081787109375, 0.0012493133544921875, 0.001979827880859375, 0.0023784637451171875]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0010728836059570312, 0.001155853271484375, 0.0020904541015625, 0.0020999908447265625, 0.00494384765625]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0012063980102539062, 0.0010862350463867188, 0.0016040802001953125, 0.0021076202392578125, 0.0089874267578125]
byte5 tgt value: [0.0, 0.0, 0.2421875, 0.0, 0.0]
byte5 pred value: [0.0033245086669921875, 0.116943359375, 0.436279296875, 0.0023059844970703125, 0.00621795654296875]
byte6 tgt value: [0.0, 0.0, 0.85546875, 0.0, 0.01171875]
byte6 pred value: [0.004665374755859375, 0.10968017578125, 0.285888671875, 0.0030879974365234375, 0.0234222412109375]
byte7 tgt value: [0.0, 0.0, 0.9453125, 0.0, 0.09375]
byte7 pred value: [0.00482940673828125, 0.12646484375, 0.416748046875, 0.004791259765625, 0.33544921875]
byte8 tgt value: [0.671875, 0.234375, 0.47265625, 0.01953125, 0.91015625]
byte8 pred value: [0.4267578125, 0.2059326171875, 0.485595703125, 0.056549072265625, 0.477294921875]
tgt code: hexvar hexvar eax ret rax
pred code: hexvar hexvar eax ret rax
2021-10-11 09:04:20 | INFO | train_inner | {"epoch": 1, "update": 0.305, "loss": "1.935", "code_loss": "2.061", "value_loss_mse": "0.022", "code_ppl": "4.17", "wps": "19619.2", "ups": "0.08", "wpb": "252394", "bsz": "1024", "num_updates": "3780", "lr": "0.000189", "gnorm": "2.577", "loss_scale": "1", "train_wall": "58", "gb_free": "12.9", "wall": "48389"}
2021-10-11 09:06:27 | INFO | train_inner | {"epoch": 1, "update": 0.306, "loss": "1.961", "code_loss": "2.074", "value_loss_mse": "0.022", "code_ppl": "4.21", "wps": "18344.1", "ups": "0.08", "wpb": "232496", "bsz": "1024", "num_updates": "3790", "lr": "0.0001895", "gnorm": "2.657", "loss_scale": "1", "train_wall": "77", "gb_free": "12.9", "wall": "48516"}
[0.62890625, 0.859375, 0.0, 0.796875, 0.0]
byte7 pred value: [0.5869140625, 0.84375, 0.0079345703125, 0.484130859375, 0.015838623046875]
byte8 tgt value: [0.6875, 0.8125, 0.03125, 0.6953125, 0.03125]
byte8 pred value: [0.452392578125, 0.7431640625, 0.1163330078125, 0.43701171875, 0.04168701171875]
tgt code: mov rdi je hexvar eax
pred code: push rbx call rax eax
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0033111572265625, 0.002758026123046875, 0.015777587890625, 0.062103271484375, 0.004383087158203125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0021076202392578125, 0.0029697418212890625, 0.0179901123046875, 0.07342529296875, 0.003223419189453125]
byte3 tgt value: [0.0, 0.49609375, 0.49609375, 0.0, 0.35546875]
byte3 pred value: [0.003650665283203125, 0.52197265625, 0.53515625, 0.1368408203125, 0.25048828125]
byte4 tgt value: [0.0, 0.99609375, 0.99609375, 0.0, 0.37109375]
byte4 pred value: [0.0021495819091796875, 0.9921875, 0.970703125, 0.235107421875, 0.2890625]
byte5 tgt value: [0.140625, 0.9765625, 0.9765625, 0.0, 0.1171875]
byte5 pred value: [0.53369140625, 0.8466796875, 0.822265625, 0.328857421875, 0.195556640625]
byte6 tgt value: [0.671875, 0.484375, 0.484375, 0.0, 0.87109375]
byte6 pred value: [0.5, 0.59130859375, 0.5732421875, 0.2421875, 0.40087890625]
byte7 tgt value: [0.98046875, 0.734375, 0.73828125, 0.0, 0.58203125]
byte7 pred value: [0.5654296875, 0.8583984375, 0.82958984375, 0.266357421875, 0.261962890625]
byte8 tgt value: [0.7734375, 0.3125, 0.1875, 0.1875, 0.8125]
byte8 pred value: [0.6201171875, 0.307861328125, 0.302490234375, 0.223388671875, 0.30126953125]
tgt code: rsp movaps movaps ^8 rsp
pred code: rsp movaps movaps ^16 rsp
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0014324188232421875, 0.00595855712890625, 0.0006461143493652344, 0.0008797645568847656, 0.05145263671875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.001506805419921875, 0.00591278076171875, 0.0007615089416503906, 0.0009851455688476562, 0.04510498046875]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.375]
byte3 pred value: [0.0014495849609375, 0.006824493408203125, 0.0015611648559570312, 0.0027790069580078125, 0.1605224609375]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.17578125]
byte4 pred value: [0.0009365081787109375, 0.004756927490234375, 0.0015668869018554688, 0.004085540771484375, 0.2239990234375]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.8828125]
byte5 pred value: [0.0014495849609375, 0.01525115966796875, 0.0041656494140625, 0.01009368896484375, 0.51904296875]
byte6 tgt value: [0.0, 0.0, 0.01953125, 0.0078125, 0.95703125]
byte6 pred value: [0.0028896331787109375, 0.015899658203125, 0.0180511474609375, 0.012969970703125, 0.47216796875]
byte7 tgt value: [0.0, 0.0, 0.53515625, 0.31640625, 0.875]
byte7 pred value: [0.01214599609375, 0.01406097412109375, 0.58349609375, 0.533203125, 0.31396484375]
byte8 tgt value: [0.25, 0.00390625, 0.94140625, 0.75, 0.625]
byte8 pred value: [0.1644287109375, 0.0230712890625, 0.5146484375, 0.52294921875, 0.445068359375]
tgt code: rip rdi + rbx rax
pred code: rip rbx + rbx edx
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0012693405151367188, 0.0004355907440185547, 0.00106048583984375, 0.0007352828979492188, 0.0016813278198242188]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0016546249389648438, 0.0003199577331542969, 0.0008592605590820312, 0.0006694793701171875, 0.001178741455078125]
byte3 tgt value: [0.0, 0.0, 0.08984375, 0.0, 0.0]
byte3 pred value: [0.035675048828125, 0.0006189346313476562, 0.19091796875, 0.00397491455078125, 0.012237548828125]
byte4 tgt value: [0.0, 0.0, 0.57421875, 0.0, 0.0]
byte4 pred value: [0.07720947265625, 0.0009622573852539062, 0.50732421875, 0.0069580078125, 0.0416259765625]
byte5 tgt value: [0.0, 0.0, 0.4140625, 0.0, 0.0]
byte5 pred value: [0.06671142578125, 0.0041351318359375, 0.3798828125, 0.00494384765625, 0.04986572265625]
byte6 tgt value: [0.0, 0.0, 0.43359375, 0.0, 0.0]
byte6 pred value: [0.08660888671875, 0.00469970703125, 0.423095703125, 0.006717681884765625, 0.059539794921875]
byte7 tgt value: [0.0, 0.0, 0.3984375, 0.0, 0.0]
byte7 pred value: [0.058349609375, 0.0060272216796875, 0.356689453125, 0.006744384765625, 0.053314208984375]
byte8 tgt value: [0.00390625, 0.24609375, 0.9375, 0.00390625, 0.02734375]
byte8 pred value: [0.1414794921875, 0.145751953125, 0.49951171875, 0.08740234375, 0.1312255859375]
tgt code: ^8 cmp rsp hexvar +
pred code: ^8 mov rsp hexvar +
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.002834320068359375, 0.0034160614013671875, 0.003223419189453125, 0.0003418922424316406, 0.00021827220916748047]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0029926300048828125, 0.004116058349609375, 0.004486083984375, 0.0005617141723632812, 0.0003418922424316406]
byte3 tgt value: [0.49609375, 0.49609375, 0.0, 0.0, 0.0]
byte3 pred value: [0.498046875, 0.50439453125, 0.0034027099609375, 0.002323150634765625, 0.002758026123046875]
byte4 tgt value: [0.99609375, 0.99609375, 0.0, 0.0, 0.0]
byte4 pred value: [0.99169921875, 0.994140625, 0.0029811859130859375, 0.002590179443359375, 0.003429412841796875]
byte5 tgt value: [0.765625, 0.765625, 0.0, 0.0, 0.0]
byte5 pred value: [0.83984375, 0.81103515625, 0.003429412841796875, 0.003223419189453125, 0.0041656494140625]
byte6 tgt value: [0.56640625, 0.56640625, 0.0, 0.01171875, 0.01171875]
byte6 pred value: [0.53515625, 0.537109375, 0.004199981689453125, 0.0272674560546875, 0.019866943359375]
byte7 tgt value: [0.67578125, 0.67578125, 0.0, 0.16796875, 0.16796875]
byte7 pred value: [0.86376953125, 0.85693359375, 0.0059356689453125, 0.48193359375, 0.364990234375]
byte8 tgt value: [0.125, 0.125, 0.0, 0.20703125, 0.07421875]
byte8 pred value: [0.160888671875, 0.09417724609375, 0.11083984375, 0.470947265625, 0.452880859375]
tgt code: ^8 + ^8 push rsp
pred code: ^8 + ^8 mov rsp
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00701141357421875, 0.0008425712585449219, 0.00183868408203125, 0.006511688232421875, 0.00131988525390625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00926971435546875, 0.001239776611328125, 0.002208709716796875, 0.0082550048828125, 0.0020751953125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.00609588623046875, 0.0009622573852539062, 0.0016613006591796875, 0.0038394927978515625, 0.002349853515625]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.006771087646484375, 0.0011606216430664062, 0.0030994415283203125, 0.0029582977294921875, 0.00391387939453125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.13818359375, 0.002010345458984375, 0.0110321044921875, 0.0283355712890625, 0.006587982177734375]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.156005859375, 0.0048675537109375, 0.037109375, 0.0276947021484375, 0.008514404296875]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.1439208984375, 0.0090179443359375, 0.166015625, 0.039642333984375, 0.00974273681640625]
byte8 tgt value: [0.0, 0.09375, 0.1328125, 0.5, 0.03125]
byte8 pred value: [0.2115478515625, 0.309814453125, 0.369873046875, 0.1556396484375, 0.1495361328125]
tgt code: lea - setbe movabs cl
pred code: mov + mov mov eax
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0582275390625, 0.0009183883666992188, 0.08477783203125, 0.00142669677734375, 0.0034160614013671875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0504150390625, 0.0011119842529296875, 0.07611083984375, 0.001918792724609375, 0.0036640167236328125]
byte3 tgt value: [0.0, 0.265625, 0.0, 0.0, 0.49609375]
byte3 pred value: [0.06982421875, 0.1517333984375, 0.106689453125, 0.0012063980102539062, 0.5029296875]
byte4 tgt value: [0.0, 0.33984375, 0.0, 0.0, 0.99609375]
byte4 pred value: [0.10125732421875, 0.31103515625, 0.1417236328125, 0.0014896392822265625, 0.990234375]
byte5 tgt value: [0.0, 0.78515625, 0.0, 0.0, 0.97265625]
byte5 pred value: [0.07611083984375, 0.416748046875, 0.10760498046875, 0.001720428466796875, 0.88232421875]
byte6 tgt value: [0.0, 0.15625, 0.0, 0.0, 0.640625]
byte6 pred value: byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0948486328125, 0.0039005279541015625, 0.0015363693237304688, 0.001220703125, 0.0007915496826171875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0970458984375, 0.0033512115478515625, 0.0012645721435546875, 0.0008459091186523438, 0.0008492469787597656]
byte3 tgt value: [0.0, 0.46484375, 0.0, 0.0, 0.0]
byte3 pred value: [0.1077880859375, 0.05242919921875, 0.045257568359375, 0.01525115966796875, 0.0009288787841796875]
byte4 tgt value: [0.0, 0.7265625, 0.0, 0.0, 0.0]
byte4 pred value: [0.1385498046875, 0.1373291015625, 0.1177978515625, 0.03167724609375, 0.0009217262268066406]
byte5 tgt value: [0.0, 0.69140625, 0.0, 0.0, 0.0]
byte5 pred value: [0.10931396484375, 0.11553955078125, 0.09619140625, 0.0360107421875, 0.0012063980102539062]
byte6 tgt value: [0.0, 0.4453125, 0.00390625, 0.00390625, 0.0]
byte6 pred value: [0.10247802734375, 0.089599609375, 0.0784912109375, 0.0328369140625, 0.0022792816162109375]
byte7 tgt value: [0.0, 0.796875, 0.98046875, 0.984375, 0.0]
byte7 pred value: [0.1026611328125, 0.5029296875, 0.84423828125, 0.88037109375, 0.01073455810546875]
byte8 tgt value: [0.14453125, 0.75, 0.484375, 0.25, 0.0625]
byte8 pred value: [0.16064453125, 0.318603515625, 0.5029296875, 0.499755859375, 0.09075927734375]
tgt code: hexvar rsp hexvar mov hexvar
pred code: hexvar rsp hexvar mov hexvar
2021-10-11 09:08:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 09:08:52 | INFO | train_inner | {"epoch": 1, "update": 0.307, "loss": "1.938", "code_loss": "2.056", "value_loss_mse": "0.022", "code_ppl": "4.16", "wps": "16110", "ups": "0.07", "wpb": "234232", "bsz": "1024", "num_updates": "3800", "lr": "0.00019", "gnorm": "2.565", "loss_scale": "1", "train_wall": "105", "gb_free": "12.9", "wall": "48661"}
2021-10-11 09:09:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 09:11:13 | INFO | train_inner | {"epoch": 1, "update": 0.308, "loss": "1.931", "code_loss": "2.048", "value_loss_mse": "0.022", "code_ppl": "4.13", "wps": "17521.6", "ups": "0.07", "wpb": "246964", "bsz": "1024", "num_updates": "3810", "lr": "0.0001905", "gnorm": "2.507", "loss_scale": "1", "train_wall": "41", "gb_free": "12.9", "wall": "48802"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.045867919921875, 0.0802001953125, 0.001178741455078125, 0.0033245086669921875, 0.042816162109375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.040008544921875, 0.06695556640625, 0.0010042190551757812, 0.0027790069580078125, 0.0460205078125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.234375]
byte3 pred value: [0.042724609375, 0.07354736328125, 0.0031719207763671875, 0.004180908203125, 0.070556640625]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.80859375]
byte4 pred value: [0.041229248046875, 0.08197021484375, 0.00605010986328125, 0.0039005279541015625, 0.14990234375]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.1953125]
byte5 pred value: [0.04559326171875, 0.07794189453125, 0.00600433349609375, 0.003482818603515625, 0.1181640625]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.5546875]
byte6 pred value: [0.02191162109375, 0.059326171875, 0.004665374755859375, 0.0035381317138671875, 0.079345703125]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.421875]
byte7 pred value: [0.02606201171875, 0.05877685546875, 0.00997161865234375, 0.004180908203125, 0.144287109375]
byte8 tgt value: [0.0, 0.08984375, 0.9375, 0.03125, 0.375]
byte8 pred value: [0.075439453125, 0.1295166015625, 0.80029296875, 0.0328369140625, 0.241455078125]
tgt code: rax ^8 rsi + r8
pred code: edx ^8 rbp + hexvar
2021-10-11 09:13:15 | INFO | train_inner | {"epoch": 1, "update": 0.309, "loss": "1.958", "code_loss": "2.049", "value_loss_mse": "0.022", "code_ppl": "4.14", "wps": "18775.7", "ups": "0.08", "wpb": "227942", "bsz": "1024", "num_updates": "3820", "lr": "0.000191", "gnorm": "2.405", "loss_scale": "1", "train_wall": "40", "gb_free": "12.9", "wall": "48923"}
2021-10-11 09:15:17 | INFO | train_inner | {"epoch": 1, "update": 0.309, "loss": "1.971", "code_loss": "2.017", "value_loss_mse": "0.022", "code_ppl": "4.05", "wps": "18418", "ups": "0.08", "wpb": "225389", "bsz": "1024", "num_updates": "3830", "lr": "0.0001915", "gnorm": "3.226", "loss_scale": "1", "train_wall": "31", "gb_free": "12.9", "wall": "49046"}
2021-10-11 09:17:28 | INFO | train_inner | {"epoch": 1, "update": 0.31, "loss": "1.98", "code_loss": "2.059", "value_loss_mse": "0.022", "code_ppl": "4.17", "wps": "19508.9", "ups": "0.08", "wpb": "255446", "bsz": "1024", "num_updates": "3840", "lr": "0.000192", "gnorm": "2.765", "loss_scale": "1", "train_wall": "16", "gb_free": "12.9", "wall": "49177"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0009851455688476562, 0.00498199462890625, 0.0007762908935546875, 0.01332855224609375, 0.0022258758544921875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0010442733764648438, 0.0060272216796875, 0.000904083251953125, 0.0142822265625, 0.0023326873779296875]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0015916824340820312, 0.003780364990234375, 0.0018033981323242188, 0.093994140625, 0.038543701171875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.001201629638671875, 0.004398345947265625, 0.0018243789672851562, 0.1719970703125, 0.0953369140625]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0021991729736328125, 0.007373809814453125, 0.0017547607421875, 0.149658203125, 0.058441162109375]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.0022525787353515625, 0.006931304931640625, 0.00208282470703125, 0.11737060546875, 0.043701171875]
byte7 tgt value: [0.0, 0.0, 0.0, 0.65625, 0.65625]
byte7 pred value: [0.004085540771484375, 0.0060272216796875, 0.00238800048828125, 0.37841796875, 0.495361328125]
byte8 tgt value: [0.03125, 0.00390625, 0.03125, 0.625, 0.47265625]
byte8 pred value: [0.0455322265625, 0.057281494140625, 0.0965576171875, 0.31884765625, 0.430908203125]
tgt code: rax rax je hexvar ^4
pred code: esi rdx nop hexvar ^8
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0016040802001953125, 0.000469207763671875, 0.002208709716796875, 0.0090179443359375, 0.0008263587951660156]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0014047622680664062, 0.0005440711975097656, 0.0025310516357421875, 0.014556884765625, 0.001056671142578125]
byte3 tgt value: [0.49609375, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.490234375, 0.0021495819091796875, 0.00394439697265625, 0.00867462158203125, 0.0013990402221679688]
byte4 tgt value: [0.99609375, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.98974609375, 0.0024433135986328125, 0.002620697021484375, 0.012237548828125, 0.0011835098266601562]
byte5 tgt value: [0.8828125, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.7744140625, 0.00243377685546875, 0.0053863525390625, 0.01337432861328125, 0.0019044876098632812]
byte6 tgt value: [0.34765625, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.330078125, 0.00284576416015625, 0.006072998046875, 0.01146697998046875, 0.002521514892578125]
byte7 tgt value: [0.36328125, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.368896484375, 0.0030879974365234375, 0.00787353515625, 0.020843505859375, 0.00634002685546875]
byte8 tgt value: [0.03125, 0.125, 0.00390625, 0.203125, 0.28125]
byte8 pred value: [0.1312255859375, 0.1868896484375, 0.25341796875, 0.144775390625, 0.2049560546875]
tgt code: jmp mov rdi eax
pred code: ret mov rdi eax
2021-10-11 09:19:26 | INFO | train_inner | {"epoch": 1, "update": 0.311, "loss": "1.923", "code_loss": "2.006", "value_loss_mse": "0.022", "code_ppl": "4.02", "wps": "17814.4", "ups": "0.08", "wpb": "209939", "bsz": "1024", "num_updates": "3850", "lr": "0.0001925", "gnorm": "3.007", "loss_scale": "1", "train_wall": "58", "gb_free": "12.9", "wall": "49295"}
2021-10-11 09:21:26 | INFO | train_inner | {"epoch": 1, "update": 0.312, "loss": "1.935", "code_loss": "2.035", "value_loss_mse": "0.022", "code_ppl": "4.1", "wps": "18905.8", "ups": "0.08", "wpb": "226819", "bsz": "1024", "num_updates": "3860", "lr": "0.000193", "gnorm": "2.794", "loss_scale": "1", "train_wall": "45", "gb_free": "12.9", "wall": "49415"}
2021-10-11 09:23:37 | INFO | train_inner | {"epoch": 1, "update": 0.313, "loss": "1.942", "code_loss": "2.04", "value_loss_mse": "0.022", "code_ppl": "4.11", "wps": "18956.8", "ups": "0.08", "wpb": "248573", "bsz": "1024", "num_updates": "3870", "lr": "0.0001935", "gnorm": "2.556", "loss_scale": "1", "train_wall": "19", "gb_free": "12.9", "wall": "49546"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00319671630859375, 0.001201629638671875, 0.0035247802734375, 0.00147247314453125, 0.0029125213623046875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.004329681396484375, 0.002124786376953125, 0.0034694671630859375, 0.0011072158813476562, 0.002323150634765625]
byte3 tgt value: [0.0, 0.49609375, 0.0, 0.0, 0.375]
byte3 pred value: [0.00926971435546875, 0.425537109375, 0.00490570068359375, 0.0015974044799804688, 0.1981201171875]
byte4 tgt value: [0.0, 0.99609375, 0.0, 0.0, 0.03125]
byte4 pred value: [0.01229095458984375, 0.986328125, 0.0069580078125, 0.0028667449951171875, 0.168701171875]
byte5 tgt value: [0.0, 0.72265625, 0.0, 0.0, 0.0078125]
byte5 pred value: [0.00926971435546875, 0.72119140625, 0.0074310302734375, 0.0092315673828125, 0.167724609375]
byte6 tgt value: [0.0, 0.55078125, 0.0, 0.0234375, 0.07421875]
byte6 pred value: [0.010528564453125, 0.472412109375, 0.0060272216796875, 0.0531005859375, 0.156982421875]
byte7 tgt value: [0.0, 0.421875, 0.0, 0.64453125, 0.953125]
byte7 pred value: [0.012969970703125, 0.368408203125, 0.00763702392578125, 0.92822265625, 0.4951171875]
byte8 tgt value: [0.0, 0.9375, 0.125, 0.12890625, 0.625]
byte8 pred value: [0.033843994140625, 0.34765625, 0.1788330078125, 0.46533203125, 0.473388671875]
tgt code: edx hexvar edx ret mov
pred code: eax hexvar hexvar ret pop
2021-10-11 09:25:46 | INFO | train_inner | {"epoch": 1, "update": 0.314, "loss": "1.92", "code_loss": "2.032", "value_loss_mse": "0.022", "code_ppl": "4.09", "wps": "18705.1", "ups": "0.08", "wpb": "241725", "bsz": "1024", "num_updates": "3880", "lr": "0.000194", "gnorm": "2.469", "loss_scale": "1", "train_wall": "16", "gb_free": "12.9", "wall": "49675"}
2021-10-11 09:27:51 | INFO | train_inner | {"epoch": 1, "update": 0.314, "loss": "1.921", "code_loss": "2.029", "value_loss_mse": "0.022", "code_ppl": "4.08", "wps": "18867", "ups": "0.08", "wpb": "235916", "bsz": "1024", "num_updates": "3890", "lr": "0.0001945", "gnorm": "2.61", "loss_scale": "1", "train_wall": "16", "gb_free": "12.9", "wall": "49800"}
2021-10-11 09:29:57 | INFO | train_inner | {"epoch": 1, "update": 0.315, "loss": "1.948", "code_loss": "2.031", "value_loss_mse": "0.022", "code_ppl": "4.09", "wps": "18868.7", "ups": "0.08", "wpb": "237088", "bsz": "1024", "num_updates": "3900", "lr": "0.000195", "gnorm": "3.022", "loss_scale": "1", "train_wall": "16", "gb_free": "12.9", "wall": "49926"}
2021-10-11 09:31:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 09:32:10 | INFO | train_inner | {"epoch": 1, "update": 0.316, "loss": "1.934", "code_loss": "2.013", "value_loss_mse": "0.022", "code_ppl": "4.04", "wps": "16420.2", "ups": "0.08", "wpb": "217773", "bsz": "1024", "num_updates": "3910", "lr": "0.0001955", "gnorm": "3.144", "loss_scale": "1", "train_wall": "16", "gb_free": "12.9", "wall": "50058"}
2021-10-11 09:33:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 09:34:30 | INFO | train_inner | {"epoch": 1, "update": 0.317, "loss": "1.958", "code_loss": "2.018", "value_loss_mse": "0.022", "code_ppl": "4.05", "wps": "16814.1", "ups": "0.07", "wpb": "235655", "bsz": "1024", "num_updates": "3920", "lr": "0.000196", "gnorm": "3.189", "loss_scale": "1", "train_wall": "19", "gb_free": "12.9", "wall": "50198"}
2021-10-11 09:36:42 | INFO | train_inner | {"epoch": 1, "update": 0.318, "loss": "1.93", "code_loss": "2.043", "value_loss_mse": "0.022", "code_ppl": "4.12", "wps": "18369.2", "ups": "0.08", "wpb": "243725", "bsz": "1024", "num_updates": "3930", "lr": "0.0001965", "gnorm": "2.736", "loss_scale": "1", "train_wall": "24", "gb_free": "12.9", "wall": "50331"}
2021-10-11 09:38:49 | INFO | train_inner | {"epoch": 1, "update": 0.319, "loss": "1.921", "code_loss": "2.012", "value_loss_mse": "0.022", "code_ppl": "4.03", "wps": "19433.5", "ups": "0.08", "wpb": "245702", "bsz": "1024", "num_updates": "3940", "lr": "0.000197", "gnorm": "2.334", "loss_scale": "1", "train_wall": "16", "gb_free": "12.9", "wall": "50457"}
2021-10-11 09:40:52 | INFO | train_inner | {"epoch": 1, "update": 0.319, "loss": "1.917", "code_loss": "2.004", "value_loss_mse": "0.022", "code_ppl": "4.01", "wps": "18641.3", "ups": "0.08", "wpb": "229227", "bsz": "1024", "num_updates": "3950", "lr": "0.0001975", "gnorm": "2.582", "loss_scale": "1", "train_wall": "24", "gb_free": "12.9", "wall": "50580"}
2021-10-11 09:42:58 | INFO | train_inner | {"epoch": 1, "update": 0.32, "loss": "1.877", "code_loss": "2.006", "value_loss_mse": "0.021", "code_ppl": "4.02", "wps": "17807.9", "ups": "0.08", "wpb": "224413", "bsz": "1024", "num_updates": "3960", "lr": "0.000198", "gnorm": "2.826", "loss_scale": "1", "train_wall": "16", "gb_free": "12.9", "wall": "50706"}
2021-10-11 09:45:00 | INFO | train_inner | {"epoch": 1, "update": 0.321, "loss": "1.948", "code_loss": "2.019", "value_loss_mse": "0.022", "code_ppl": "4.05", "wps": "19415.1", "ups": "0.08", "wpb": "236770", "bsz": "1024", "num_updates": "3970", "lr": "0.0001985", "gnorm": "3.065", "loss_scale": "1", "train_wall": "17", "gb_free": "12.9", "wall": "50828"}
2021-10-11 09:47:12 | INFO | train_inner | {"epoch": 1, "update": 0.322, "loss": "1.933", "code_loss": "1.996", "value_loss_mse": "0.022", "code_ppl": "3.99", "wps": "18377.4", "ups": "0.08", "wpb": "242202", "bsz": "1024", "num_updates": "3980", "lr": "0.000199", "gnorm": "2.55", "loss_scale": "1", "train_wall": "18", "gb_free": "12.9", "wall": "50960"}
2021-10-11 09:48:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 09:49:26 | INFO | train_inner | {"epoch": 1, "update": 0.323, "loss": "1.971", "code_loss": "1.995", "value_loss_mse": "0.022", "code_ppl": "3.99", "wps": "16727.4", "ups": "0.07", "wpb": "224186", "bsz": "1024", "num_updates": "3990", "lr": "0.0001995", "gnorm": "3.122", "loss_scale": "1", "train_wall": "17", "gb_free": "12.9", "wall": "51094"}
2021-10-11 09:50:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 09:51:51 | INFO | train_inner | {"epoch": 1, "update": 0.323, "loss": "1.92", "code_loss": "2.021", "value_loss_mse": "0.022", "code_ppl": "4.06", "wps": "16695.2", "ups": "0.07", "wpb": "242461", "bsz": "1024", "num_updates": "4000", "lr": "0.0002", "gnorm": "2.591", "loss_scale": "1", "train_wall": "18", "gb_free": "12.9", "wall": "51239"}
2021-10-11 09:54:09 | INFO | train_inner | {"epoch": 1, "update": 0.324, "loss": "1.894", "code_loss": "2.023", "value_loss_mse": "0.021", "code_ppl": "4.06", "wps": "18096.6", "ups": "0.07", "wpb": "249456", "bsz": "1024", "num_updates": "4010", "lr": "0.0002005", "gnorm": "2.522", "loss_scale": "1", "train_wall": "17", "gb_free": "12.9", "wall": "51377"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0018892288208007812, 0.00042724609375, 0.0005254745483398438, 0.0016231536865234375, 0.0009474754333496094]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0017547607421875, 0.0008592605590820312, 0.0011377334594726562, 0.0020580291748046875, 0.0006313323974609375]
byte3 tgt value: [0.375, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.163818359375, 0.001461029052734375, 0.0020580291748046875, 0.00586700439453125, 0.0016489028930664062]
byte4 tgt value: [0.40625, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.2437744140625, 0.001178741455078125, 0.0020351409912109375, 0.006488800048828125, 0.001789093017578125]
byte5 tgt value: [0.328125, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.52685546875, 0.0048675537109375, 0.005279541015625, 0.004520416259765625, 0.001926422119140625]
byte6 tgt value: [0.62109375, 0.0, 0.01171875, 0.0, 0.0]
byte6 pred value: [0.64697265625, 0.0439453125, 0.038909912109375, 0.00518035888671875, 0.0018672943115234375]
byte7 tgt value: [0.70703125, 0.0, 0.54296875, 0.0, 0.0]
byte7 pred value: [0.59765625, 0.409912109375, 0.36865234375, 0.0104522705078125, 0.0038242340087890625]
byte8 tgt value: [0.0, 0.0625, 0.1484375, 0.2109375, 0.23046875]
byte8 pred value: [0.4375, 0.4541015625, 0.455810546875, 0.11676025390625, 0.1744384765625]
tgt code: rbx hexvar nop rbx hexvar
pred code: rsi hexvar mov rbx hexvar
2021-10-11 09:55:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 09:56:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 09:56:46 | INFO | train_inner | {"epoch": 1, "update": 0.325, "loss": "1.885", "code_loss": "2.012", "value_loss_mse": "0.021", "code_ppl": "4.03", "wps": "15035.3", "ups": "0.06", "wpb": "237274", "bsz": "1024", "num_updates": "4020", "lr": "0.000201", "gnorm": "2.753", "loss_scale": "1", "train_wall": "20", "gb_free": "12.9", "wall": "51535"}
2021-10-11 09:58:52 | INFO | train_inner | {"epoch": 1, "update": 0.326, "loss": "1.929", "code_loss": "1.982", "value_loss_mse": "0.022", "code_ppl": "3.95", "wps": "18453.6", "ups": "0.08", "wpb": "231772", "bsz": "1024", "num_updates": "4030", "lr": "0.0002015", "gnorm": "2.641", "loss_scale": "1", "train_wall": "16", "gb_free": "12.9", "wall": "51661"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0017957687377929688, 0.009521484375, 0.0015430450439453125, 0.0012493133544921875, 0.0106964111328125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0022335052490234375, 0.00971221923828125, 0.0010652542114257812, 0.0011425018310546875, 0.0116424560546875]
byte3 tgt value: [0.0, 0.4453125, 0.0, 0.0, 0.0]
byte3 pred value: [0.00250244140625, 0.300537109375, 0.0021152496337890625, 0.05108642578125, 0.01422882080078125]
byte4 tgt value: [0.0, 0.125, 0.0, 0.0, 0.0]
byte4 pred value: [0.002811431884765625, 0.041839599609375, 0.0014553070068359375, 0.0173797607421875, 0.00919342041015625]
byte5 tgt value: [0.0, 0.5859375, 0.0, 0.0, 0.0]
byte5 pred value: [0.003650665283203125, 0.4775390625, 0.0033512115478515625, 0.11297607421875, 0.01282501220703125]
byte6 tgt value: [0.0, 0.34375, 0.0, 0.0, 0.0]
byte6 pred value: [0.0027256011962890625, 0.2080078125, 0.00800323486328125, 0.0537109375, 0.010528564453125]
byte7 tgt value: [0.0, 0.23828125, 0.26171875, 0.81640625, 0.0]
byte7 pred value: [0.0038242340087890625, 0.3779296875, 0.2900390625, 0.40576171875, 0.0163421630859375]
byte8 tgt value: [0.09765625, 0.60546875, 0.4375, 0.9375, 0.03125]
byte8 pred value: [0.1190185546875, 0.448974609375, 0.48046875, 0.490234375, 0.077392578125]
tgt code: rdi rdi rdx mov mov
pred code: rax r14d ecx push push
2021-10-11 10:01:03 | INFO | train_inner | {"epoch": 1, "update": 0.327, "loss": "1.875", "code_loss": "1.996", "value_loss_mse": "0.021", "code_ppl": "3.99", "wps": "18925.3", "ups": "0.08", "wpb": "247456", "bsz": "1024", "num_updates": "4040", "lr": "0.000202", "gnorm": "2.724", "loss_scale": "1", "train_wall": "16", "gb_free": "12.9", "wall": "51791"}
2021-10-11 10:03:18 | INFO | train_inner | {"epoch": 1, "update": 0.328, "loss": "1.885", "code_loss": "1.997", "value_loss_mse": "0.021", "code_ppl": "3.99", "wps": "18762.9", "ups": "0.07", "wpb": "253603", "bsz": "1024", "num_updates": "4050", "lr": "0.0002025", "gnorm": "2.622", "loss_scale": "1", "train_wall": "17", "gb_free": "12.9", "wall": "51927"}
2021-10-11 10:05:20 | INFO | train_inner | {"epoch": 1, "update": 0.328, "loss": "1.871", "code_loss": "1.987", "value_loss_mse": "0.021", "code_ppl": "3.97", "wps": "19139.7", "ups": "0.08", "wpb": "232986", "bsz": "1024", "num_updates": "4060", "lr": "0.000203", "gnorm": "2.518", "loss_scale": "1", "train_wall": "18", "gb_free": "12.9", "wall": "52048"}
2021-10-11 10:06:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:07:36 | INFO | train_inner | {"epoch": 1, "update": 0.329, "loss": "1.877", "code_loss": "1.964", "value_loss_mse": "0.021", "code_ppl": "3.9", "wps": "16889.4", "ups": "0.07", "wpb": "230595", "bsz": "1024", "num_updates": "4070", "lr": "0.0002035", "gnorm": "3.068", "loss_scale": "1", "train_wall": "22", "gb_free": "12.9", "wall": "52185"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.014556884765625, 0.1124267578125, 0.06097412109375, 0.050323486328125, 0.0008864402770996094]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0127716064453125, 0.1248779296875, 0.07763671875, 0.063720703125, 0.0007319450378417969]
byte3 tgt value: [0.3515625, 0.3515625, 0.3515625, 0.0, 0.0]
byte3 pred value: [0.0227203369140625, 0.389404296875, 0.378173828125, 0.278076171875, 0.0010986328125]
byte4 tgt value: [0.07421875, 0.07421875, 0.07421875, 0.0, 0.0]
byte4 pred value: [0.0236968994140625, 0.2322998046875, 0.223388671875, 0.18359375, 0.0006718635559082031]
byte5 tgt value: [0.31640625, 0.31640625, 0.31640625, 0.0, 0.0]
byte5 pred value: [0.03314208984375, 0.48193359375, 0.490966796875, 0.33056640625, 0.0028228759765625]
byte6 tgt value: [0.72265625, 0.72265625, 0.72265625, 0.0, 0.0]
byte6 pred value: [0.0272216796875, 0.474365234375, 0.568359375, 0.34033203125, 0.006511688232421875]
byte7 tgt value: [0.88671875, 0.88671875, 0.8828125, 0.0, 0.0]
byte7 pred value: [0.02691650390625, 0.52783203125, 0.64208984375, 0.361572265625, 0.035614013671875]
byte8 tgt value: [0.5, 0.5, 0.75, 0.23046875, 0.03125]
byte8 pred value: [0.09124755859375, 0.486328125, 0.461181640625, 0.331787109375, 0.0849609375]
tgt code: rdx mov rax mov ^8
pred code: rax mov rax mov rbp
2021-10-11 10:09:39 | INFO | train_inner | {"epoch": 1, "update": 0.33, "loss": "1.893", "code_loss": "1.976", "value_loss_mse": "0.021", "code_ppl": "3.93", "wps": "18950.6", "ups": "0.08", "wpb": "233084", "bsz": "1024", "num_updates": "4080", "lr": "0.000204", "gnorm": "3.192", "loss_scale": "1", "train_wall": "16", "gb_free": "12.9", "wall": "52308"}
2021-10-11 10:11:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:12:00 | INFO | train_inner | {"epoch": 1, "update": 0.331, "loss": "1.882", "code_loss": "1.992", "value_loss_mse": "0.021", "code_ppl": "3.98", "wps": "17099.2", "ups": "0.07", "wpb": "240074", "bsz": "1024", "num_updates": "4090", "lr": "0.0002045", "gnorm": "2.873", "loss_scale": "1", "train_wall": "18", "gb_free": "12.9", "wall": "52448"}
2021-10-11 10:13:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:14:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:14:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:14:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:14:57 | INFO | train_inner | {"epoch": 1, "update": 0.332, "loss": "1.9", "code_loss": "1.98", "value_loss_mse": "0.021", "code_ppl": "3.94", "wps": "13148.9", "ups": "0.06", "wpb": "233574", "bsz": "1024", "num_updates": "4100", "lr": "0.000205", "gnorm": "3.098", "loss_scale": "1", "train_wall": "22", "gb_free": "12.9", "wall": "52626"}
2021-10-11 10:15:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:15:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:17:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:17:50 | INFO | train_inner | {"epoch": 1, "update": 0.333, "loss": "1.867", "code_loss": "1.975", "value_loss_mse": "0.021", "code_ppl": "3.93", "wps": "13492", "ups": "0.06", "wpb": "232944", "bsz": "1024", "num_updates": "4110", "lr": "0.0002055", "gnorm": "2.92", "loss_scale": "1", "train_wall": "22", "gb_free": "12.9", "wall": "52799"}
2021-10-11 10:18:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:19:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:20:16 | INFO | train_inner | {"epoch": 1, "update": 0.334, "loss": "1.871", "code_loss": "1.968", "value_loss_mse": "0.021", "code_ppl": "3.91", "wps": "15878.8", "ups": "0.07", "wpb": "232102", "bsz": "1024", "num_updates": "4120", "lr": "0.000206", "gnorm": "2.751", "loss_scale": "1", "train_wall": "18", "gb_free": "12.9", "wall": "52945"}
2021-10-11 10:20:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:22:45 | INFO | train_inner | {"epoch": 1, "update": 0.335, "loss": "1.872", "code_loss": "1.999", "value_loss_mse": "0.021", "code_ppl": "4", "wps": "16163", "ups": "0.07", "wpb": "240432", "bsz": "1024", "num_updates": "4130", "lr": "0.0002065", "gnorm": "2.933", "loss_scale": "1", "train_wall": "19", "gb_free": "12.9", "wall": "53094"}
2021-10-11 10:23:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:25:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:25:19 | INFO | train_inner | {"epoch": 1, "update": 0.336, "loss": "1.897", "code_loss": "1.974", "value_loss_mse": "0.021", "code_ppl": "3.93", "wps": "15525", "ups": "0.06", "wpb": "238982", "bsz": "1024", "num_updates": "4140", "lr": "0.000207", "gnorm": "3.098", "loss_scale": "1", "train_wall": "27", "gb_free": "12.9", "wall": "53247"}
[0.07342529296875, 0.1165771484375, 0.10052490234375, 0.00266265869140625, 0.69921875]
byte7 tgt value: [0.0, 0.37109375, 0.0, 0.0, 0.98828125]
byte7 pred value: [0.11065673828125, 0.380615234375, 0.1376953125, 0.006565093994140625, 0.91650390625]
byte8 tgt value: [0.0, 0.08984375, 0.0, 0.15625, 0.125]
byte8 pred value: [0.2130126953125, 0.49169921875, 0.258056640625, 0.148681640625, 0.11578369140625]
tgt code: - mov ^8 - rax
pred code: - mov ^8 rbp rax
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0015850067138671875, 0.001129150390625, 0.0016613006591796875, 0.0005884170532226562, 0.0007948875427246094]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0013990402221679688, 0.001178741455078125, 0.0017747879028320312, 0.0006265640258789062, 0.0007295608520507812]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.092041015625, 0.0015306472778320312, 0.0011472702026367188, 0.0006046295166015625, 0.006824493408203125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.090576171875, 0.0016813278198242188, 0.0012998580932617188, 0.0004878044128417969, 0.00971221923828125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.1390380859375, 0.002811431884765625, 0.002471923828125, 0.0011968612670898438, 0.013275146484375]
byte6 tgt value: [0.00390625, 0.0, 0.0, 0.01953125, 0.0078125]
byte6 pred value: [0.09027099609375, 0.00208282470703125, 0.0025119781494140625, 0.0024242401123046875, 0.01971435546875]
byte7 tgt value: [0.7734375, 0.0, 0.0, 0.41015625, 0.48828125]
byte7 pred value: [0.564453125, 0.00787353515625, 0.004505157470703125, 0.0129241943359375, 0.435791015625]
byte8 tgt value: [0.03125, 0.09375, 0.23046875, 0.171875, 0.875]
byte8 pred value: [0.36083984375, 0.1070556640625, 0.129638671875, 0.07989501953125, 0.432861328125]
tgt code: cmp mov + hexvar rbx
pred code: mov mov + hexvar rbx
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0010728836059570312, 0.0007886886596679688, 0.0002613067626953125, 0.0009074211120605469, 0.0029125213623046875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0009474754333496094, 0.0007734298706054688, 0.00051116943359375, 0.0007238388061523438, 0.0026416778564453125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0143890380859375, 0.0028553009033203125, 0.0009436607360839844, 0.0171051025390625, 0.004329681396484375]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0125732421875, 0.003337860107421875, 0.000865936279296875, 0.0160980224609375, 0.00591278076171875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.042724609375, 0.00690460205078125, 0.00257110595703125, 0.0574951171875, 0.0282745361328125]
byte6 tgt value: [0.00390625, 0.00390625, 0.0, 0.00390625, 0.0]
byte6 pred value: [0.0165252685546875, 0.00861358642578125, 0.007755279541015625, 0.0177764892578125, 0.0293121337890625]
byte7 tgt value: [0.703125, 0.703125, 0.0, 0.69140625, 0.0]
byte7 pred value: [0.5830078125, 0.59716796875, 0.03125, 0.55712890625, 0.041839599609375]
byte8 tgt value: [0.30859375, 0.0546875, 0.046875, 0.6875, 0.00390625]
byte8 pred value: [0.434814453125, 0.4423828125, 0.1724853515625, 0.365966796875, 0.070556640625]
tgt code: je pop nop hexvar +
pred code: mov mov sub hexvar +
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0007948875427246094, 0.0029125213623046875, 0.0005316734313964844, 0.001674652099609375, 0.0011119842529296875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0008263587951660156, 0.0016613006591796875, 0.00055694580078125, 0.0010404586791992188, 0.0009622573852539062]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0010404586791992188, 0.00455474853515625, 0.0004992485046386719, 0.002010345458984375, 0.00127410888671875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0009813308715820312, 0.002124786376953125, 0.0005745887756347656, 0.0027141571044921875, 0.0010480880737304688]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0015735626220703125, 0.00494384765625, 0.001178741455078125, 0.0023136138916015625, 0.0025310516357421875]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.0018463134765625, 0.00945281982421875, 0.0021152496337890625, 0.00263214111328125, 0.0021820068359375]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.00494384765625, 0.0082855224609375, 0.0179901123046875, 0.0038852691650390625, 0.00511932373046875]
byte8 tgt value: [0.09375, 0.25, 0.1875, 0.140625, 0.03125]
byte8 pred value: [0.160400390625, 0.1561279296875, 0.1676025390625, 0.09771728515625, 0.047943115234375]
tgt code: hexvar hexvar je hexvar ^8
pred code: hexvar hexvar mov hexvar ^8
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0029468536376953125, 0.01107025146484375, 0.0012788772583007812, 0.0013456344604492188, 0.0018606185913085938]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.003337860107421875, 0.010986328125, 0.0010404586791992188, 0.0012645721435546875, 0.0018100738525390625]
byte3 tgt value: [0.0, 0.09765625, 0.30859375, 0.0, 0.0]
byte3 pred value: [0.06231689453125, 0.2315673828125, 0.3662109375, 0.0010166168212890625, 0.0022258758544921875]
byte4 tgt value: [0.0, 0.03125, 0.58984375, 0.0, 0.0]
byte4 pred value: [0.050811767578125, 0.09844970703125, 0.487548828125, 0.00075531005859375, 0.0034160614013671875]
byte5 tgt value: [0.0, 0.71484375, 0.30078125, 0.0, 0.0]
byte5 pred value: [0.1884765625, 0.71826171875, 0.449951171875, 0.0018100738525390625, 0.0018606185913085938]
byte6 tgt value: [0.0, 0.89453125, 0.4453125, 0.0, 0.0]
byte6 pred value: [0.251953125, 0.822265625, 0.23974609375, 0.0018177032470703125, 0.0022525787353515625]
byte7 tgt value: [0.5703125, 0.39453125, 0.05859375, 0.0, 0.0]
byte7 pred value: [0.63134765625, 0.490966796875, 0.293212890625, 0.004024505615234375, 0.0039005279541015625]
byte8 tgt value: [0.78125, 0.375, 0.9375, 0.1015625, 0.24609375]
byte8 pred value: [0.64453125, 0.451904296875, 0.82080078125, 0.1368408203125, 0.137939453125]
tgt code: + ebx ^4 rax *
pred code: + rbx ^4 rax *
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0007615089416503906, 0.007404327392578125, 0.0007700920104980469, 0.0011653900146484375, 0.0006613731384277344]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00070953369140625, 0.0099334716796875, 0.0006694793701171875, 0.00130462646484375, 0.0009398460388183594]
byte3 tgt value: [0.49609375, 0.0, 0.0625, 0.0, 0.0]
byte3 pred value: [0.485107421875, 0.009521484375, 0.0260009765625, 0.06707763671875, 0.0018968582153320312]
byte4 tgt value: [0.99609375, 0.0, 0.21875, 0.0, 0.0]
byte4 pred value: [0.9560546875, 0.00971221923828125, 0.0200958251953125, 0.12103271484375, 0.0030517578125]
byte5 tgt value: [0.8203125, 0.0, 0.44921875, 0.0, 0.0]
byte5 pred value: [0.7119140625, 0.0300445556640625, 0.073974609375, 0.220458984375, 0.004791259765625]
byte6 tgt value: [0.203125, 0.0, 0.05859375, 0.0, 0.0078125]
byte6 pred value: [0.48291015625, 0.0211639404296875, 0.04510498046875, 0.1385498046875, 0.0116424560546875]
byte7 tgt value: [0.80078125, 0.0, 0.40625, 0.84375, 0.71875]
byte7 pred value: [0.5029296875, 0.0164642333984375, 0.5771484375, 0.45263671875, 0.488525390625]
byte8 tgt value: [0.09375, 0.078125, 0.5625, 0.5625, 0.5625]
byte8 pred value: [0.1357421875, 0.044342041015625, 0.5263671875, 0.309326171875, 0.492919921875]
tgt code: * add rcx movzx hexvar
pred code: * mov edx movzx hexvar
byte1 tgt value: [0.17578125, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.318359375, 0.0020275115966796875, 0.0037364959716796875, 0.0296478271484375, 0.003482818603515625]
byte2 tgt value: [0.14453125, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.386474609375, 0.0023593902587890625, 0.0037078857421875, 0.034881591796875, 0.003337860107421875]
byte3 tgt value: [0.54296875, 0.1875, 0.0, 0.0, 0.0]
byte3 pred value: [0.458984375, 0.07977294921875, 0.005405426025390625, 0.027069091796875, 0.00579833984375]
byte4 tgt value: [0.640625, 0.46875, 0.0, 0.0, 0.0]
byte4 pred value: 2021-10-11 10:25:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:26:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:26:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:27:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:27:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:27:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:27:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:27:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:28:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:28:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:28:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:28:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:28:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:29:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:29:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:29:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:29:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:30:44 | INFO | train_inner | {"epoch": 1, "update": 0.338, "loss": "1.848", "code_loss": "1.926", "value_loss_mse": "0.021", "code_ppl": "3.8", "wps": "6545.2", "ups": "0.03", "wpb": "213162", "bsz": "1024", "num_updates": "4150", "lr": "0.0002075", "gnorm": "3.522", "loss_scale": "1", "train_wall": "79", "gb_free": "12.9", "wall": "53573"}
2021-10-11 10:32:56 | INFO | train_inner | {"epoch": 1, "update": 0.339, "loss": "1.881", "code_loss": "1.979", "value_loss_mse": "0.021", "code_ppl": "3.94", "wps": "19065.1", "ups": "0.08", "wpb": "251133", "bsz": "1024", "num_updates": "4160", "lr": "0.000208", "gnorm": "2.926", "loss_scale": "1", "train_wall": "17", "gb_free": "12.9", "wall": "53705"}
2021-10-11 10:33:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:33:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:33:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:34:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:34:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:34:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:34:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:34:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:35:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:35:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:35:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:35:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:35:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:36:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:36:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:36:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:36:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:36:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:37:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:37:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:37:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:37:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:37:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:38:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:38:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:38:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:38:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:39:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:39:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:39:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:39:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:39:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:40:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:40:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0006437301635742188, 0.0009546279907226562, 0.000583648681640625, 0.0008726119995117188, 0.0009927749633789062]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0007734298706054688, 0.0010204315185546875, 0.0006337165832519531, 0.0009217262268066406, 0.0010042190551757812]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.002590179443359375, 0.004055023193359375, 0.0026721954345703125, 0.0007495880126953125, 0.0009074211120605469]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.00397491455078125, 0.00690460205078125, 0.005138397216796875, 0.0008459091186523438, 0.0011205673217773438]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.007232666015625, 0.0239105224609375, 0.00714874267578125, 0.0013246536254882812, 0.0016164779663085938]
byte6 tgt value: [0.01953125, 0.0, 0.01953125, 0.0, 0.0]
byte6 pred value: [0.0100555419921875, 0.0241851806640625, 0.01049041748046875, 0.0028781890869140625, 0.002811431884765625]
byte7 tgt value: [0.62109375, 0.0, 0.61328125, 0.0, 0.0]
byte7 pred value: [0.638671875, 0.043853759765625, 0.5927734375, 0.00930023193359375, 0.004756927490234375]
byte8 tgt value: [0.921875, 0.75, 0.203125, 0.09375, 0.0625]
byte8 pred value: [0.40234375, 0.2144775390625, 0.448974609375, 0.1729736328125, 0.142822265625]
tgt code: rdi ^8 rax ^4 rax
pred code: rsi ^4 rax ^4 rip
2021-10-11 10:40:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:40:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:41:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:41:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:41:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:41:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:41:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:42:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:42:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:42:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:42:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:43:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:43:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:43:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:43:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:43:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:44:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:44:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:44:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:44:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:45:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:45:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:45:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:45:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:45:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:46:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:46:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:46:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:46:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:47:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:47:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:47:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:47:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:47:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:48:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:48:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:48:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:48:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:48:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:49:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:49:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:49:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:49:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:49:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:50:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:50:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:50:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:50:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:51:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:51:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:51:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:51:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:51:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:52:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:52:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:52:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:52:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:53:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:53:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:53:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.004199981689453125, 0.006565093994140625, 0.000415802001953125, 0.0016422271728515625, 0.0023136138916015625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.004627227783203125, 0.00847625732421875, 0.0003712177276611328, 0.0020904541015625, 0.0025615692138671875]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.49609375]
byte3 pred value: [0.004627227783203125, 0.10430908203125, 0.00106048583984375, 0.01056671142578125, 0.49755859375]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.99609375]
byte4 pred value: [0.00595855712890625, 0.2081298828125, 0.0027141571044921875, 0.02655029296875, 0.99462890625]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.69921875]
byte5 pred value: [0.01049041748046875, 0.162109375, 0.0020198822021484375, 0.0135345458984375, 0.77880859375]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.36328125]
byte6 pred value: [0.01312255859375, 0.0784912109375, 0.003124237060546875, 0.0090179443359375, 0.342041015625]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.234375]
byte7 pred value: [0.0129241943359375, 0.08587646484375, 0.00803375244140625, 0.011871337890625, 0.278564453125]
byte8 tgt value: [0.00390625, 0.203125, 0.6875, 0.171875, 0.25]
byte8 pred value: [0.059539794921875, 0.139404296875, 0.4521484375, 0.09088134765625, 0.265380859375]
tgt code: jmp ^2 rax add je
pred code: je ^2 rax je cmp
2021-10-11 10:53:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:53:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:54:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:54:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:54:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:54:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:54:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0003275871276855469, 0.0005054473876953125, 0.0004425048828125, 0.0003654956817626953, 0.0005769729614257812]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00036835670471191406, 0.0005273818969726562, 0.0005211830139160156, 0.00037860870361328125, 0.000743865966796875]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0007123947143554688, 0.0029354095458984375, 0.003551483154296875, 0.0009584426879882812, 0.001178741455078125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0011072158813476562, 0.0034427642822265625, 0.004718780517578125, 0.0013885498046875, 0.00127410888671875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.001361846923828125, 0.0057525634765625, 0.007404327392578125, 0.00183868408203125, 0.00260162353515625]
byte6 tgt value: [0.0, 0.00390625, 0.01171875, 0.0, 0.01171875]
byte6 pred value: [0.001995086669921875, 0.0082550048828125, 0.01056671142578125, 0.0026721954345703125, 0.01129150390625]
byte7 tgt value: [0.0, 0.32421875, 0.37890625, 0.0, 0.96875]
byte7 pred value: [0.01016998291015625, 0.416015625, 0.404052734375, 0.0139007568359375, 0.54052734375]
byte8 tgt value: [0.125, 0.5625, 0.07421875, 0.00390625, 0.73046875]
byte8 pred value: [0.270263671875, 0.479248046875, 0.43310546875, 0.29052734375, 0.485595703125]
tgt code: rax hexvar lea rax r15
pred code: edx hexvar lea rax edx
2021-10-11 10:55:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:55:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:55:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:55:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:56:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:56:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:56:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:56:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:57:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:57:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:57:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:57:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:57:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:58:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:58:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:58:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:58:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:58:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:59:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:59:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:59:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:59:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 10:59:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:00:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:00:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:00:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:00:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:00:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:01:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:01:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:01:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:01:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:02:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:02:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:02:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:02:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:02:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:03:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:03:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:03:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:03:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:03:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:04:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:04:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:04:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:04:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:05:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:05:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:05:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:05:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-10-11 11:05:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2021-10-11 11:06:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 11:07:41 | INFO | train_inner | {"epoch": 1, "update": 0.352, "loss": "1.826", "code_loss": "1.954", "value_loss_mse": "0.02", "code_ppl": "3.88", "wps": "1091.2", "ups": "0", "wpb": "227507", "bsz": "1024", "num_updates": "4170", "lr": "0.0002085", "gnorm": "3.179", "loss_scale": "0.25", "train_wall": "292", "gb_free": "12.9", "wall": "55790"}
2021-10-11 11:09:42 | INFO | train_inner | {"epoch": 1, "update": 0.353, "loss": "1.843", "code_loss": "1.916", "value_loss_mse": "0.021", "code_ppl": "3.77", "wps": "18857", "ups": "0.08", "wpb": "228346", "bsz": "1024", "num_updates": "4180", "lr": "0.000209", "gnorm": "3.244", "loss_scale": "0.25", "train_wall": "39", "gb_free": "12.9", "wall": "55911"}
2021-10-11 11:12:07 | INFO | train_inner | {"epoch": 1, "update": 0.354, "loss": "1.836", "code_loss": "1.959", "value_loss_mse": "0.021", "code_ppl": "3.89", "wps": "18652.2", "ups": "0.07", "wpb": "270205", "bsz": "1024", "num_updates": "4190", "lr": "0.0002095", "gnorm": "2.599", "loss_scale": "0.25", "train_wall": "19", "gb_free": "12.9", "wall": "56056"}
2021-10-11 11:14:10 | INFO | train_inner | {"epoch": 1, "update": 0.355, "loss": "1.815", "code_loss": "1.935", "value_loss_mse": "0.02", "code_ppl": "3.82", "wps": "18881", "ups": "0.08", "wpb": "231398", "bsz": "1024", "num_updates": "4200", "lr": "0.00021", "gnorm": "2.517", "loss_scale": "0.25", "train_wall": "15", "gb_free": "12.9", "wall": "56178"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0033111572265625, 0.00930023193359375, 0.0002913475036621094, 0.0005211830139160156, 0.00395965576171875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.004467010498046875, 0.00600433349609375, 0.00034999847412109375, 0.0008134841918945312, 0.004150390625]
byte3 tgt value: [0.0, 0.1640625, 0.0, 0.0, 0.0]
byte3 pred value: [0.005279541015625, 0.2822265625, 0.0006022453308105469, 0.001239776611328125, 0.026611328125]
byte4 tgt value: [0.0, 0.77734375, 0.0, 0.0, 0.0]
byte4 pred value: [0.0082550048828125, 0.87109375, 0.0005617141723632812, 0.0016355514526367188, 0.04803466796875]
byte5 tgt value: [0.0, 0.65625, 0.0, 0.0, 0.0]
byte5 pred value: [0.01090240478515625, 0.64892578125, 0.003795623779296875, 0.0023784637451171875, 0.03753662109375]
byte6 tgt value: [0.0, 0.2109375, 0.0, 0.0, 0.0]
byte6 pred value: [0.0121002197265625, 0.205810546875, 0.005279541015625, 0.0024929046630859375, 0.025177001953125]
byte7 tgt value: [0.0, 0.05078125, 0.0, 0.0, 0.0]
byte7 pred value: [0.01422882080078125, 0.103759765625, 0.0038852691650390625, 0.0026416778564453125, 0.0293731689453125]
byte8 tgt value: [0.0, 0.0625, 0.03125, 0.0, 0.00390625]
byte8 pred value: [0.10107421875, 0.399658203125, 0.04107666015625, 0.059326171875, 0.10357666015625]
tgt code: mov push rbp hexvar call
pred code: xor pop r12 hexvar call
byte1 tgt value: [0.0, 0.0, 0.0, 0.46875, 0.0]
byte1 pred value: [0.00036263465881347656, 0.0010118484497070312, 0.001220703125, 0.395263671875, 0.0016489028930664062]
byte2 tgt value: [0.0, 0.0, 0.0, 0.1484375, 0.0]
byte2 pred value: [0.0005817413330078125, 0.0013780593872070312, 0.0011606216430664062, 0.436767578125, 0.00142669677734375]
byte3 tgt value: [0.0, 0.0, 0.0, 0.8984375, 0.109375]
byte3 pred value: [0.00274658203125, 0.0020198822021484375, 0.0018243789672851562, 0.51708984375, 0.129638671875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.17578125, 0.25390625]
byte4 pred value: [0.0015544891357421875, 0.0015363693237304688, 0.0031604766845703125, 0.5703125, 0.244384765625]
byte5 tgt value: [0.0, 0.0, 0.0, 0.91796875, 0.55859375]
byte5 pred value: [0.00579833984375, 0.0033512115478515625, 0.00586700439453125, 0.552734375, 0.5712890625]
byte6 tgt value: [0.01953125, 0.0, 0.0, 0.25390625, 0.12890625]
byte6 pred value: [0.0182952880859375, 0.00572967529296875, 0.005664825439453125, 0.64404296875, 0.06927490234375]
byte7 tgt value: [0.421875, 0.0, 0.0, 0.98046875, 0.26953125]
byte7 pred value: [0.42041015625, 0.0188751220703125, 0.00885009765625, 0.6181640625, 0.33349609375]
byte8 tgt value: [0.984375, 0.03125, 0.2265625, 0.04296875, 0.75]
byte8 pred value: [0.4599609375, 0.0616455078125, 0.1343994140625, 0.50537109375, 0.71826171875]
tgt code: ^8 rbx rdx hexvar pop
pred code: ^8 rbx rdi hexvar mov
2021-10-11 11:16:11 | INFO | train_inner | {"epoch": 1, "update": 0.355, "loss": "1.827", "code_loss": "1.943", "value_loss_mse": "0.02", "code_ppl": "3.84", "wps": "17972.5", "ups": "0.08", "wpb": "217616", "bsz": "1024", "num_updates": "4210", "lr": "0.0002105", "gnorm": "3.682", "loss_scale": "0.25", "train_wall": "15", "gb_free": "12.9", "wall": "56299"}
2021-10-11 11:18:24 | INFO | train_inner | {"epoch": 1, "update": 0.356, "loss": "1.86", "code_loss": "1.944", "value_loss_mse": "0.021", "code_ppl": "3.85", "wps": "18842.2", "ups": "0.08", "wpb": "250918", "bsz": "1024", "num_updates": "4220", "lr": "0.000211", "gnorm": "2.926", "loss_scale": "0.25", "train_wall": "17", "gb_free": "12.9", "wall": "56432"}
2021-10-11 11:20:26 | INFO | train_inner | {"epoch": 1, "update": 0.357, "loss": "1.844", "code_loss": "1.927", "value_loss_mse": "0.021", "code_ppl": "3.8", "wps": "18512.4", "ups": "0.08", "wpb": "226554", "bsz": "1024", "num_updates": "4230", "lr": "0.0002115", "gnorm": "3.328", "loss_scale": "0.25", "train_wall": "15", "gb_free": "12.9", "wall": "56555"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0029239654541015625, 0.0006213188171386719, 0.024139404296875, 0.00064849853515625, 0.0024051666259765625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0027256011962890625, 0.0007181167602539062, 0.0217742919921875, 0.0006337165832519531, 0.002216339111328125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0035247802734375, 0.00443267822265625, 0.0186920166015625, 0.0005817413330078125, 0.002521514892578125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.003040313720703125, 0.005664825439453125, 0.021697998046875, 0.0005335807800292969, 0.001941680908203125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.00307464599609375, 0.007232666015625, 0.0244293212890625, 0.0010814666748046875, 0.0023136138916015625]
byte6 tgt value: [0.0, 0.0078125, 0.0, 0.0, 0.0]
byte6 pred value: [0.0033626556396484375, 0.01267242431640625, 0.0278472900390625, 0.0009889602661132812, 0.0017137527465820312]
byte7 tgt value: [0.0, 0.46484375, 0.0, 0.0, 0.0]
byte7 pred value: [0.0053863525390625, 0.4765625, 0.031494140625, 0.004116058349609375, 0.00714874267578125]
byte8 tgt value: [0.00390625, 0.5, 0.15625, 0.046875, 0.0078125]
byte8 pred value: [0.026458740234375, 0.470458984375, 0.10540771484375, 0.07171630859375, 0.06781005859375]
tgt code: r13 mov r15d jle mov
pred code: rdi mov edx call mov
2021-10-11 11:22:36 | INFO | train_inner | {"epoch": 1, "update": 0.358, "loss": "1.842", "code_loss": "1.921", "value_loss_mse": "0.021", "code_ppl": "3.79", "wps": "18736", "ups": "0.08", "wpb": "242352", "bsz": "1024", "num_updates": "4240", "lr": "0.000212", "gnorm": "2.953", "loss_scale": "0.25", "train_wall": "16", "gb_free": "12.9", "wall": "56684"}
2021-10-11 11:24:42 | INFO | train_inner | {"epoch": 1, "update": 0.359, "loss": "1.817", "code_loss": "1.927", "value_loss_mse": "0.02", "code_ppl": "3.8", "wps": "19238.1", "ups": "0.08", "wpb": "244098", "bsz": "1024", "num_updates": "4250", "lr": "0.0002125", "gnorm": "3.223", "loss_scale": "0.25", "train_wall": "16", "gb_free": "12.9", "wall": "56811"}
2021-10-11 11:27:01 | INFO | train_inner | {"epoch": 1, "update": 0.359, "loss": "1.795", "code_loss": "1.917", "value_loss_mse": "0.02", "code_ppl": "3.78", "wps": "18284.4", "ups": "0.07", "wpb": "252634", "bsz": "1024", "num_updates": "4260", "lr": "0.000213", "gnorm": "2.695", "loss_scale": "0.25", "train_wall": "61", "gb_free": "12.9", "wall": "56949"}
2021-10-11 11:29:12 | INFO | train_inner | {"epoch": 1, "update": 0.36, "loss": "1.78", "code_loss": "1.922", "value_loss_mse": "0.02", "code_ppl": "3.79", "wps": "19212.6", "ups": "0.08", "wpb": "252317", "bsz": "1024", "num_updates": "4270", "lr": "0.0002135", "gnorm": "2.763", "loss_scale": "0.25", "train_wall": "92", "gb_free": "12.9", "wall": "57081"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.006984710693359375, 0.0007977485656738281, 0.004608154296875, 0.0008831024169921875, 0.005138397216796875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.006439208984375, 0.0007700920104980469, 0.004962921142578125, 0.0007853507995605469, 0.0043487548828125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.007404327392578125, 0.00530242919921875, 0.00547027587890625, 0.00130462646484375, 0.005512237548828125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.006439208984375, 0.018829345703125, 0.005641937255859375, 0.0008831024169921875, 0.00469970703125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0090179443359375, 0.005405426025390625, 0.00919342041015625, 0.003223419189453125, 0.008514404296875]
byte6 tgt value: [0.0, 0.0078125, 0.0, 0.0078125, 0.0]
byte6 pred value: [0.01078033447265625, 0.00891876220703125, 0.01129150390625, 0.00997161865234375, 0.0082855224609375]
byte7 tgt value: [0.0, 0.51171875, 0.0, 0.51171875, 0.0]
byte7 pred value: [0.0129241943359375, 0.5322265625, 0.0136871337890625, 0.56591796875, 0.008544921875]
byte8 tgt value: [0.125, 0.5078125, 0.01171875, 0.5078125, 0.03515625]
byte8 pred value: [0.06982421875, 0.46044921875, 0.0831298828125, 0.509765625, 0.06561279296875]
tgt code: hexvar rbx rbp pop rax
pred code: hexvar rbp rbp mov rax
2021-10-11 11:31:20 | INFO | train_inner | {"epoch": 1, "update": 0.361, "loss": "1.869", "code_loss": "1.895", "value_loss_mse": "0.021", "code_ppl": "3.72", "wps": "17815.9", "ups": "0.08", "wpb": "228291", "bsz": "1024", "num_updates": "4280", "lr": "0.000214", "gnorm": "3.644", "loss_scale": "0.25", "train_wall": "100", "gb_free": "12.9", "wall": "57209"}
2021-10-11 11:33:26 | INFO | train_inner | {"epoch": 1, "update": 0.362, "loss": "1.794", "code_loss": "1.895", "value_loss_mse": "0.02", "code_ppl": "3.72", "wps": "17492.1", "ups": "0.08", "wpb": "219632", "bsz": "1024", "num_updates": "4290", "lr": "0.0002145", "gnorm": "3.845", "loss_scale": "0.25", "train_wall": "99", "gb_free": "13.5", "wall": "57334"}
2021-10-11 11:35:30 | INFO | train_inner | {"epoch": 1, "update": 0.363, "loss": "1.826", "code_loss": "1.915", "value_loss_mse": "0.02", "code_ppl": "3.77", "wps": "18705.8", "ups": "0.08", "wpb": "232166", "bsz": "1024", "num_updates": "4300", "lr": "0.000215", "gnorm": "3.138", "loss_scale": "0.25", "train_wall": "82", "gb_free": "12.9", "wall": "57458"}
2021-10-11 11:37:44 | INFO | train_inner | {"epoch": 1, "update": 0.363, "loss": "1.807", "code_loss": "1.891", "value_loss_mse": "0.02", "code_ppl": "3.71", "wps": "17631.3", "ups": "0.07", "wpb": "236649", "bsz": "1024", "num_updates": "4310", "lr": "0.0002155", "gnorm": "3.059", "loss_scale": "0.25", "train_wall": "109", "gb_free": "12.9", "wall": "57593"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0009288787841796875, 0.000904083251953125, 0.002124786376953125, 0.0022792816162109375, 0.0007581710815429688]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0012598037719726562, 0.0008625984191894531, 0.0017137527465820312, 0.0021495819091796875, 0.0007948875427246094]
byte3 tgt value: [0.0, 0.2890625, 0.0, 0.2890625, 0.0]
byte3 pred value: [0.001239776611328125, 0.406982421875, 0.251953125, 0.359619140625, 0.0012693405151367188]
byte4 tgt value: [0.0, 0.640625, 0.0, 0.640625, 0.0]
byte4 pred value: [0.0017681121826171875, 0.55419921875, 0.326416015625, 0.5205078125, 0.0011739730834960938]
byte5 tgt value: [0.0, 0.1953125, 0.0, 0.1953125, 0.0]
byte5 pred value: [0.002140045166015625, 0.428466796875, 0.31201171875, 0.407470703125, 0.0023784637451171875]
byte6 tgt value: [0.0, 0.5703125, 0.0, 0.56640625, 0.0]
byte6 pred value: [0.0025501251220703125, 0.499755859375, 0.34423828125, 0.477294921875, 0.0017337799072265625]
byte7 tgt value: [0.0, 0.890625, 0.0, 0.01953125, 0.0]
byte7 pred value: [0.00582122802734375, 0.61474609375, 0.279296875, 0.401611328125, 0.0035247802734375]
byte8 tgt value: [0.0625, 0.375, 0.2109375, 0.5625, 0.03125]
byte8 pred value: [0.06939697265625, 0.57470703125, 0.46630859375, 0.49609375, 0.06268310546875]
tgt code: + mov rax rax ^8
pred code: + mov rax rax ^8
2021-10-11 11:39:49 | INFO | train_inner | {"epoch": 1, "update": 0.364, "loss": "1.78", "code_loss": "1.894", "value_loss_mse": "0.02", "code_ppl": "3.72", "wps": "18487.8", "ups": "0.08", "wpb": "230752", "bsz": "1024", "num_updates": "4320", "lr": "0.000216", "gnorm": "3.86", "loss_scale": "0.25", "train_wall": "81", "gb_free": "12.9", "wall": "57717"}
2021-10-11 11:41:51 | INFO | train_inner | {"epoch": 1, "update": 0.365, "loss": "1.782", "code_loss": "1.907", "value_loss_mse": "0.02", "code_ppl": "3.75", "wps": "18455.6", "ups": "0.08", "wpb": "225720", "bsz": "1024", "num_updates": "4330", "lr": "0.0002165", "gnorm": "3.445", "loss_scale": "0.25", "train_wall": "26", "gb_free": "12.9", "wall": "57840"}
2021-10-11 11:44:04 | INFO | train_inner | {"epoch": 1, "update": 0.366, "loss": "1.823", "code_loss": "1.922", "value_loss_mse": "0.02", "code_ppl": "3.79", "wps": "18654.8", "ups": "0.08", "wpb": "247213", "bsz": "1024", "num_updates": "4340", "lr": "0.000217", "gnorm": "2.99", "loss_scale": "0.25", "train_wall": "17", "gb_free": "12.9", "wall": "57972"}
2021-10-11 11:46:06 | INFO | train_inner | {"epoch": 1, "update": 0.367, "loss": "1.806", "code_loss": "1.893", "value_loss_mse": "0.02", "code_ppl": "3.71", "wps": "19386.9", "ups": "0.08", "wpb": "237053", "bsz": "1024", "num_updates": "4350", "lr": "0.0002175", "gnorm": "3.173", "loss_scale": "0.25", "train_wall": "15", "gb_free": "12.9", "wall": "58095"}
2021-10-11 11:48:14 | INFO | train_inner | {"epoch": 1, "update": 0.367, "loss": "1.817", "code_loss": "1.87", "value_loss_mse": "0.02", "code_ppl": "3.65", "wps": "17889", "ups": "0.08", "wpb": "228541", "bsz": "1024", "num_updates": "4360", "lr": "0.000218", "gnorm": "3.818", "loss_scale": "0.25", "train_wall": "16", "gb_free": "12.9", "wall": "58222"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0008263587951660156, 0.0027256011962890625, 0.003124237060546875, 0.0005011558532714844, 0.001201629638671875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0007042884826660156, 0.0026111602783203125, 0.0031604766845703125, 0.0005998611450195312, 0.0009660720825195312]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0010404586791992188, 0.035064697265625, 0.0029926300048828125, 0.00208282470703125, 0.03875732421875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0008168220520019531, 0.06451416015625, 0.0030879974365234375, 0.0012645721435546875, 0.07135009765625]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0009398460388183594, 0.06964111328125, 0.004116058349609375, 0.0029125213623046875, 0.072265625]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.0015611648559570312, 0.08270263671875, 0.00653839111328125, 0.01507568359375, 0.109130859375]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.609375]
byte7 pred value: [0.004070281982421875, 0.305908203125, 0.007259368896484375, 0.12139892578125, 0.5673828125]
byte8 tgt value: [0.125, 0.0859375, 0.24609375, 0.125, 0.25]
byte8 pred value: [0.09912109375, 0.26123046875, 0.11419677734375, 0.25537109375, 0.3544921875]
tgt code: + + ^8 rax je
pred code: + + ^8 rdi je
2021-10-11 11:50:25 | INFO | train_inner | {"epoch": 1, "update": 0.368, "loss": "1.798", "code_loss": "1.875", "value_loss_mse": "0.02", "code_ppl": "3.67", "wps": "17442.3", "ups": "0.08", "wpb": "229222", "bsz": "1024", "num_updates": "4370", "lr": "0.0002185", "gnorm": "2.929", "loss_scale": "0.25", "train_wall": "17", "gb_free": "12.9", "wall": "58354"}
2021-10-11 11:52:35 | INFO | train_inner | {"epoch": 1, "update": 0.369, "loss": "1.795", "code_loss": "1.889", "value_loss_mse": "0.02", "code_ppl": "3.7", "wps": "18664", "ups": "0.08", "wpb": "242963", "bsz": "1024", "num_updates": "4380", "lr": "0.000219", "gnorm": "3.051", "loss_scale": "0.25", "train_wall": "16", "gb_free": "12.9", "wall": "58484"}
2021-10-11 11:54:36 | INFO | train_inner | {"epoch": 1, "update": 0.37, "loss": "1.798", "code_loss": "1.892", "value_loss_mse": "0.02", "code_ppl": "3.71", "wps": "19475", "ups": "0.08", "wpb": "235981", "bsz": "1024", "num_updates": "4390", "lr": "0.0002195", "gnorm": "2.864", "loss_scale": "0.25", "train_wall": "34", "gb_free": "12.9", "wall": "58605"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0053863525390625, 0.0022258758544921875, 0.004962921142578125, 0.0029239654541015625, 0.0023784637451171875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.005279541015625, 0.002323150634765625, 0.003692626953125, 0.0034427642822265625, 0.00279998779296875]
byte3 tgt value: [0.0, 0.3046875, 0.0, 0.0, 0.0]
byte3 pred value: [0.005062103271484375, 0.292236328125, 0.039794921875, 0.0030879974365234375, 0.004329681396484375]
byte4 tgt value: [0.0, 0.40234375, 0.0, 0.0, 0.0]
byte4 pred value: [0.00482940673828125, 0.52490234375, 0.06854248046875, 0.0020351409912109375, 0.0026531219482421875]
byte5 tgt value: [0.0, 0.0078125, 0.0, 0.0, 0.0]
byte5 pred value: [0.004810333251953125, 0.12249755859375, 0.019378662109375, 0.0022869110107421875, 0.003337860107421875]
byte6 tgt value: [0.0, 0.1171875, 0.0, 0.0, 0.0]
byte6 pred value: [0.00536346435546875, 0.1646728515625, 0.034820556640625, 0.0030155181884765625, 0.0033626556396484375]
byte7 tgt value: [0.0, 0.87109375, 0.55859375, 0.0, 0.0]
byte7 pred value: [0.006511688232421875, 0.71875, 0.5517578125, 0.006145477294921875, 0.004573822021484375]
byte8 tgt value: [0.0546875, 0.34375, 0.34375, 0.03125, 0.5625]
byte8 pred value: [0.11199951171875, 0.482177734375, 0.333740234375, 0.0809326171875, 0.13671875]
tgt code: hexvar rax + call
pred code: hexvar rax + call
2021-10-11 11:56:36 | INFO | train_inner | {"epoch": 1, "update": 0.371, "loss": "1.784", "code_loss": "1.877", "value_loss_mse": "0.02", "code_ppl": "3.67", "wps": "18587.8", "ups": "0.08", "wpb": "223030", "bsz": "1024", "num_updates": "4400", "lr": "0.00022", "gnorm": "3.268", "loss_scale": "0.25", "train_wall": "41", "gb_free": "12.9", "wall": "58725"}
2021-10-11 11:58:47 | INFO | train_inner | {"epoch": 1, "update": 0.371, "loss": "1.785", "code_loss": "1.889", "value_loss_mse": "0.02", "code_ppl": "3.7", "wps": "18345.8", "ups": "0.08", "wpb": "240148", "bsz": "1024", "num_updates": "4410", "lr": "0.0002205", "gnorm": "4.075", "loss_scale": "0.25", "train_wall": "53", "gb_free": "12.9", "wall": "58856"}
2021-10-11 12:00:49 | INFO | train_inner | {"epoch": 1, "update": 0.372, "loss": "1.807", "code_loss": "1.859", "value_loss_mse": "0.02", "code_ppl": "3.63", "wps": "18195.1", "ups": "0.08", "wpb": "221808", "bsz": "1024", "num_updates": "4420", "lr": "0.000221", "gnorm": "4.286", "loss_scale": "0.25", "train_wall": "83", "gb_free": "12.9", "wall": "58978"}
2021-10-11 12:02:59 | INFO | train_inner | {"epoch": 1, "update": 0.373, "loss": "1.805", "code_loss": "1.889", "value_loss_mse": "0.02", "code_ppl": "3.7", "wps": "19010.8", "ups": "0.08", "wpb": "245955", "bsz": "1024", "num_updates": "4430", "lr": "0.0002215", "gnorm": "3.704", "loss_scale": "0.25", "train_wall": "59", "gb_free": "12.9", "wall": "59107"}
2021-10-11 12:04:59 | INFO | train_inner | {"epoch": 1, "update": 0.374, "loss": "1.797", "code_loss": "1.858", "value_loss_mse": "0.02", "code_ppl": "3.62", "wps": "18903.3", "ups": "0.08", "wpb": "228278", "bsz": "1024", "num_updates": "4440", "lr": "0.000222", "gnorm": "3.563", "loss_scale": "0.25", "train_wall": "19", "gb_free": "12.9", "wall": "59228"}
2021-10-11 12:07:03 | INFO | train_inner | {"epoch": 1, "update": 0.375, "loss": "1.779", "code_loss": "1.86", "value_loss_mse": "0.02", "code_ppl": "3.63", "wps": "19126", "ups": "0.08", "wpb": "236973", "bsz": "1024", "num_updates": "4450", "lr": "0.0002225", "gnorm": "3.494", "loss_scale": "0.25", "train_wall": "22", "gb_free": "12.9", "wall": "59352"}
2021-10-11 12:09:10 | INFO | train_inner | {"epoch": 1, "update": 0.375, "loss": "1.813", "code_loss": "1.873", "value_loss_mse": "0.02", "code_ppl": "3.66", "wps": "18144.7", "ups": "0.08", "wpb": "230832", "bsz": "1024", "num_updates": "4460", "lr": "0.000223", "gnorm": "3.917", "loss_scale": "0.25", "train_wall": "16", "gb_free": "12.9", "wall": "59479"}
2021-10-11 12:11:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 12:11:22 | INFO | train_inner | {"epoch": 1, "update": 0.376, "loss": "1.765", "code_loss": "1.851", "value_loss_mse": "0.02", "code_ppl": "3.61", "wps": "17350.1", "ups": "0.08", "wpb": "228136", "bsz": "1024", "num_updates": "4470", "lr": "0.0002235", "gnorm": "3.827", "loss_scale": "0.25", "train_wall": "37", "gb_free": "12.9", "wall": "59611"}
2021-10-11 12:13:25 | INFO | train_inner | {"epoch": 1, "update": 0.377, "loss": "1.769", "code_loss": "1.854", "value_loss_mse": "0.02", "code_ppl": "3.61", "wps": "18637.5", "ups": "0.08", "wpb": "229555", "bsz": "1024", "num_updates": "4480", "lr": "0.000224", "gnorm": "4.041", "loss_scale": "0.25", "train_wall": "64", "gb_free": "12.9", "wall": "59734"}
2021-10-11 12:15:34 | INFO | train_inner | {"epoch": 1, "update": 0.378, "loss": "1.811", "code_loss": "1.865", "value_loss_mse": "0.02", "code_ppl": "3.64", "wps": "19029.6", "ups": "0.08", "wpb": "246032", "bsz": "1024", "num_updates": "4490", "lr": "0.0002245", "gnorm": "3.266", "loss_scale": "0.25", "train_wall": "64", "gb_free": "12.9", "wall": "59863"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00238800048828125, 0.001972198486328125, 0.0026721954345703125, 0.005428314208984375, 0.0007181167602539062]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0024814605712890625, 0.0018892288208007812, 0.0022430419921875, 0.004924774169921875, 0.0006289482116699219]
byte3 tgt value: [0.0, 0.48046875, 0.48046875, 0.0, 0.0]
byte3 pred value: [0.081787109375, 0.42822265625, 0.426025390625, 0.00327301025390625, 0.0005860328674316406]
byte4 tgt value: [0.0, 0.2421875, 0.2421875, 0.0, 0.0]
byte4 pred value: [0.1256103515625, 0.33154296875, 0.347412109375, 0.0039005279541015625, 0.00037860870361328125]
byte5 tgt value: [0.0, 0.64453125, 0.64453125, 0.0, 0.0]
byte5 pred value: [0.110107421875, 0.53515625, 0.5751953125, 0.00547027587890625, 0.0007762908935546875]
byte6 tgt value: [0.0, 0.84375, 0.84375, 0.0, 0.0]
byte6 pred value: [0.05340576171875, 0.47314453125, 0.496337890625, 0.00731658935546875, 0.001438140869140625]
byte7 tgt value: [0.5078125, 0.20703125, 0.20703125, 0.0, 0.0]
byte7 pred value: [0.369873046875, 0.49169921875, 0.498046875, 0.00818634033203125, 0.0095977783203125]
byte8 tgt value: [0.81640625, 0.0, 0.0, 0.0390625, 0.0625]
byte8 pred value: [0.433837890625, 0.55908203125, 0.6123046875, 0.1295166015625, 0.09503173828125]
tgt code: jnbe rbx nop mov edi
pred code: mov hexvar nop mov eax
2021-10-11 12:17:44 | INFO | train_inner | {"epoch": 1, "update": 0.379, "loss": "1.736", "code_loss": "1.844", "value_loss_mse": "0.019", "code_ppl": "3.59", "wps": "18416.6", "ups": "0.08", "wpb": "239421", "bsz": "1024", "num_updates": "4500", "lr": "0.000225", "gnorm": "3.08", "loss_scale": "0.25", "train_wall": "76", "gb_free": "12.9", "wall": "59993"}
2021-10-11 12:19:50 | INFO | train_inner | {"epoch": 1, "update": 0.38, "loss": "1.748", "code_loss": "1.831", "value_loss_mse": "0.02", "code_ppl": "3.56", "wps": "18605", "ups": "0.08", "wpb": "234108", "bsz": "1024", "num_updates": "4510", "lr": "0.0002255", "gnorm": "4.757", "loss_scale": "0.25", "train_wall": "61", "gb_free": "12.9", "wall": "60119"}
2021-10-11 12:20:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 12:22:03 | INFO | train_inner | {"epoch": 1, "update": 0.38, "loss": "1.756", "code_loss": "1.821", "value_loss_mse": "0.02", "code_ppl": "3.53", "wps": "16701.2", "ups": "0.08", "wpb": "220998", "bsz": "1024", "num_updates": "4520", "lr": "0.000226", "gnorm": "4.848", "loss_scale": "0.25", "train_wall": "61", "gb_free": "12.9", "wall": "60251"}
2021-10-11 12:24:13 | INFO | train_inner | {"epoch": 1, "update": 0.381, "loss": "1.739", "code_loss": "1.832", "value_loss_mse": "0.019", "code_ppl": "3.56", "wps": "18262.5", "ups": "0.08", "wpb": "238968", "bsz": "1024", "num_updates": "4530", "lr": "0.0002265", "gnorm": "3.398", "loss_scale": "0.25", "train_wall": "40", "gb_free": "12.9", "wall": "60382"}
2021-10-11 12:26:33 | INFO | train_inner | {"epoch": 1, "update": 0.382, "loss": "1.791", "code_loss": "1.861", "value_loss_mse": "0.02", "code_ppl": "3.63", "wps": "18652.9", "ups": "0.07", "wpb": "259581", "bsz": "1024", "num_updates": "4540", "lr": "0.000227", "gnorm": "3.338", "loss_scale": "0.25", "train_wall": "110", "gb_free": "12.9", "wall": "60521"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00030303001403808594, 0.00274658203125, 0.0011072158813476562, 0.0024433135986328125, 0.00217437744140625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0003077983856201172, 0.00183868408203125, 0.0012350082397460938, 0.0034427642822265625, 0.0025310516357421875]
byte3 tgt value: [0.0, 0.0, 0.19921875, 0.0, 0.49609375]
byte3 pred value: [0.00154876708984375, 0.0034160614013671875, 0.1171875, 0.01322174072265625, 0.497802734375]
byte4 tgt value: [0.0, 0.0, 0.74609375, 0.0, 0.99609375]
byte4 pred value: [0.0015916824340820312, 0.00577545166015625, 0.424072265625, 0.0297088623046875, 0.98681640625]
byte5 tgt value: [0.0, 0.0, 0.27734375, 0.0, 0.69921875]
byte5 pred value: [0.0060272216796875, 0.0360107421875, 0.1087646484375, 0.01363372802734375, 0.78662109375]
byte6 tgt value: [0.015625, 0.0, 0.23046875, 0.0, 0.39453125]
byte6 pred value: [0.03985595703125, 0.03759765625, 0.0802001953125, 0.0141143798828125, 0.413330078125]
byte7 tgt value: [0.8671875, 0.0, 0.0, 0.0625, 0.296875]
byte7 pred value: [0.78076171875, 0.062225341796875, 0.455322265625, 0.0189056396484375, 0.4892578125]
byte8 tgt value: [0.2578125, 0.0, 0.3125, 0.0, 0.9375]
byte8 pred value: [0.4990234375, 0.09771728515625, 0.49169921875, 0.0284423828125, 0.08648681640625]
tgt code: hexvar test esi hexvar hexvar
pred code: hexvar je esi hexvar rsp
2021-10-11 12:28:34 | INFO | train_inner | {"epoch": 1, "update": 0.383, "loss": "1.725", "code_loss": "1.838", "value_loss_mse": "0.019", "code_ppl": "3.57", "wps": "18969.1", "ups": "0.08", "wpb": "230049", "bsz": "1024", "num_updates": "4550", "lr": "0.0002275", "gnorm": "4.003", "loss_scale": "0.25", "train_wall": "32", "gb_free": "12.9", "wall": "60643"}
2021-10-11 12:30:46 | INFO | train_inner | {"epoch": 1, "update": 0.384, "loss": "1.763", "code_loss": "1.836", "value_loss_mse": "0.02", "code_ppl": "3.57", "wps": "18274.6", "ups": "0.08", "wpb": "241779", "bsz": "1024", "num_updates": "4560", "lr": "0.000228", "gnorm": "3.682", "loss_scale": "0.25", "train_wall": "17", "gb_free": "12.9", "wall": "60775"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00038909912109375, 0.0008168220520019531, 0.0008797645568847656, 0.0014047622680664062, 0.0005464553833007812]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00030303001403808594, 0.0012063980102539062, 0.0009398460388183594, 0.0014495849609375, 0.00051116943359375]
byte3 tgt value: [0.0, 0.0, 0.0, 0.46875, 0.0]
byte3 pred value: [0.0016489028930664062, 0.0019121170043945312, 0.0011472702026367188, 0.2197265625, 0.0029125213623046875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.99609375, 0.0]
byte4 pred value: [0.0022792816162109375, 0.002140045166015625, 0.0008358955383300781, 0.85791015625, 0.0032596588134765625]
byte5 tgt value: [0.0, 0.0, 0.0, 0.5078125, 0.0]
byte5 pred value: [0.0843505859375, 0.0029010772705078125, 0.005001068115234375, 0.65576171875, 0.011962890625]
byte6 tgt value: [0.0, 0.0, 0.0, 0.3125, 0.01953125]
byte6 pred value: [0.061431884765625, 0.005512237548828125, 0.01282501220703125, 0.1416015625, 0.0246124267578125]
byte7 tgt value: [0.0, 0.0, 0.24609375, 0.19140625, 0.81640625]
byte7 pred value: [0.0885009765625, 0.038604736328125, 0.2724609375, 0.3095703125, 0.20556640625]
byte8 tgt value: [0.140625, 0.00390625, 0.98828125, 0.1875, 0.54296875]
byte8 pred value: [0.1441650390625, 0.047943115234375, 0.8876953125, 0.4169921875, 0.2462158203125]
tgt code: mov hexvar mov ^1 r12
pred code: mov hexvar mov ^4 rip
2021-10-11 12:33:04 | INFO | train_inner | {"epoch": 1, "update": 0.384, "loss": "1.725", "code_loss": "1.828", "value_loss_mse": "0.019", "code_ppl": "3.55", "wps": "17777.8", "ups": "0.07", "wpb": "244320", "bsz": "1024", "num_updates": "4570", "lr": "0.0002285", "gnorm": "4.087", "loss_scale": "0.25", "train_wall": "17", "gb_free": "12.9", "wall": "60912"}
2021-10-11 12:35:06 | INFO | train_inner | {"epoch": 1, "update": 0.385, "loss": "1.765", "code_loss": "1.82", "value_loss_mse": "0.02", "code_ppl": "3.53", "wps": "19378.4", "ups": "0.08", "wpb": "236568", "bsz": "1024", "num_updates": "4580", "lr": "0.000229", "gnorm": "3.512", "loss_scale": "0.25", "train_wall": "15", "gb_free": "12.9", "wall": "61034"}
2021-10-11 12:37:09 | INFO | train_inner | {"epoch": 1, "update": 0.386, "loss": "1.734", "code_loss": "1.812", "value_loss_mse": "0.019", "code_ppl": "3.51", "wps": "18284.7", "ups": "0.08", "wpb": "225277", "bsz": "1024", "num_updates": "4590", "lr": "0.0002295", "gnorm": "4.626", "loss_scale": "0.25", "train_wall": "15", "gb_free": "12.9", "wall": "61158"}
2021-10-11 12:39:14 | INFO | train_inner | {"epoch": 1, "update": 0.387, "loss": "1.747", "code_loss": "1.828", "value_loss_mse": "0.02", "code_ppl": "3.55", "wps": "18653.3", "ups": "0.08", "wpb": "232909", "bsz": "1024", "num_updates": "4600", "lr": "0.00023", "gnorm": "3.87", "loss_scale": "0.25", "train_wall": "30", "gb_free": "12.9", "wall": "61282"}
2021-10-11 12:41:18 | INFO | train_inner | {"epoch": 1, "update": 0.388, "loss": "1.751", "code_loss": "1.842", "value_loss_mse": "0.02", "code_ppl": "3.58", "wps": "18991.8", "ups": "0.08", "wpb": "236794", "bsz": "1024", "num_updates": "4610", "lr": "0.0002305", "gnorm": "4.752", "loss_scale": "0.25", "train_wall": "61", "gb_free": "12.9", "wall": "61407"}
2021-10-11 12:43:30 | INFO | train_inner | {"epoch": 1, "update": 0.388, "loss": "1.74", "code_loss": "1.845", "value_loss_mse": "0.019", "code_ppl": "3.59", "wps": "18729.4", "ups": "0.08", "wpb": "246781", "bsz": "1024", "num_updates": "4620", "lr": "0.000231", "gnorm": "4.205", "loss_scale": "0.25", "train_wall": "47", "gb_free": "12.9", "wall": "61539"}
2021-10-11 12:45:35 | INFO | train_inner | {"epoch": 1, "update": 0.389, "loss": "1.712", "code_loss": "1.806", "value_loss_mse": "0.019", "code_ppl": "3.5", "wps": "19364.3", "ups": "0.08", "wpb": "241242", "bsz": "1024", "num_updates": "4630", "lr": "0.0002315", "gnorm": "4.633", "loss_scale": "0.25", "train_wall": "69", "gb_free": "12.9", "wall": "61663"}
2021-10-11 12:47:43 | INFO | train_inner | {"epoch": 1, "update": 0.39, "loss": "1.741", "code_loss": "1.824", "value_loss_mse": "0.02", "code_ppl": "3.54", "wps": "19340.3", "ups": "0.08", "wpb": "248496", "bsz": "1024", "num_updates": "4640", "lr": "0.000232", "gnorm": "3.791", "loss_scale": "0.25", "train_wall": "36", "gb_free": "12.9", "wall": "61792"}
2021-10-11 12:48:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 12:50:04 | INFO | train_inner | {"epoch": 1, "update": 0.391, "loss": "1.762", "code_loss": "1.812", "value_loss_mse": "0.02", "code_ppl": "3.51", "wps": "16444.6", "ups": "0.07", "wpb": "231404", "bsz": "1024", "num_updates": "4650", "lr": "0.0002325", "gnorm": "4.999", "loss_scale": "0.25", "train_wall": "18", "gb_free": "12.9", "wall": "61933"}
2021-10-11 12:50:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
[0.5498046875, 0.1590576171875, 0.005428314208984375, 0.0282745361328125, 0.00494384765625]
byte5 tgt value: [0.5859375, 0.30078125, 0.0, 0.0, 0.0]
byte5 pred value: [0.489013671875, 0.2005615234375, 0.00800323486328125, 0.0301055908203125, 0.00864410400390625]
byte6 tgt value: [0.4375, 0.61328125, 0.0, 0.0, 0.0]
byte6 pred value: [0.462158203125, 0.27294921875, 0.00498199462890625, 0.03533935546875, 0.006488800048828125]
byte7 tgt value: [0.55859375, 0.71875, 0.0, 0.0, 0.0]
byte7 pred value: [0.55615234375, 0.43505859375, 0.006168365478515625, 0.042877197265625, 0.0094146728515625]
byte8 tgt value: [0.27734375, 0.9140625, 0.7265625, 0.00390625, 0.7265625]
byte8 pred value: [0.50927734375, 0.54541015625, 0.82421875, 0.12103271484375, 0.796875]
tgt code: rdi je rbx + +
pred code: + je rbx + +
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0313720703125, 0.0010814666748046875, 0.0005726814270019531, 0.00206756591796875, 0.0012254714965820312]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0328369140625, 0.0008492469787597656, 0.0005617141723632812, 0.002269744873046875, 0.0009965896606445312]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.234375]
byte3 pred value: [0.035614013671875, 0.00106048583984375, 0.0009927749633789062, 0.1859130859375, 0.16748046875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.06903076171875, 0.0011692047119140625, 0.0020751953125, 0.1636962890625, 0.153076171875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.265625]
byte5 pred value: [0.033782958984375, 0.03460693359375, 0.004680633544921875, 0.294189453125, 0.29150390625]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.58984375]
byte6 pred value: [0.0333251953125, 0.06732177734375, 0.0054473876953125, 0.427490234375, 0.52392578125]
byte7 tgt value: [0.99609375, 0.0, 0.0, 0.0, 0.51953125]
byte7 pred value: [0.8310546875, 0.05108642578125, 0.00547027587890625, 0.244384765625, 0.2042236328125]
byte8 tgt value: [0.99609375, 0.0, 0.0, 0.05078125, 0.546875]
byte8 pred value: [0.85498046875, 0.1041259765625, 0.1441650390625, 0.41064453125, 0.462646484375]
tgt code: ^4 rip ret push
pred code: ^4 rip ret call
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0017957687377929688, 0.0005974769592285156, 0.006771087646484375, 0.0013408660888671875, 0.00080108642578125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0024623870849609375, 0.0008168220520019531, 0.0058441162109375, 0.0014104843139648438, 0.0010814666748046875]
byte3 tgt value: [0.0, 0.0, 0.0, 0.33203125, 0.0]
byte3 pred value: [0.0022869110107421875, 0.0011339187622070312, 0.00494384765625, 0.02056884765625, 0.0022602081298828125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.1875, 0.0]
byte4 pred value: [0.0024051666259765625, 0.00133514404296875, 0.006565093994140625, 0.01934814453125, 0.0023136138916015625]
byte5 tgt value: [0.0, 0.0, 0.0, 0.796875, 0.0]
byte5 pred value: [0.00254058837890625, 0.0015363693237304688, 0.007175445556640625, 0.0343017578125, 0.0028781890869140625]
byte6 tgt value: [0.0, 0.0, 0.0, 0.05859375, 0.0078125]
byte6 pred value: [0.0023784637451171875, 0.002124786376953125, 0.0050811767578125, 0.0192413330078125, 0.01363372802734375]
byte7 tgt value: [0.0, 0.0, 0.0, 0.109375, 0.7890625]
byte7 pred value: [0.0032482147216796875, 0.003223419189453125, 0.007965087890625, 0.498779296875, 0.640625]
byte8 tgt value: [0.03125, 0.0, 0.03125, 0.5, 0.56640625]
byte8 pred value: [0.08740234375, 0.1019287109375, 0.078369140625, 0.46044921875, 0.54736328125]
tgt code: mov rbx rsp test ^8
pred code: call r13 rsp mov ^8
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0018892288208007812, 0.0005483627319335938, 0.0018968582153320312, 0.002834320068359375, 0.0008592605590820312]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0020904541015625, 0.0008230209350585938, 0.0029125213623046875, 0.00238800048828125, 0.0005483627319335938]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0038394927978515625, 0.0014162063598632812, 0.052337646484375, 0.0020999908447265625, 0.0010986328125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0037078857421875, 0.0014896392822265625, 0.198486328125, 0.002010345458984375, 0.0009813308715820312]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.00524139404296875, 0.001972198486328125, 0.1761474609375, 0.0032978057861328125, 0.0014667510986328125]
byte6 tgt value: [0.0, 0.0, 0.01171875, 0.0, 0.0]
byte6 pred value: [0.004116058349609375, 0.002590179443359375, 0.038177490234375, 0.0029468536376953125, 0.0017747879028320312]
byte7 tgt value: [0.0, 0.0, 0.33203125, 0.0, 0.0]
byte7 pred value: [0.0027675628662109375, 0.004070281982421875, 0.294189453125, 0.004398345947265625, 0.003749847412109375]
byte8 tgt value: [0.03125, 0.08203125, 0.1875, 0.0625, 0.0625]
byte8 pred value: [0.0296478271484375, 0.1317138671875, 0.1898193359375, 0.07501220703125, 0.114990234375]
tgt code: rdx mov hexvar lea ^1
pred code: rdx test hexvar test ^1
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00443267822265625, 0.0016164779663085938, 0.0009436607360839844, 0.000820159912109375, 0.0011377334594726562]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00441741943359375, 0.002132415771484375, 0.0009698867797851562, 0.0008864402770996094, 0.0011205673217773438]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0030269622802734375, 0.0014553070068359375, 0.0010404586791992188, 0.0009584426879882812, 0.0010204315185546875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0027370452880859375, 0.0018177032470703125, 0.0009813308715820312, 0.0007948875427246094, 0.0010318756103515625]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.038909912109375, 0.0023975372314453125, 0.0011034011840820312, 0.00154876708984375, 0.0013723373413085938]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.03955078125, 0.0026836395263671875, 0.0016546249389648438, 0.0022525787353515625, 0.002132415771484375]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.030914306640625, 0.0035247802734375, 0.00494384765625, 0.0038547515869140625, 0.0029926300048828125]
byte8 tgt value: [0.00390625, 0.0390625, 0.0625, 0.28125, 0.03125]
byte8 pred value: [0.052703857421875, 0.11419677734375, 0.1495361328125, 0.2191162109375, 0.205810546875]
tgt code: mov rdi mov ^8 add
pred code: mov rdi mov ^8 add
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0002846717834472656, 0.0024623870849609375, 0.0002512931823730469, 0.0010900497436523438, 0.004085540771484375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0006289482116699219, 0.0022335052490234375, 0.00043392181396484375, 0.0007762908935546875, 0.00605010986328125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.002323150634765625, 0.03436279296875, 0.001720428466796875, 0.0013990402221679688, 0.004299163818359375]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.00766754150390625, 0.048583984375, 0.0018310546875, 0.00130462646484375, 0.004116058349609375]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.00690460205078125, 0.037750244140625, 0.004215240478515625, 0.0025119781494140625, 0.01233673095703125]
byte6 tgt value: [0.0, 0.0, 0.01171875, 0.0, 0.0]
byte6 pred value: [0.018341064453125, 0.06427001953125, 0.017578125, 0.00250244140625, 0.007122039794921875]
byte7 tgt value: [0.36328125, 0.0, 0.1015625, 0.0, 0.0]
byte7 pred value: [0.2430419921875, 0.052337646484375, 0.327880859375, 0.0034961700439453125, 0.00981903076171875]
byte8 tgt value: [0.08203125, 0.0390625, 0.578125, 0.03125, 0.0]
byte8 pred value: [0.33984375, 0.1773681640625, 0.45458984375, 0.040618896484375, 0.0384521484375]
tgt code: ^8 add hexvar hexvar
pred code: ^8 mov hexvar hexvar
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0004477500915527344, 0.0017547607421875, 0.0025615692138671875, 0.0002913475036621094, 0.0003006458282470703]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: 2021-10-11 12:52:19 | INFO | train_inner | {"epoch": 1, "update": 0.392, "loss": "1.765", "code_loss": "1.798", "value_loss_mse": "0.02", "code_ppl": "3.48", "wps": "17437.3", "ups": "0.07", "wpb": "235603", "bsz": "1024", "num_updates": "4660", "lr": "0.000233", "gnorm": "4.556", "loss_scale": "0.25", "train_wall": "47", "gb_free": "12.9", "wall": "62068"}
2021-10-11 12:53:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 12:54:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 12:54:44 | INFO | train_inner | {"epoch": 1, "update": 0.393, "loss": "1.722", "code_loss": "1.795", "value_loss_mse": "0.019", "code_ppl": "3.47", "wps": "15094.9", "ups": "0.07", "wpb": "219421", "bsz": "1024", "num_updates": "4670", "lr": "0.0002335", "gnorm": "5.113", "loss_scale": "0.25", "train_wall": "63", "gb_free": "12.9", "wall": "62213"}
2021-10-11 12:56:58 | INFO | train_inner | {"epoch": 1, "update": 0.394, "loss": "1.724", "code_loss": "1.816", "value_loss_mse": "0.019", "code_ppl": "3.52", "wps": "18907.8", "ups": "0.08", "wpb": "251949", "bsz": "1024", "num_updates": "4680", "lr": "0.000234", "gnorm": "4.134", "loss_scale": "0.25", "train_wall": "19", "gb_free": "12.9", "wall": "62346"}
2021-10-11 12:59:00 | INFO | train_inner | {"epoch": 1, "update": 0.394, "loss": "1.732", "code_loss": "1.795", "value_loss_mse": "0.019", "code_ppl": "3.47", "wps": "18703.9", "ups": "0.08", "wpb": "228907", "bsz": "1024", "num_updates": "4690", "lr": "0.0002345", "gnorm": "3.748", "loss_scale": "0.25", "train_wall": "17", "gb_free": "12.9", "wall": "62469"}
2021-10-11 13:00:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:00:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:00:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:01:52 | INFO | train_inner | {"epoch": 1, "update": 0.395, "loss": "1.721", "code_loss": "1.78", "value_loss_mse": "0.019", "code_ppl": "3.43", "wps": "13743.5", "ups": "0.06", "wpb": "236237", "bsz": "1024", "num_updates": "4700", "lr": "0.000235", "gnorm": "4.363", "loss_scale": "0.25", "train_wall": "61", "gb_free": "12.9", "wall": "62641"}
2021-10-11 13:04:06 | INFO | train_inner | {"epoch": 1, "update": 0.396, "loss": "1.726", "code_loss": "1.801", "value_loss_mse": "0.019", "code_ppl": "3.48", "wps": "18759.6", "ups": "0.07", "wpb": "250748", "bsz": "1024", "num_updates": "4710", "lr": "0.0002355", "gnorm": "4.516", "loss_scale": "0.25", "train_wall": "97", "gb_free": "12.9", "wall": "62774"}
2021-10-11 13:06:11 | INFO | train_inner | {"epoch": 1, "update": 0.397, "loss": "1.739", "code_loss": "1.784", "value_loss_mse": "0.02", "code_ppl": "3.44", "wps": "18533.5", "ups": "0.08", "wpb": "232312", "bsz": "1024", "num_updates": "4720", "lr": "0.000236", "gnorm": "3.918", "loss_scale": "0.25", "train_wall": "62", "gb_free": "12.9", "wall": "62900"}
2021-10-11 13:08:30 | INFO | train_inner | {"epoch": 1, "update": 0.398, "loss": "1.737", "code_loss": "1.78", "value_loss_mse": "0.02", "code_ppl": "3.43", "wps": "17720.5", "ups": "0.07", "wpb": "245898", "bsz": "1024", "num_updates": "4730", "lr": "0.0002365", "gnorm": "5.18", "loss_scale": "0.25", "train_wall": "96", "gb_free": "13.6", "wall": "63038"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.000507354736328125, 0.0083770751953125, 0.005489349365234375, 0.0005617141723632812, 0.00064849853515625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0005235671997070312, 0.00653839111328125, 0.004680633544921875, 0.0005035400390625, 0.0005011558532714844]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0016613006591796875, 0.0087432861328125, 0.006565093994140625, 0.0009474754333496094, 0.0010442733764648438]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0025119781494140625, 0.0090179443359375, 0.007404327392578125, 0.0005035400390625, 0.0006461143493652344]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.00345611572265625, 0.013275146484375, 0.008880615234375, 0.001495361328125, 0.0015010833740234375]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.006072998046875, 0.0162200927734375, 0.0095977783203125, 0.0054473876953125, 0.004299163818359375]
byte7 tgt value: [0.1875, 0.0, 0.0, 0.39453125, 0.1875]
byte7 pred value: [0.280029296875, 0.01312255859375, 0.00891876220703125, 0.40478515625, 0.2276611328125]
byte8 tgt value: [0.375, 0.28125, 0.0078125, 0.4375, 0.25]
byte8 pred value: [0.48681640625, 0.10687255859375, 0.059417724609375, 0.355224609375, 0.2119140625]
tgt code: rax eax call xor edi
pred code: rax eax call mov hexvar
2021-10-11 13:10:33 | INFO | train_inner | {"epoch": 1, "update": 0.399, "loss": "1.698", "code_loss": "1.776", "value_loss_mse": "0.019", "code_ppl": "3.43", "wps": "18931.8", "ups": "0.08", "wpb": "232810", "bsz": "1024", "num_updates": "4740", "lr": "0.000237", "gnorm": "4.239", "loss_scale": "0.25", "train_wall": "61", "gb_free": "12.9", "wall": "63161"}
2021-10-11 13:11:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:12:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:12:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:12:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:13:24 | INFO | train_inner | {"epoch": 1, "update": 0.4, "loss": "1.704", "code_loss": "1.764", "value_loss_mse": "0.019", "code_ppl": "3.4", "wps": "12802.4", "ups": "0.06", "wpb": "219316", "bsz": "1024", "num_updates": "4750", "lr": "0.0002375", "gnorm": "5.848", "loss_scale": "0.25", "train_wall": "92", "gb_free": "12.9", "wall": "63333"}
2021-10-11 13:15:22 | INFO | train_inner | {"epoch": 1, "update": 0.401, "loss": "1.708", "code_loss": "1.795", "value_loss_mse": "0.019", "code_ppl": "3.47", "wps": "18749.9", "ups": "0.08", "wpb": "221766", "bsz": "1024", "num_updates": "4760", "lr": "0.000238", "gnorm": "5.039", "loss_scale": "0.25", "train_wall": "33", "gb_free": "12.9", "wall": "63451"}
2021-10-11 13:16:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:16:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:16:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:16:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:17:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:18:24 | INFO | train_inner | {"epoch": 1, "update": 0.402, "loss": "1.722", "code_loss": "1.784", "value_loss_mse": "0.019", "code_ppl": "3.44", "wps": "12450.4", "ups": "0.05", "wpb": "226483", "bsz": "1024", "num_updates": "4770", "lr": "0.0002385", "gnorm": "5.729", "loss_scale": "0.25", "train_wall": "36", "gb_free": "12.9", "wall": "63633"}
2021-10-11 13:20:27 | INFO | train_inner | {"epoch": 1, "update": 0.403, "loss": "1.684", "code_loss": "1.781", "value_loss_mse": "0.019", "code_ppl": "3.44", "wps": "18661", "ups": "0.08", "wpb": "228765", "bsz": "1024", "num_updates": "4780", "lr": "0.000239", "gnorm": "3.918", "loss_scale": "0.25", "train_wall": "38", "gb_free": "12.9", "wall": "63755"}
2021-10-11 13:22:35 | INFO | train_inner | {"epoch": 1, "update": 0.403, "loss": "1.707", "code_loss": "1.771", "value_loss_mse": "0.019", "code_ppl": "3.41", "wps": "18911.8", "ups": "0.08", "wpb": "241928", "bsz": "1024", "num_updates": "4790", "lr": "0.0002395", "gnorm": "4.059", "loss_scale": "0.25", "train_wall": "75", "gb_free": "12.9", "wall": "63883"}
2021-10-11 13:23:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:23:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:23:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:24:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:24:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:24:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:24:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:25:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:25:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:25:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0156707763671875, 0.0013723373413085938, 0.0062408447265625, 0.0013885498046875, 0.0010166168212890625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.01073455810546875, 0.0021152496337890625, 0.00653839111328125, 0.001674652099609375, 0.0009698867797851562]
byte3 tgt value: [0.0, 0.23828125, 0.0, 0.0, 0.0]
byte3 pred value: [0.0243377685546875, 0.2305908203125, 0.10931396484375, 0.183349609375, 0.0017004013061523438]
byte4 tgt value: [0.0, 0.86328125, 0.0, 0.0, 0.0]
byte4 pred value: [0.04132080078125, 0.7666015625, 0.253662109375, 0.64013671875, 0.0018529891967773438]
byte5 tgt value: [0.0, 0.765625, 0.765625, 0.0, 0.0]
byte5 pred value: [0.046539306640625, 0.8837890625, 0.35498046875, 0.85205078125, 0.0034694671630859375]
byte6 tgt value: [0.0, 0.72265625, 0.77734375, 0.0, 0.0]
byte6 pred value: [0.0305633544921875, 0.83349609375, 0.31298828125, 0.73388671875, 0.0033626556396484375]
byte7 tgt value: [0.0, 0.125, 0.109375, 0.00390625, 0.0]
byte7 pred value: [0.03228759765625, 0.141845703125, 0.18603515625, 0.529296875, 0.007175445556640625]
byte8 tgt value: [0.0859375, 0.5078125, 0.25, 0.375, 0.0]
byte8 pred value: [0.1014404296875, 0.61328125, 0.28857421875, 0.44140625, 0.138427734375]
tgt code: hexvar edx + dl hexvar
pred code: hexvar rax + al hexvar
2021-10-11 13:26:53 | INFO | train_inner | {"epoch": 1, "update": 0.405, "loss": "1.695", "code_loss": "1.767", "value_loss_mse": "0.019", "code_ppl": "3.4", "wps": "9253", "ups": "0.04", "wpb": "238819", "bsz": "1024", "num_updates": "4800", "lr": "0.00024", "gnorm": "5.087", "loss_scale": "0.25", "train_wall": "177", "gb_free": "12.9", "wall": "64142"}
2021-10-11 13:29:03 | INFO | train_inner | {"epoch": 1, "update": 0.406, "loss": "1.699", "code_loss": "1.78", "value_loss_mse": "0.019", "code_ppl": "3.43", "wps": "18197", "ups": "0.08", "wpb": "237644", "bsz": "1024", "num_updates": "4810", "lr": "0.0002405", "gnorm": "6.306", "loss_scale": "0.25", "train_wall": "94", "gb_free": "12.9", "wall": "64272"}
2021-10-11 13:31:08 | INFO | train_inner | {"epoch": 1, "update": 0.407, "loss": "1.639", "code_loss": "1.75", "value_loss_mse": "0.018", "code_ppl": "3.36", "wps": "19206.2", "ups": "0.08", "wpb": "240061", "bsz": "1024", "num_updates": "4820", "lr": "0.000241", "gnorm": "4.18", "loss_scale": "0.25", "train_wall": "40", "gb_free": "12.9", "wall": "64397"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0001926422119140625, 0.0018892288208007812, 0.0008134841918945312, 0.0017824172973632812, 0.0006718635559082031]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00025916099548339844, 0.0020904541015625, 0.0006289482116699219, 0.0020198822021484375, 0.0010528564453125]
byte3 tgt value: [0.0, 0.39453125, 0.0, 0.10546875, 0.0]
byte3 pred value: [0.004886627197265625, 0.384521484375, 0.0018177032470703125, 0.01971435546875, 0.00133514404296875]
byte4 tgt value: [0.0, 0.11328125, 0.0, 0.23828125, 0.0]
byte4 pred value: [0.0022430419921875, 0.51416015625, 0.002002716064453125, 0.035400390625, 0.0011510848999023438]
byte5 tgt value: [0.0, 0.22265625, 0.0, 0.66796875, 0.0]
byte5 pred value: [0.305908203125, 0.38330078125, 0.0027675628662109375, 0.07806396484375, 0.0021991729736328125]
byte6 tgt value: [0.0, 0.20703125, 0.0, 0.84375, 0.03515625]
byte6 pred value: [0.389892578125, 0.381591796875, 0.003635406494140625, 0.06982421875, 0.010986328125]
byte7 tgt value: [0.0, 0.2265625, 0.0, 0.26171875, 0.9375]
byte7 pred value: [0.5283203125, 0.49365234375, 0.005039215087890625, 0.05340576171875, 0.580078125]
byte8 tgt value: [0.2421875, 0.375, 0.12109375, 0.125, 0.09765625]
byte8 pred value: [0.5244140625, 0.50390625, 0.11932373046875, 0.13720703125, 0.48095703125]
tgt code: hexvar hexvar rsi hexvar
pred code: hexvar hexvar rdi hexvar
2021-10-11 13:33:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:33:37 | INFO | train_inner | {"epoch": 1, "update": 0.408, "loss": "1.707", "code_loss": "1.744", "value_loss_mse": "0.019", "code_ppl": "3.35", "wps": "16486.6", "ups": "0.07", "wpb": "244883", "bsz": "1024", "num_updates": "4830", "lr": "0.0002415", "gnorm": "4.755", "loss_scale": "0.25", "train_wall": "73", "gb_free": "12.9", "wall": "64546"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0008492469787597656, 0.0004458427429199219, 0.00026535987854003906, 0.0004546642303466797, 0.0002846717834472656]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0007853507995605469, 0.0004222393035888672, 0.0004546642303466797, 0.000537872314453125, 0.00038743019104003906]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.01363372802734375, 0.0005316734313964844, 0.001220703125, 0.01358795166015625, 0.0009660720825195312]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0394287109375, 0.0006985664367675781, 0.00127410888671875, 0.0345458984375, 0.0011920928955078125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.022369384765625, 0.0010776519775390625, 0.002834320068359375, 0.0262603759765625, 0.0030040740966796875]
byte6 tgt value: [0.0, 0.0, 0.0859375, 0.015625, 0.0859375]
byte6 pred value: [0.00800323486328125, 0.0030517578125, 0.021240234375, 0.021209716796875, 0.0162200927734375]
byte7 tgt value: [0.859375, 0.0, 0.23046875, 0.171875, 0.1875]
byte7 pred value: [0.457275390625, 0.036163330078125, 0.26708984375, 0.280029296875, 0.286376953125]
byte8 tgt value: [0.625, 0.26953125, 0.1015625, 0.53125, 0.45703125]
byte8 pred value: [0.453369140625, 0.179931640625, 0.517578125, 0.442138671875, 0.471923828125]
tgt code: rbx ^8 + or eax
pred code: hexvar ^8 + mov eax
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0007948875427246094, 0.0026721954345703125, 0.0013561248779296875, 0.00047278404235839844, 0.0011835098266601562]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0006046295166015625, 0.002471923828125, 0.0013666152954101562, 0.00039196014404296875, 0.0009217262268066406]
byte3 tgt value: [0.0, 0.49609375, 0.18359375, 0.0, 0.0]
byte3 pred value: [0.08343505859375, 0.459228515625, 0.1719970703125, 0.0010404586791992188, 0.0015544891357421875]
byte4 tgt value: [0.0, 0.99609375, 0.76953125, 0.0, 0.0]
byte4 pred value: [0.26806640625, 0.8828125, 0.77734375, 0.0013561248779296875, 0.0009622573852539062]
byte5 tgt value: [0.0, 0.98828125, 0.23046875, 0.0, 0.0]
byte5 pred value: [0.3115234375, 0.7412109375, 0.165283203125, 0.001361846923828125, 0.0012941360473632812]
byte6 tgt value: [0.0, 0.70703125, 0.33984375, 0.0, 0.0]
byte6 pred value: [0.327880859375, 0.497802734375, 0.390869140625, 0.0017070770263671875, 0.001495361328125]
byte7 tgt value: [0.0, 0.35546875, 0.8828125, 0.0, 0.0]
byte7 pred value: [0.1905517578125, 0.38427734375, 0.91064453125, 0.005199432373046875, 0.0029468536376953125]
byte8 tgt value: [0.0, 0.6328125, 0.5, 0.13671875, 0.03125]
byte8 pred value: [0.32470703125, 0.509765625, 0.5693359375, 0.12420654296875, 0.020843505859375]
tgt code: rsi hexvar r13 rdx r12
pred code: rdx hexvar rsp rax rsi
2021-10-11 13:35:43 | INFO | train_inner | {"epoch": 1, "update": 0.408, "loss": "1.674", "code_loss": "1.76", "value_loss_mse": "0.019", "code_ppl": "3.39", "wps": "18678.1", "ups": "0.08", "wpb": "234854", "bsz": "1024", "num_updates": "4840", "lr": "0.000242", "gnorm": "4.595", "loss_scale": "0.25", "train_wall": "70", "gb_free": "12.9", "wall": "64671"}
2021-10-11 13:37:44 | INFO | train_inner | {"epoch": 1, "update": 0.409, "loss": "1.713", "code_loss": "1.777", "value_loss_mse": "0.019", "code_ppl": "3.43", "wps": "19236.4", "ups": "0.08", "wpb": "234253", "bsz": "1024", "num_updates": "4850", "lr": "0.0002425", "gnorm": "4.898", "loss_scale": "0.25", "train_wall": "44", "gb_free": "12.9", "wall": "64793"}
2021-10-11 13:37:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:40:03 | INFO | train_inner | {"epoch": 1, "update": 0.41, "loss": "1.735", "code_loss": "1.77", "value_loss_mse": "0.02", "code_ppl": "3.41", "wps": "17167.9", "ups": "0.07", "wpb": "238484", "bsz": "1024", "num_updates": "4860", "lr": "0.000243", "gnorm": "5.872", "loss_scale": "0.25", "train_wall": "35", "gb_free": "12.9", "wall": "64932"}
2021-10-11 13:42:08 | INFO | train_inner | {"epoch": 1, "update": 0.411, "loss": "1.69", "code_loss": "1.757", "value_loss_mse": "0.019", "code_ppl": "3.38", "wps": "18889.8", "ups": "0.08", "wpb": "235619", "bsz": "1024", "num_updates": "4870", "lr": "0.0002435", "gnorm": "5.118", "loss_scale": "0.25", "train_wall": "50", "gb_free": "12.9", "wall": "65057"}
2021-10-11 13:43:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:43:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:43:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:44:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:45:06 | INFO | train_inner | {"epoch": 1, "update": 0.412, "loss": "1.659", "code_loss": "1.74", "value_loss_mse": "0.019", "code_ppl": "3.34", "wps": "12152.6", "ups": "0.06", "wpb": "216769", "bsz": "1024", "num_updates": "4880", "lr": "0.000244", "gnorm": "6.181", "loss_scale": "0.25", "train_wall": "131", "gb_free": "12.9", "wall": "65235"}
2021-10-11 13:47:06 | INFO | train_inner | {"epoch": 1, "update": 0.413, "loss": "1.717", "code_loss": "1.766", "value_loss_mse": "0.019", "code_ppl": "3.4", "wps": "19207.5", "ups": "0.08", "wpb": "229127", "bsz": "1024", "num_updates": "4890", "lr": "0.0002445", "gnorm": "3.912", "loss_scale": "0.25", "train_wall": "19", "gb_free": "12.9", "wall": "65354"}
2021-10-11 13:49:17 | INFO | train_inner | {"epoch": 1, "update": 0.414, "loss": "1.69", "code_loss": "1.736", "value_loss_mse": "0.019", "code_ppl": "3.33", "wps": "17375.8", "ups": "0.08", "wpb": "227878", "bsz": "1024", "num_updates": "4900", "lr": "0.000245", "gnorm": "5.086", "loss_scale": "0.25", "train_wall": "88", "gb_free": "12.9", "wall": "65486"}
2021-10-11 13:51:22 | INFO | train_inner | {"epoch": 1, "update": 0.414, "loss": "1.687", "code_loss": "1.753", "value_loss_mse": "0.019", "code_ppl": "3.37", "wps": "19306.5", "ups": "0.08", "wpb": "242166", "bsz": "1024", "num_updates": "4910", "lr": "0.0002455", "gnorm": "5.37", "loss_scale": "0.25", "train_wall": "91", "gb_free": "12.9", "wall": "65611"}
2021-10-11 13:52:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:53:44 | INFO | train_inner | {"epoch": 1, "update": 0.415, "loss": "1.682", "code_loss": "1.741", "value_loss_mse": "0.019", "code_ppl": "3.34", "wps": "17242.7", "ups": "0.07", "wpb": "244036", "bsz": "1024", "num_updates": "4920", "lr": "0.000246", "gnorm": "5.165", "loss_scale": "0.25", "train_wall": "73", "gb_free": "12.9", "wall": "65753"}
2021-10-11 13:54:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:55:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:56:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:56:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 13:56:37 | INFO | train_inner | {"epoch": 1, "update": 0.416, "loss": "1.652", "code_loss": "1.728", "value_loss_mse": "0.019", "code_ppl": "3.31", "wps": "13591.8", "ups": "0.06", "wpb": "235797", "bsz": "1024", "num_updates": "4930", "lr": "0.0002465", "gnorm": "5.595", "loss_scale": "0.25", "train_wall": "107", "gb_free": "12.9", "wall": "65926"}
2021-10-11 13:58:47 | INFO | train_inner | {"epoch": 1, "update": 0.417, "loss": "1.709", "code_loss": "1.715", "value_loss_mse": "0.019", "code_ppl": "3.28", "wps": "18128.3", "ups": "0.08", "wpb": "235315", "bsz": "1024", "num_updates": "4940", "lr": "0.000247", "gnorm": "5.131", "loss_scale": "0.25", "train_wall": "68", "gb_free": "12.9", "wall": "66056"}
2021-10-11 14:00:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:01:09 | INFO | train_inner | {"epoch": 1, "update": 0.418, "loss": "1.667", "code_loss": "1.718", "value_loss_mse": "0.019", "code_ppl": "3.29", "wps": "17042.3", "ups": "0.07", "wpb": "241235", "bsz": "1024", "num_updates": "4950", "lr": "0.0002475", "gnorm": "6.205", "loss_scale": "0.25", "train_wall": "99", "gb_free": "12.9", "wall": "66197"}
2021-10-11 14:02:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
byte1 tgt value: [0.0, 0.0, 0.0, 0.97265625, 0.0]
byte1 pred value: [0.0153045654296875, 0.009674072265625, 0.0004973411560058594, 0.44921875, 0.003795623779296875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.6484375, 0.0]
byte2 pred value: [0.01384735107421875, 0.0083160400390625, 0.0005817413330078125, 0.462646484375, 0.00254058837890625]
byte3 tgt value: [0.0, 0.0, 0.0, 0.1875, 0.49609375]
byte3 pred value: [0.01395416259765625, 0.01146697998046875, 0.0007381439208984375, 0.490966796875, 0.472900390625]
byte4 tgt value: [0.0, 0.0, 0.0, 0.37109375, 0.99609375]
byte4 pred value: [0.0095977783203125, 0.00881195068359375, 0.00047278404235839844, 0.46533203125, 0.994140625]
byte5 tgt value: [0.0, 0.0, 0.0, 0.41015625, 0.796875]
byte5 pred value: [0.01519012451171875, 0.01146697998046875, 0.003063201904296875, 0.479248046875, 0.74462890625]
byte6 tgt value: [0.0, 0.0, 0.0234375, 0.77734375, 0.2421875]
byte6 pred value: [0.01036834716796875, 0.010528564453125, 0.0171051025390625, 0.5732421875, 0.1593017578125]
byte7 tgt value: [0.0, 0.0, 0.07421875, 0.44921875, 0.73828125]
byte7 pred value: [0.011199951171875, 0.01242828369140625, 0.436767578125, 0.58349609375, 0.75537109375]
byte8 tgt value: [0.07421875, 0.1171875, 0.81640625, 0.9296875, 0.125]
byte8 pred value: [0.06427001953125, 0.12213134765625, 0.501953125, 0.5087890625, 0.093505859375]
tgt code: hexvar hexvar hexvar +
pred code: hexvar hexvar hexvar +
2021-10-11 14:03:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:03:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:03:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:03:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:04:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:04:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:04:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:05:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:05:17 | INFO | train_inner | {"epoch": 1, "update": 0.42, "loss": "1.736", "code_loss": "1.761", "value_loss_mse": "0.02", "code_ppl": "3.39", "wps": "9478.2", "ups": "0.04", "wpb": "234921", "bsz": "1024", "num_updates": "4960", "lr": "0.000248", "gnorm": "6.565", "loss_scale": "0.25", "train_wall": "158", "gb_free": "12.9", "wall": "66445"}
2021-10-11 14:05:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:05:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:06:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:06:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:06:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:06:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:06:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:07:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:07:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:07:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:07:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:08:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:09:59 | INFO | train_inner | {"epoch": 1, "update": 0.421, "loss": "1.689", "code_loss": "1.759", "value_loss_mse": "0.019", "code_ppl": "3.38", "wps": "8278.9", "ups": "0.04", "wpb": "233491", "bsz": "1024", "num_updates": "4970", "lr": "0.0002485", "gnorm": "4.99", "loss_scale": "0.25", "train_wall": "78", "gb_free": "12.9", "wall": "66727"}
2021-10-11 14:11:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.001155853271484375, 0.00323486328125, 0.0018892288208007812, 0.00464630126953125, 0.003482818603515625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.001129150390625, 0.0045928955078125, 0.0024433135986328125, 0.004024505615234375, 0.005161285400390625]
byte3 tgt value: [0.0, 0.22265625, 0.22265625, 0.0, 0.0]
byte3 pred value: [0.003337860107421875, 0.2379150390625, 0.21044921875, 0.00963592529296875, 0.01898193359375]
byte4 tgt value: [0.0, 0.33984375, 0.33984375, 0.0, 0.0]
byte4 pred value: [0.0041351318359375, 0.310791015625, 0.2119140625, 0.01374053955078125, 0.040374755859375]
byte5 tgt value: [0.0, 0.03125, 0.03125, 0.0, 0.0]
byte5 pred value: [0.062103271484375, 0.055511474609375, 0.03277587890625, 0.014007568359375, 0.0272674560546875]
byte6 tgt value: [0.0, 0.83984375, 0.8359375, 0.0, 0.0]
byte6 pred value: [0.2022705078125, 0.845703125, 0.70458984375, 0.0228424072265625, 0.0872802734375]
byte7 tgt value: [0.0, 0.22265625, 0.3203125, 0.0, 0.99609375]
byte7 pred value: [0.8486328125, 0.1265869140625, 0.3740234375, 0.03326416015625, 0.91455078125]
byte8 tgt value: [0.1953125, 0.1640625, 0.875, 0.0, 0.99609375]
byte8 pred value: [0.787109375, 0.158935546875, 0.488525390625, 0.06427001953125, 0.88818359375]
tgt code: + jmp rax + hexvar
pred code: + je ^8 + hexvar
2021-10-11 14:12:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:12:33 | INFO | train_inner | {"epoch": 1, "update": 0.422, "loss": "1.676", "code_loss": "1.743", "value_loss_mse": "0.019", "code_ppl": "3.35", "wps": "16123.3", "ups": "0.06", "wpb": "248666", "bsz": "1024", "num_updates": "4980", "lr": "0.000249", "gnorm": "6.007", "loss_scale": "0.25", "train_wall": "19", "gb_free": "12.9", "wall": "66882"}
2021-10-11 14:13:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0005884170532226562, 0.015899658203125, 0.002452850341796875, 0.00926971435546875, 0.0007581710815429688]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0005908012390136719, 0.01473236083984375, 0.0024814605712890625, 0.00989532470703125, 0.0008039474487304688]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0008525848388671875, 0.044097900390625, 0.004505157470703125, 0.0894775390625, 0.0008039474487304688]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0008559226989746094, 0.078369140625, 0.0050201416015625, 0.26318359375, 0.0009965896606445312]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0235595703125, 0.053192138671875, 0.004486083984375, 0.0885009765625, 0.0021076202392578125]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.0293121337890625, 0.060302734375, 0.004680633544921875, 0.156494140625, 0.0041351318359375]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.03240966796875, 0.05499267578125, 0.0059814453125, 0.134765625, 0.01374053955078125]
byte8 tgt value: [0.0, 0.0, 0.0, 0.0, 0.125]
byte8 pred value: [0.05450439453125, 0.0823974609375, 0.0125732421875, 0.1912841796875, 0.134765625]
tgt code: hexvar xmm0 + + mov
pred code: hexvar xmm0 + + mov
2021-10-11 14:13:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:14:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:14:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:15:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:15:38 | INFO | train_inner | {"epoch": 1, "update": 0.424, "loss": "1.642", "code_loss": "1.723", "value_loss_mse": "0.018", "code_ppl": "3.3", "wps": "11823.1", "ups": "0.05", "wpb": "218691", "bsz": "1024", "num_updates": "4990", "lr": "0.0002495", "gnorm": "5.176", "loss_scale": "0.25", "train_wall": "23", "gb_free": "12.9", "wall": "67066"}
2021-10-11 14:16:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:17:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:18:01 | INFO | train_inner | {"epoch": 1, "update": 0.425, "loss": "1.656", "code_loss": "1.708", "value_loss_mse": "0.019", "code_ppl": "3.27", "wps": "15195.4", "ups": "0.07", "wpb": "217229", "bsz": "1024", "num_updates": "5000", "lr": "0.00025", "gnorm": "5.878", "loss_scale": "0.25", "train_wall": "39", "gb_free": "12.9", "wall": "67209"}
2021-10-11 14:18:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:20:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:20:37 | INFO | train_inner | {"epoch": 1, "update": 0.425, "loss": "1.667", "code_loss": "1.719", "value_loss_mse": "0.019", "code_ppl": "3.29", "wps": "15526.1", "ups": "0.06", "wpb": "243024", "bsz": "1024", "num_updates": "5010", "lr": "0.0002505", "gnorm": "3.739", "loss_scale": "0.25", "train_wall": "22", "gb_free": "12.9", "wall": "67366"}
2021-10-11 14:21:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:22:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:23:11 | INFO | train_inner | {"epoch": 1, "update": 0.426, "loss": "1.649", "code_loss": "1.699", "value_loss_mse": "0.019", "code_ppl": "3.25", "wps": "14800", "ups": "0.06", "wpb": "227757", "bsz": "1024", "num_updates": "5020", "lr": "0.000251", "gnorm": "6.084", "loss_scale": "0.25", "train_wall": "31", "gb_free": "19.5", "wall": "67520"}
2021-10-11 14:23:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:23:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:24:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:24:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:24:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:24:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:25:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:25:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:25:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:25:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:27:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:27:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:27:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:28:09 | INFO | train_inner | {"epoch": 1, "update": 0.428, "loss": "1.644", "code_loss": "1.708", "value_loss_mse": "0.019", "code_ppl": "3.27", "wps": "8155.3", "ups": "0.03", "wpb": "242538", "bsz": "1024", "num_updates": "5030", "lr": "0.0002515", "gnorm": "5.565", "loss_scale": "0.25", "train_wall": "173", "gb_free": "12.9", "wall": "67817"}
2021-10-11 14:28:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:28:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:28:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:29:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:29:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:29:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:29:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:29:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:29:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:30:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:30:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:30:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:30:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:32:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:32:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:33:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0005817413330078125, 0.0006070137023925781, 0.0005316734313964844, 0.0005793571472167969, 0.00043892860412597656]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0006823539733886719, 0.0006189346313476562, 0.0007734298706054688, 0.0005660057067871094, 0.0005035400390625]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0005130767822265625, 0.0023784637451171875, 0.0013990402221679688, 0.001995086669921875, 0.0018968582153320312]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0008935928344726562, 0.0034694671630859375, 0.0013093948364257812, 0.00323486328125, 0.00319671630859375]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0032482147216796875, 0.005199432373046875, 0.0033893585205078125, 0.004085540771484375, 0.0032978057861328125]
byte6 tgt value: [0.0, 0.00390625, 0.02734375, 0.00390625, 0.0]
byte6 pred value: [0.01242828369140625, 0.0092315673828125, 0.0216217041015625, 0.006439208984375, 0.006389617919921875]
byte7 tgt value: [0.0, 0.828125, 0.19140625, 0.87109375, 0.671875]
byte7 pred value: [0.346923828125, 0.8701171875, 0.64306640625, 0.78125, 0.55859375]
byte8 tgt value: [0.1875, 0.78125, 0.64453125, 0.9375, 0.625]
byte8 pred value: [0.328125, 0.5087890625, 0.50634765625, 0.51513671875, 0.458984375]
tgt code: ^1 eax rip + hexvar
pred code: ^8 ecx rip + hexvar
2021-10-11 14:33:25 | INFO | train_inner | {"epoch": 1, "update": 0.43, "loss": "1.634", "code_loss": "1.671", "value_loss_mse": "0.018", "code_ppl": "3.18", "wps": "6745.1", "ups": "0.03", "wpb": "213379", "bsz": "1024", "num_updates": "5040", "lr": "0.000252", "gnorm": "6.013", "loss_scale": "0.25", "train_wall": "141", "gb_free": "12.9", "wall": "68134"}
2021-10-11 14:34:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:35:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:35:53 | INFO | train_inner | {"epoch": 1, "update": 0.431, "loss": "1.69", "code_loss": "1.71", "value_loss_mse": "0.019", "code_ppl": "3.27", "wps": "15525.1", "ups": "0.07", "wpb": "230210", "bsz": "1024", "num_updates": "5050", "lr": "0.0002525", "gnorm": "6.228", "loss_scale": "0.25", "train_wall": "81", "gb_free": "12.9", "wall": "68282"}
2021-10-11 14:36:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:36:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:37:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:37:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:37:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:37:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:38:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:38:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:38:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:38:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:38:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:39:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:39:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:39:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:41:01 | INFO | train_inner | {"epoch": 1, "update": 0.433, "loss": "1.659", "code_loss": "1.72", "value_loss_mse": "0.019", "code_ppl": "3.29", "wps": "7721.4", "ups": "0.03", "wpb": "237427", "bsz": "1024", "num_updates": "5060", "lr": "0.000253", "gnorm": "5.537", "loss_scale": "0.25", "train_wall": "47", "gb_free": "12.9", "wall": "68589"}
[0.0004711151123046875, 0.0018310546875, 0.0021648406982421875, 0.0005035400390625, 0.0004305839538574219]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0006880760192871094, 0.2132568359375, 0.003692626953125, 0.00183868408203125, 0.0015125274658203125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0005860328674316406, 0.217529296875, 0.00319671630859375, 0.0014553070068359375, 0.0011425018310546875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0012254714965820312, 0.179931640625, 0.004608154296875, 0.003650665283203125, 0.00323486328125]
byte6 tgt value: [0.0, 0.0, 0.0, 0.01171875, 0.01171875]
byte6 pred value: [0.00208282470703125, 0.298828125, 0.006290435791015625, 0.0273284912109375, 0.0235595703125]
byte7 tgt value: [0.0, 0.46484375, 0.0, 0.01953125, 0.015625]
byte7 pred value: [0.00812530517578125, 0.52294921875, 0.007205963134765625, 0.53955078125, 0.441162109375]
byte8 tgt value: [0.0625, 0.375, 0.0625, 0.125, 0.9921875]
byte8 pred value: [0.14892578125, 0.41796875, 0.03131103515625, 0.505859375, 0.498779296875]
tgt code: rax rdi hexvar rdi hexvar
pred code: rbp rbx hexvar rbx hexvar
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0101318359375, 0.0190887451171875, 0.004924774169921875, 0.0012254714965820312, 0.00861358642578125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00919342041015625, 0.0196075439453125, 0.0041351318359375, 0.0007181167602539062, 0.008514404296875]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.010986328125, 0.08123779296875, 0.013427734375, 0.000820159912109375, 0.01374053955078125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.01233673095703125, 0.11029052734375, 0.018798828125, 0.0005011558532714844, 0.012237548828125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.056121826171875, 0.093017578125, 0.0115509033203125, 0.0023326873779296875, 0.05291748046875]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.06268310546875, 0.092041015625, 0.0144500732421875, 0.0021991729736328125, 0.054412841796875]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.0782470703125, 0.07696533203125, 0.01009368896484375, 0.004924774169921875, 0.0703125]
byte8 tgt value: [0.23046875, 0.0, 0.0, 0.2109375, 0.0]
byte8 pred value: [0.1434326171875, 0.1695556640625, 0.045196533203125, 0.2470703125, 0.0802001953125]
tgt code: lea hexvar mov ^4 rsp
pred code: mov hexvar lea ^4 rsp
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0143890380859375, 0.00243377685546875, 0.0009660720825195312, 0.0015192031860351562, 0.010986328125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.01507568359375, 0.0037364959716796875, 0.0011835098266601562, 0.0011472702026367188, 0.0125732421875]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0129241943359375, 0.2447509765625, 0.0095977783203125, 0.0015363693237304688, 0.1759033203125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.01363372802734375, 0.378173828125, 0.010986328125, 0.0011692047119140625, 0.2293701171875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0185394287109375, 0.379150390625, 0.01363372802734375, 0.0008935928344726562, 0.302734375]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.01560211181640625, 0.363525390625, 0.0162811279296875, 0.0013942718505859375, 0.28515625]
byte7 tgt value: [0.0, 0.49609375, 0.4921875, 0.0, 0.56640625]
byte7 pred value: [0.014617919921875, 0.2398681640625, 0.4892578125, 0.003692626953125, 0.332275390625]
byte8 tgt value: [0.0, 0.0859375, 0.78515625, 0.078125, 0.02734375]
byte8 pred value: [0.05340576171875, 0.54150390625, 0.5732421875, 0.10540771484375, 0.411865234375]
tgt code: - hexvar rax ^8 rbp
pred code: - hexvar rax ^8 rbp
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0020904541015625, 0.001094818115234375, 0.0004973411560058594, 0.0011339187622070312, 0.0007672309875488281]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.002140045166015625, 0.0012845993041992188, 0.0005617141723632812, 0.0015306472778320312, 0.0009474754333496094]
byte3 tgt value: [0.34375, 0.0, 0.0703125, 0.0703125, 0.0703125]
byte3 pred value: [0.16259765625, 0.00217437744140625, 0.196044921875, 0.215576171875, 0.1676025390625]
byte4 tgt value: [0.5625, 0.0, 0.84765625, 0.84765625, 0.84765625]
byte4 pred value: [0.7138671875, 0.001949310302734375, 0.71923828125, 0.8486328125, 0.82080078125]
byte5 tgt value: [0.74609375, 0.0, 0.9609375, 0.9609375, 0.9609375]
byte5 pred value: [0.68017578125, 0.003780364990234375, 0.8642578125, 0.87548828125, 0.82373046875]
byte6 tgt value: [0.4140625, 0.0, 0.7578125, 0.7578125, 0.7578125]
byte6 pred value: [0.417236328125, 0.0036220550537109375, 0.80419921875, 0.8564453125, 0.85498046875]
byte7 tgt value: [0.1640625, 0.0, 0.66796875, 0.265625, 0.265625]
byte7 pred value: [0.15673828125, 0.0029468536376953125, 0.6611328125, 0.32177734375, 0.166015625]
byte8 tgt value: [0.625, 0.0, 0.25, 0.3046875, 0.2578125]
byte8 pred value: [0.61865234375, 0.00937652587890625, 0.32080078125, 0.35595703125, 0.27197265625]
tgt code: + rax hexvar ^4 rip
pred code: + rax hexvar ^4 rip
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00482940673828125, 0.0006589889526367188, 0.0020198822021484375, 0.0032482147216796875, 0.0012645721435546875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.006488800048828125, 0.0008759498596191406, 0.0018968582153320312, 0.0028667449951171875, 0.0011510848999023438]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.01137542724609375, 0.0015125274658203125, 0.0034961700439453125, 0.0054473876953125, 0.001956939697265625]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.00885009765625, 0.0018606185913085938, 0.004520416259765625, 0.00391387939453125, 0.0016164779663085938]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.00963592529296875, 0.002811431884765625, 0.00536346435546875, 0.004505157470703125, 0.0016489028930664062]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.01332855224609375, 0.00453948974609375, 0.0059814453125, 0.00595855712890625, 0.0020427703857421875]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.01009368896484375, 0.005344390869140625, 0.00557708740234375, 0.005039215087890625, 0.00279998779296875]
byte8 tgt value: [0.00390625, 0.0, 0.0, 0.00390625, 0.03125]
byte8 pred value: [0.1485595703125, 0.15234375, 0.0272216796875, 0.0948486328125, 0.07159423828125]
tgt code: eax + ^8 hexvar rbx
pred code: eax + ^8 al rbx
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00313568115234375, 0.0006413459777832031, 0.0008358955383300781, 0.00023233890533447266, 0.00022339820861816406]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0031719207763671875, 0.0005011558532714844, 0.0009851455688476562, 0.0003597736358642578, 0.00031256675720214844]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.005535125732421875, 0.0010204315185546875, 0.0009965896606445312, 0.0026721954345703125, 0.0014047622680664062]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0082550048828125, 0.0007467269897460938, 0.0010404586791992188, 0.0048675537109375, 0.001979827880859375]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.00867462158203125, 0.0013780593872070312, 0.0010280609130859375, 0.004924774169921875, 0.00250244140625]
byte6 tgt value: [0.0, 0.0078125, 0.0, 0.00390625, 0.00390625]
byte6 pred value: [0.0089874267578125, 0.005138397216796875, 0.001201629638671875, 0.0125732421875, 0.0079345703125]
byte7 tgt value: [0.0, 0.23828125, 0.0, 0.15234375, 0.87890625]
byte7 pred value: [0.00885009765625, 0.26220703125, 0.00130462646484375, 0.17333984375, 0.2271728515625]
byte8 tgt value: [0.015625, 0.5625, 0.0078125, 0.3125, 0.25]
byte8 pred value: [0.04400634765625, 0.56298828125, 0.0379638671875, 0.51611328125, 0.501953125]
tgt code: test ecx ecx hexvar ^8
pred code: mov hexvar hexvar hexvar ^8
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: 2021-10-11 14:43:06 | INFO | train_inner | {"epoch": 1, "update": 0.434, "loss": "1.683", "code_loss": "1.717", "value_loss_mse": "0.019", "code_ppl": "3.29", "wps": "18554.2", "ups": "0.08", "wpb": "233190", "bsz": "1024", "num_updates": "5070", "lr": "0.0002535", "gnorm": "5.864", "loss_scale": "0.25", "train_wall": "19", "gb_free": "12.9", "wall": "68715"}
2021-10-11 14:43:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:43:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0008072853088378906, 0.0011034011840820312, 0.00037407875061035156, 0.0006165504455566406, 0.0008392333984375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0010166168212890625, 0.0013408660888671875, 0.00047469139099121094, 0.0006933212280273438, 0.0008726119995117188]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0012998580932617188, 0.03753662109375, 0.002140045166015625, 0.0007524490356445312, 0.012054443359375]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0005884170532226562, 0.027008056640625, 0.00157928466796875, 0.0006289482116699219, 0.01395416259765625]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0013942718505859375, 0.06304931640625, 0.004364013671875, 0.0010166168212890625, 0.020599365234375]
byte6 tgt value: [0.0, 0.0, 0.015625, 0.0, 0.0]
byte6 pred value: [0.00473785400390625, 0.09271240234375, 0.024749755859375, 0.0021572113037109375, 0.0285491943359375]
byte7 tgt value: [0.0, 0.92578125, 0.69140625, 0.0, 0.44921875]
byte7 pred value: [0.0115509033203125, 0.70947265625, 0.56201171875, 0.0092315673828125, 0.64794921875]
byte8 tgt value: [0.1875, 0.625, 0.05078125, 0.125, 0.25]
byte8 pred value: [0.0300445556640625, 0.5126953125, 0.51953125, 0.1708984375, 0.5263671875]
tgt code: push push test rsi je
pred code: mov mov mov eax jmp
2021-10-11 14:43:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:43:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:44:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:44:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:45:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:45:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:47:02 | INFO | train_inner | {"epoch": 1, "update": 0.436, "loss": "1.66", "code_loss": "1.732", "value_loss_mse": "0.019", "code_ppl": "3.32", "wps": "10279.2", "ups": "0.04", "wpb": "241766", "bsz": "1024", "num_updates": "5080", "lr": "0.000254", "gnorm": "5.709", "loss_scale": "0.25", "train_wall": "44", "gb_free": "12.9", "wall": "68950"}
2021-10-11 14:48:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:49:27 | INFO | train_inner | {"epoch": 1, "update": 0.436, "loss": "1.632", "code_loss": "1.729", "value_loss_mse": "0.018", "code_ppl": "3.32", "wps": "17827.2", "ups": "0.07", "wpb": "259354", "bsz": "1024", "num_updates": "5090", "lr": "0.0002545", "gnorm": "5.458", "loss_scale": "0.25", "train_wall": "24", "gb_free": "12.9", "wall": "69096"}
2021-10-11 14:49:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:51:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:51:54 | INFO | train_inner | {"epoch": 1, "update": 0.437, "loss": "1.645", "code_loss": "1.701", "value_loss_mse": "0.019", "code_ppl": "3.25", "wps": "15004.4", "ups": "0.07", "wpb": "220170", "bsz": "1024", "num_updates": "5100", "lr": "0.000255", "gnorm": "7.791", "loss_scale": "0.25", "train_wall": "18", "gb_free": "12.9", "wall": "69242"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0016164779663085938, 0.004314422607421875, 0.0015125274658203125, 0.0009436607360839844, 0.0033893585205078125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0015668869018554688, 0.0026721954345703125, 0.001628875732421875, 0.001155853271484375, 0.0036640167236328125]
byte3 tgt value: [0.0, 0.21875, 0.0, 0.0, 0.0]
byte3 pred value: [0.00494384765625, 0.2115478515625, 0.00885009765625, 0.002269744873046875, 0.0083770751953125]
byte4 tgt value: [0.0, 0.57421875, 0.0, 0.0, 0.0]
byte4 pred value: [0.0074310302734375, 0.6015625, 0.0235595703125, 0.0033893585205078125, 0.0104522705078125]
byte5 tgt value: [0.0, 0.06640625, 0.0, 0.0, 0.0]
byte5 pred value: [0.0083160400390625, 0.1259765625, 0.012237548828125, 0.003124237060546875, 0.008544921875]
byte6 tgt value: [0.0, 0.43359375, 0.0, 0.0, 0.0]
byte6 pred value: [0.00646209716796875, 0.485595703125, 0.0135345458984375, 0.002368927001953125, 0.008514404296875]
byte7 tgt value: [0.0, 0.23828125, 0.0, 0.0, 0.0]
byte7 pred value: [0.011688232421875, 0.1163330078125, 0.0239105224609375, 0.0038242340087890625, 0.00989532470703125]
byte8 tgt value: [0.0, 0.5625, 0.0, 0.00390625, 0.00390625]
byte8 pred value: [0.06829833984375, 0.51123046875, 0.115966796875, 0.0379638671875, 0.0287628173828125]
tgt code: + hexvar rbp sub call
pred code: + hexvar rbp push call
2021-10-11 14:53:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:54:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:54:40 | INFO | train_inner | {"epoch": 1, "update": 0.438, "loss": "1.614", "code_loss": "1.731", "value_loss_mse": "0.018", "code_ppl": "3.32", "wps": "15305.8", "ups": "0.06", "wpb": "254314", "bsz": "1024", "num_updates": "5110", "lr": "0.0002555", "gnorm": "5.168", "loss_scale": "0.25", "train_wall": "21", "gb_free": "12.9", "wall": "69409"}
2021-10-11 14:56:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:56:56 | INFO | train_inner | {"epoch": 1, "update": 0.439, "loss": "1.59", "code_loss": "1.677", "value_loss_mse": "0.018", "code_ppl": "3.2", "wps": "17368.2", "ups": "0.07", "wpb": "236989", "bsz": "1024", "num_updates": "5120", "lr": "0.000256", "gnorm": "5.235", "loss_scale": "0.25", "train_wall": "22", "gb_free": "12.9", "wall": "69545"}
2021-10-11 14:58:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:58:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:58:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:59:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:59:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:59:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:59:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 14:59:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:00:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:00:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:00:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:00:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:01:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:01:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:01:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:01:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:01:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:02:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:02:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:02:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:02:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:02:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:03:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:03:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:03:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:03:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:03:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:04:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:04:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:04:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:04:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:04:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:05:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:05:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:05:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:05:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:05:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:06:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:06:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:06:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:06:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:07:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:07:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:07:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:07:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:07:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:08:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:08:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:08:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:08:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:09:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:09:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:09:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:09:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:09:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:10:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:10:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:10:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:10:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:11:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:11:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:11:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:11:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:11:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:12:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:12:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:12:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:12:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:13:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:13:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:13:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:13:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:13:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:14:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:14:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:14:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:14:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:14:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:15:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:15:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:15:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:15:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:16:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:16:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:16:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:16:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:16:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:17:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:17:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:17:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:17:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:17:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:18:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:18:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:18:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:18:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:18:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:19:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:19:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:19:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:19:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:20:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:20:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:20:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:20:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:20:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:21:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00042724609375, 0.0018463134765625, 0.0009622573852539062, 0.0005092620849609375, 0.0017480850219726562]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0006799697875976562, 0.0022430419921875, 0.0009112358093261719, 0.0005035400390625, 0.001495361328125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0005636215209960938, 0.059417724609375, 0.0033512115478515625, 0.0010528564453125, 0.00464630126953125]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0006589889526367188, 0.0850830078125, 0.00524139404296875, 0.00206756591796875, 0.005260467529296875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.52734375, 0.52734375]
byte5 pred value: [0.0009288787841796875, 0.12139892578125, 0.12274169921875, 0.058990478515625, 0.03179931640625]
byte6 tgt value: [0.0, 0.00390625, 0.0, 0.5546875, 0.5546875]
byte6 pred value: [0.0020351409912109375, 0.1485595703125, 0.155517578125, 0.06268310546875, 0.0245208740234375]
byte7 tgt value: [0.0, 0.609375, 0.0, 0.375, 0.375]
byte7 pred value: [0.015899658203125, 0.5361328125, 0.208984375, 0.07354736328125, 0.03607177734375]
byte8 tgt value: [0.03125, 0.3125, 0.00390625, 0.8125, 0.8125]
byte8 pred value: [0.1947021484375, 0.459228515625, 0.2088623046875, 0.11798095703125, 0.036163330078125]
tgt code: edi rbx eax test rsp
pred code: edi rbx eax mov eax
2021-10-11 15:21:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:21:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:21:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:21:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:22:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:22:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:22:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:22:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:22:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:23:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:23:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:23:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:23:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:24:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:24:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:24:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:24:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:24:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:25:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:25:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:25:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:25:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:25:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:26:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:26:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:26:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:26:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:26:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:27:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:27:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:27:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:27:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:28:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:28:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:28:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:28:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:28:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:29:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:29:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:29:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:29:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:29:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:30:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:30:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:30:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:30:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:30:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:31:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:31:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:31:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:31:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:32:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:32:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:32:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:32:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:32:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:32:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:33:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:33:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00428009033203125, 0.0007791519165039062, 0.0005793571472167969, 0.0008392333984375, 0.01036834716796875]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.004467010498046875, 0.0007581710815429688, 0.0003845691680908203, 0.0004494190216064453, 0.00861358642578125]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.005405426025390625, 0.0008263587951660156, 0.0011472702026367188, 0.0012693405151367188, 0.0219879150390625]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.00661468505859375, 0.0010986328125, 0.001056671142578125, 0.0020503997802734375, 0.050506591796875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.00930023193359375, 0.0017137527465820312, 0.0016813278198242188, 0.0014553070068359375, 0.050811767578125]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.007232666015625, 0.0016937255859375, 0.001956939697265625, 0.001918792724609375, 0.06793212890625]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.78125]
byte7 pred value: [0.007549285888671875, 0.005062103271484375, 0.002349853515625, 0.00257110595703125, 0.06707763671875]
byte8 tgt value: [0.203125, 0.03125, 0.03125, 0.25, 0.125]
byte8 pred value: [0.08404541015625, 0.0809326171875, 0.04486083984375, 0.2381591796875, 0.159423828125]
tgt code: mov rax + + rax
pred code: mov rax rsp + rax
2021-10-11 15:33:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:33:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:34:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:34:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:34:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:34:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:34:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:35:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:35:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:35:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:35:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:35:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:36:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:36:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:36:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:36:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:36:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:37:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:37:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:37:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:37:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
[0.0017004013061523438, 0.0026416778564453125, 0.0016813278198242188, 0.0008592605590820312, 0.0007266998291015625]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00154876708984375, 0.0029468536376953125, 0.001934051513671875, 0.0006747245788574219, 0.0006852149963378906]
byte3 tgt value: [0.0, 0.49609375, 0.49609375, 0.0, 0.0]
byte3 pred value: [0.0018463134765625, 0.51318359375, 0.505859375, 0.0017547607421875, 0.0012598037719726562]
byte4 tgt value: [0.0, 0.99609375, 0.99609375, 0.0, 0.0]
byte4 pred value: [0.0026721954345703125, 0.99365234375, 0.99267578125, 0.0014047622680664062, 0.0011472702026367188]
byte5 tgt value: [0.0, 0.70703125, 0.70703125, 0.0, 0.0]
byte5 pred value: [0.0020580291748046875, 0.7294921875, 0.736328125, 0.00238800048828125, 0.0023593902587890625]
byte6 tgt value: [0.0, 0.17578125, 0.17578125, 0.0, 0.0]
byte6 pred value: [0.0025501251220703125, 0.249755859375, 0.26025390625, 0.0030994415283203125, 0.0032482147216796875]
byte7 tgt value: [0.0, 0.86328125, 0.86328125, 0.0, 0.0]
byte7 pred value: [0.00679779052734375, 0.8876953125, 0.8603515625, 0.00464630126953125, 0.00269317626953125]
byte8 tgt value: [0.0625, 0.125, 0.125, 0.15625, 0.28515625]
byte8 pred value: [0.090087890625, 0.0987548828125, 0.102294921875, 0.130859375, 0.155517578125]
tgt code: mov rax rax ^8 rip
pred code: mov rax edi ^8 rip
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0005998611450195312, 0.0004029273986816406, 0.0004858970642089844, 5.9664249420166016e-05, 0.0004513263702392578]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0006213188171386719, 0.0003712177276611328, 0.0004305839538574219, 7.903575897216797e-05, 0.0006022453308105469]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0024051666259765625, 0.0018968582153320312, 0.0025310516357421875, 0.00035691261291503906, 0.0141754150390625]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0022525787353515625, 0.0023593902587890625, 0.0028228759765625, 0.00037407875061035156, 0.0177764892578125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0029926300048828125, 0.00399017333984375, 0.0032596588134765625, 0.0038242340087890625, 0.0299224853515625]
byte6 tgt value: [0.0, 0.0, 0.00390625, 0.0, 0.01171875]
byte6 pred value: [0.01262664794921875, 0.0101318359375, 0.01233673095703125, 0.0058441162109375, 0.03607177734375]
byte7 tgt value: [0.98046875, 0.98046875, 0.03515625, 0.24609375, 0.62109375]
byte7 pred value: [0.84814453125, 0.8388671875, 0.8515625, 0.1514892578125, 0.5869140625]
byte8 tgt value: [0.453125, 0.765625, 0.953125, 0.921875, 0.59375]
byte8 pred value: [0.52978515625, 0.52685546875, 0.52099609375, 0.38916015625, 0.51025390625]
tgt code: lea rax rip hexvar lea
pred code: lea rax rip hexvar je
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0006117820739746094, 0.00055694580078125, 0.0008392333984375, 0.0004239082336425781, 0.0005526542663574219]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0006666183471679688, 0.00047278404235839844, 0.0007238388061523438, 0.0006461143493652344, 0.0006413459777832031]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0020999908447265625, 0.0008039474487304688, 0.006565093994140625, 0.0014047622680664062, 0.0006747245788574219]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0014896392822265625, 0.0006961822509765625, 0.00424957275390625, 0.0007886886596679688, 0.00034880638122558594]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.003765106201171875, 0.0009398460388183594, 0.0089874267578125, 0.0036220550537109375, 0.0017480850219726562]
byte6 tgt value: [0.0078125, 0.0, 0.0, 0.01953125, 0.01953125]
byte6 pred value: [0.00653839111328125, 0.0009851455688476562, 0.0103302001953125, 0.0252227783203125, 0.014007568359375]
byte7 tgt value: [0.796875, 0.0, 0.69140625, 0.54296875, 0.54296875]
byte7 pred value: [0.7724609375, 0.0015306472778320312, 0.83935546875, 0.5322265625, 0.47509765625]
byte8 tgt value: [0.27734375, 0.015625, 0.9375, 0.90234375, 0.7421875]
byte8 pred value: [0.45068359375, 0.027008056640625, 0.4716796875, 0.49951171875, 0.398193359375]
tgt code: rbx cmp ^1 sete cmp
pred code: r13 mov ^1 push mov
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0020503997802734375, 0.001934051513671875, 0.0017337799072265625, 0.0116424560546875, 0.0008759498596191406]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0021820068359375, 0.0018672943115234375, 0.001979827880859375, 0.01363372802734375, 0.0009436607360839844]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0020275115966796875, 0.0018606185913085938, 0.06878662109375, 0.0169219970703125, 0.036834716796875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0015668869018554688, 0.0020351409912109375, 0.0216217041015625, 0.009521484375, 0.1239013671875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0032482147216796875, 0.001438140869140625, 0.11474609375, 0.010009765625, 0.05340576171875]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.00390625]
byte6 pred value: [0.00400543212890625, 0.0015850067138671875, 0.08154296875, 0.01525115966796875, 0.12890625]
byte7 tgt value: [0.0, 0.0, 0.62890625, 0.0, 0.80078125]
byte7 pred value: [0.0233306884765625, 0.003147125244140625, 0.65380859375, 0.018768310546875, 0.71630859375]
byte8 tgt value: [0.00390625, 0.18359375, 0.3125, 0.03125, 0.21875]
byte8 pred value: [0.03173828125, 0.1094970703125, 0.492919921875, 0.03875732421875, 0.486572265625]
tgt code: ^8 call r13 jmp hexvar
pred code: ^8 mov rbx mov rdi
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0005702972412109375, 0.00238800048828125, 0.00154876708984375, 0.000583648681640625, 0.0010528564453125]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0006513595581054688, 0.0024051666259765625, 0.001674652099609375, 0.0007410049438476562, 0.0010204315185546875]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.004364013671875, 0.0035381317138671875, 0.002132415771484375, 0.0026111602783203125, 0.0013456344604492188]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0053863525390625, 0.002834320068359375, 0.0015850067138671875, 0.00260162353515625, 0.0015192031860351562]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.00536346435546875, 0.005535125732421875, 0.00397491455078125, 0.002704620361328125, 0.0016164779663085938]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.00787353515625, 0.005428314208984375, 0.00441741943359375, 0.006072998046875, 0.0017414093017578125]
byte7 tgt value: [0.13671875, 0.0, 0.0, 0.12890625, 0.0]
byte7 pred value: [0.11065673828125, 0.00891876220703125, 0.0066680908203125, 0.1300048828125, 0.00269317626953125]
byte8 tgt value: [0.5, 0.01953125, 0.0, 0.9375, 0.04296875]
byte8 pred value: [0.278564453125, 0.056243896484375, 0.054901123046875, 0.311279296875, 0.0948486328125]
tgt code: rdi rbx mov rsi rcx
pred code: hexvar rbx push hexvar rax
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00041413307189941406, 0.0006213188171386719, 0.007175445556640625, 0.0083465576171875, 0.00019872188568115234]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00047850608825683594, 0.0006718635559082031, 0.008575439453125, 0.00930023193359375, 0.00030541419982910156]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0018749237060546875, 0.0006022453308105469, 0.007518768310546875, 0.0083160400390625, 0.0011692047119140625]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.002414703369140625, 0.0006165504455566406, 0.00669097900390625, 0.00760650634765625, 0.0007295608520507812]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.004398345947265625, 0.0016813278198242188, 0.0102081298828125, 0.02386474609375, 0.003749847412109375]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.00390625]
byte6 pred value: [0.00800323486328125, 0.003223419189453125, 0.0082855224609375, 0.0216522216796875, 0.028106689453125]
byte7 tgt value: [0.27734375, 0.0, 0.0, 0.0, 0.3046875]
byte7 pred value: 2021-10-11 15:37:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2021-10-11 15:38:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
2021-10-11 15:38:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
2021-10-11 15:39:04 | INFO | train_inner | {"epoch": 1, "update": 0.455, "loss": "1.636", "code_loss": "1.687", "value_loss_mse": "0.018", "code_ppl": "3.22", "wps": "927.3", "ups": "0", "wpb": "234419", "bsz": "1024", "num_updates": "5130", "lr": "0.0002565", "gnorm": "7.688", "loss_scale": "0.0625", "train_wall": "826", "gb_free": "12.9", "wall": "72073"}
2021-10-11 15:41:15 | INFO | train_inner | {"epoch": 1, "update": 0.456, "loss": "1.634", "code_loss": "1.706", "value_loss_mse": "0.018", "code_ppl": "3.26", "wps": "18776.7", "ups": "0.08", "wpb": "245136", "bsz": "1024", "num_updates": "5140", "lr": "0.000257", "gnorm": "5.573", "loss_scale": "0.0625", "train_wall": "38", "gb_free": "12.9", "wall": "72204"}
2021-10-11 15:43:21 | INFO | train_inner | {"epoch": 1, "update": 0.457, "loss": "1.652", "code_loss": "1.684", "value_loss_mse": "0.019", "code_ppl": "3.21", "wps": "18429.3", "ups": "0.08", "wpb": "232093", "bsz": "1024", "num_updates": "5150", "lr": "0.0002575", "gnorm": "7.822", "loss_scale": "0.0625", "train_wall": "16", "gb_free": "12.9", "wall": "72330"}
2021-10-11 15:45:32 | INFO | train_inner | {"epoch": 1, "update": 0.458, "loss": "1.629", "code_loss": "1.722", "value_loss_mse": "0.018", "code_ppl": "3.3", "wps": "18820.2", "ups": "0.08", "wpb": "246117", "bsz": "1024", "num_updates": "5160", "lr": "0.000258", "gnorm": "6.435", "loss_scale": "0.0625", "train_wall": "17", "gb_free": "12.9", "wall": "72460"}
2021-10-11 15:47:25 | INFO | train_inner | {"epoch": 1, "update": 0.459, "loss": "1.626", "code_loss": "1.667", "value_loss_mse": "0.018", "code_ppl": "3.18", "wps": "18841", "ups": "0.09", "wpb": "213757", "bsz": "1024", "num_updates": "5170", "lr": "0.0002585", "gnorm": "5.764", "loss_scale": "0.0625", "train_wall": "14", "gb_free": "12.9", "wall": "72574"}
2021-10-11 15:49:38 | INFO | train_inner | {"epoch": 1, "update": 0.459, "loss": "1.617", "code_loss": "1.714", "value_loss_mse": "0.018", "code_ppl": "3.28", "wps": "18467.6", "ups": "0.08", "wpb": "245904", "bsz": "1024", "num_updates": "5180", "lr": "0.000259", "gnorm": "6.842", "loss_scale": "0.0625", "train_wall": "21", "gb_free": "12.9", "wall": "72707"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00015115737915039062, 0.0001647472381591797, 0.00034737586975097656, 0.00014543533325195312, 0.00034737586975097656]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0002532005310058594, 0.0002715587615966797, 0.000507354736328125, 0.0002269744873046875, 0.00040459632873535156]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0010042190551757812, 0.0006799697875976562, 0.0007762908935546875, 0.0009584426879882812, 0.0017271041870117188]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0012645721435546875, 0.0010166168212890625, 0.002010345458984375, 0.0010318756103515625, 0.00327301025390625]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0034427642822265625, 0.0063629150390625, 0.00453948974609375, 0.002590179443359375, 0.0036067962646484375]
byte6 tgt value: [0.01953125, 0.0, 0.0, 0.01953125, 0.0]
byte6 pred value: [0.015838623046875, 0.006565093994140625, 0.004199981689453125, 0.012725830078125, 0.006511688232421875]
byte7 tgt value: [0.17578125, 0.0, 0.0, 0.171875, 0.640625]
byte7 pred value: [0.2342529296875, 0.01332855224609375, 0.00997161865234375, 0.2120361328125, 0.61572265625]
byte8 tgt value: [0.3359375, 0.2734375, 0.0, 0.765625, 0.77734375]
byte8 pred value: [0.499755859375, 0.3642578125, 0.2220458984375, 0.513671875, 0.62451171875]
tgt code: je hexvar rax nop +
pred code: lea hexvar rax lea +
2021-10-11 15:51:47 | INFO | train_inner | {"epoch": 1, "update": 0.46, "loss": "1.651", "code_loss": "1.723", "value_loss_mse": "0.019", "code_ppl": "3.3", "wps": "19067.1", "ups": "0.08", "wpb": "245037", "bsz": "1024", "num_updates": "5190", "lr": "0.0002595", "gnorm": "6.407", "loss_scale": "0.0625", "train_wall": "16", "gb_free": "12.9", "wall": "72835"}
2021-10-11 15:53:52 | INFO | train_inner | {"epoch": 1, "update": 0.461, "loss": "1.636", "code_loss": "1.685", "value_loss_mse": "0.018", "code_ppl": "3.21", "wps": "19236.6", "ups": "0.08", "wpb": "240339", "bsz": "1024", "num_updates": "5200", "lr": "0.00026", "gnorm": "5.147", "loss_scale": "0.0625", "train_wall": "16", "gb_free": "12.9", "wall": "72960"}
2021-10-11 15:54:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
2021-10-11 15:56:13 | INFO | train_inner | {"epoch": 1, "update": 0.462, "loss": "1.642", "code_loss": "1.69", "value_loss_mse": "0.019", "code_ppl": "3.23", "wps": "16871.3", "ups": "0.07", "wpb": "238944", "bsz": "1024", "num_updates": "5210", "lr": "0.0002605", "gnorm": "12.217", "loss_scale": "0.0625", "train_wall": "18", "gb_free": "12.9", "wall": "73102"}
2021-10-11 15:58:22 | INFO | train_inner | {"epoch": 1, "update": 0.463, "loss": "1.637", "code_loss": "1.709", "value_loss_mse": "0.018", "code_ppl": "3.27", "wps": "19174.8", "ups": "0.08", "wpb": "247149", "bsz": "1024", "num_updates": "5220", "lr": "0.000261", "gnorm": "7.033", "loss_scale": "0.0625", "train_wall": "16", "gb_free": "12.9", "wall": "73231"}
2021-10-11 16:00:36 | INFO | train_inner | {"epoch": 1, "update": 0.463, "loss": "1.645", "code_loss": "1.697", "value_loss_mse": "0.019", "code_ppl": "3.24", "wps": "18719.3", "ups": "0.07", "wpb": "250384", "bsz": "1024", "num_updates": "5230", "lr": "0.0002615", "gnorm": "6.361", "loss_scale": "0.0625", "train_wall": "17", "gb_free": "12.9", "wall": "73365"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00027370452880859375, 0.0028667449951171875, 0.0015850067138671875, 0.0002892017364501953, 0.0007853507995605469]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.00033283233642578125, 0.0036640167236328125, 0.0014667510986328125, 0.0004076957702636719, 0.0007853507995605469]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0008168220520019531, 0.0034427642822265625, 0.001972198486328125, 0.001094818115234375, 0.0008134841918945312]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0005793571472167969, 0.004364013671875, 0.0022602081298828125, 0.0007643699645996094, 0.0008072853088378906]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.0013408660888671875, 0.00864410400390625, 0.007518768310546875, 0.0015430450439453125, 0.04107666015625]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.0015125274658203125, 0.00812530517578125, 0.00609588623046875, 0.0017614364624023438, 0.0276947021484375]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.00263214111328125, 0.01146697998046875, 0.004398345947265625, 0.0015363693237304688, 0.022247314453125]
byte8 tgt value: [0.0078125, 0.11328125, 0.171875, 0.0078125, 0.00390625]
byte8 pred value: [0.0207977294921875, 0.09503173828125, 0.1580810546875, 0.021820068359375, 0.1300048828125]
tgt code: hexvar mov rdi hexvar +
pred code: hexvar mov rdi hexvar +
2021-10-11 16:02:44 | INFO | train_inner | {"epoch": 1, "update": 0.464, "loss": "1.643", "code_loss": "1.689", "value_loss_mse": "0.019", "code_ppl": "3.22", "wps": "18586.4", "ups": "0.08", "wpb": "237952", "bsz": "1024", "num_updates": "5240", "lr": "0.000262", "gnorm": "9.298", "loss_scale": "0.0625", "train_wall": "16", "gb_free": "12.9", "wall": "73493"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.01107025146484375, 0.0017337799072265625, 0.002323150634765625, 0.0009398460388183594, 0.0034027099609375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.01473236083984375, 0.0018100738525390625, 0.00243377685546875, 0.0010166168212890625, 0.0033245086669921875]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.29296875]
byte3 pred value: [0.01560211181640625, 0.339599609375, 0.004199981689453125, 0.0036640167236328125, 0.404052734375]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.25]
byte4 pred value: [0.01395416259765625, 0.1124267578125, 0.004680633544921875, 0.0038089752197265625, 0.061981201171875]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.6796875]
byte5 pred value: [0.0243377685546875, 0.5673828125, 0.005619049072265625, 0.004848480224609375, 0.7197265625]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.71484375]
byte6 pred value: [0.0136871337890625, 0.6572265625, 0.00469970703125, 0.00661468505859375, 0.76904296875]
byte7 tgt value: [0.0, 0.703125, 0.0, 0.0, 0.578125]
byte7 pred value: [0.026763916015625, 0.47998046875, 0.0035247802734375, 0.0037078857421875, 0.541015625]
byte8 tgt value: [0.01953125, 0.90234375, 0.09375, 0.15625, 0.55859375]
byte8 pred value: [0.2105712890625, 0.5771484375, 0.07354736328125, 0.1826171875, 0.57080078125]
tgt code: mov hexvar edx rdi hexvar
pred code: mov hexvar edx hexvar hexvar
2021-10-11 16:04:47 | INFO | train_inner | {"epoch": 1, "update": 0.465, "loss": "1.602", "code_loss": "1.663", "value_loss_mse": "0.018", "code_ppl": "3.17", "wps": "19287.7", "ups": "0.08", "wpb": "236914", "bsz": "1024", "num_updates": "5250", "lr": "0.0002625", "gnorm": "6.073", "loss_scale": "0.0625", "train_wall": "20", "gb_free": "12.9", "wall": "73616"}
2021-10-11 16:06:55 | INFO | train_inner | {"epoch": 1, "update": 0.466, "loss": "1.575", "code_loss": "1.654", "value_loss_mse": "0.018", "code_ppl": "3.15", "wps": "19005", "ups": "0.08", "wpb": "242979", "bsz": "1024", "num_updates": "5260", "lr": "0.000263", "gnorm": "6.199", "loss_scale": "0.0625", "train_wall": "46", "gb_free": "12.9", "wall": "73743"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0006961822509765625, 0.003124237060546875, 0.0029468536376953125, 0.001674652099609375, 0.0007295608520507812]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0007319450378417969, 0.002010345458984375, 0.0035800933837890625, 0.0025119781494140625, 0.0008296966552734375]
byte3 tgt value: [0.0, 0.3359375, 0.0, 0.0, 0.0]
byte3 pred value: [0.0017747879028320312, 0.09686279296875, 0.004772186279296875, 0.00250244140625, 0.0017547607421875]
byte4 tgt value: [0.0, 0.953125, 0.0, 0.0, 0.0]
byte4 pred value: [0.0017070770263671875, 0.372802734375, 0.0027256011962890625, 0.0028228759765625, 0.0024242401123046875]
byte5 tgt value: [0.0, 0.55078125, 0.0, 0.0, 0.0]
byte5 pred value: [0.0028896331787109375, 0.257568359375, 0.004486083984375, 0.005199432373046875, 0.0030994415283203125]
byte6 tgt value: [0.0, 0.71484375, 0.0, 0.0, 0.0]
byte6 pred value: [0.005321502685546875, 0.250244140625, 0.0035381317138671875, 0.0060272216796875, 0.00323486328125]
byte7 tgt value: [0.52734375, 0.73828125, 0.0, 0.0, 0.0]
byte7 pred value: [0.51904296875, 0.2496337890625, 0.0038547515869140625, 0.006984710693359375, 0.006072998046875]
byte8 tgt value: [0.81640625, 0.8125, 0.0, 0.00390625, 0.0859375]
byte8 pred value: [0.6181640625, 0.332763671875, 0.013427734375, 0.048309326171875, 0.11029052734375]
tgt code: nop ^8 rbp - hexvar
pred code: nop ^8 r12 - hexvar
2021-10-11 16:09:12 | INFO | train_inner | {"epoch": 1, "update": 0.467, "loss": "1.629", "code_loss": "1.682", "value_loss_mse": "0.018", "code_ppl": "3.21", "wps": "18133.2", "ups": "0.07", "wpb": "249297", "bsz": "1024", "num_updates": "5270", "lr": "0.0002635", "gnorm": "6.521", "loss_scale": "0.0625", "train_wall": "84", "gb_free": "12.9", "wall": "73881"}
2021-10-11 16:11:17 | INFO | train_inner | {"epoch": 1, "update": 0.467, "loss": "1.611", "code_loss": "1.661", "value_loss_mse": "0.018", "code_ppl": "3.16", "wps": "18062.2", "ups": "0.08", "wpb": "225165", "bsz": "1024", "num_updates": "5280", "lr": "0.000264", "gnorm": "7.672", "loss_scale": "0.0625", "train_wall": "100", "gb_free": "12.9", "wall": "74006"}
2021-10-11 16:13:14 | INFO | train_inner | {"epoch": 1, "update": 0.468, "loss": "1.617", "code_loss": "1.632", "value_loss_mse": "0.018", "code_ppl": "3.1", "wps": "18994.2", "ups": "0.09", "wpb": "223123", "bsz": "1024", "num_updates": "5290", "lr": "0.0002645", "gnorm": "6.234", "loss_scale": "0.0625", "train_wall": "38", "gb_free": "12.9", "wall": "74123"}
2021-10-11 16:15:22 | INFO | train_inner | {"epoch": 1, "update": 0.469, "loss": "1.635", "code_loss": "1.666", "value_loss_mse": "0.019", "code_ppl": "3.17", "wps": "18612.9", "ups": "0.08", "wpb": "237555", "bsz": "1024", "num_updates": "5300", "lr": "0.000265", "gnorm": "4.627", "loss_scale": "0.0625", "train_wall": "16", "gb_free": "12.9", "wall": "74251"}
2021-10-11 16:17:22 | INFO | train_inner | {"epoch": 1, "update": 0.47, "loss": "1.603", "code_loss": "1.641", "value_loss_mse": "0.018", "code_ppl": "3.12", "wps": "18626.8", "ups": "0.08", "wpb": "222938", "bsz": "1024", "num_updates": "5310", "lr": "0.0002655", "gnorm": "9.224", "loss_scale": "0.0625", "train_wall": "37", "gb_free": "12.9", "wall": "74370"}
2021-10-11 16:19:33 | INFO | train_inner | {"epoch": 1, "update": 0.471, "loss": "1.605", "code_loss": "1.666", "value_loss_mse": "0.018", "code_ppl": "3.17", "wps": "18042.8", "ups": "0.08", "wpb": "236394", "bsz": "1024", "num_updates": "5320", "lr": "0.000266", "gnorm": "8.061", "loss_scale": "0.0625", "train_wall": "76", "gb_free": "12.9", "wall": "74501"}
2021-10-11 16:21:41 | INFO | train_inner | {"epoch": 1, "update": 0.471, "loss": "1.6", "code_loss": "1.643", "value_loss_mse": "0.018", "code_ppl": "3.12", "wps": "18601.7", "ups": "0.08", "wpb": "239286", "bsz": "1024", "num_updates": "5330", "lr": "0.0002665", "gnorm": "5.063", "loss_scale": "0.0625", "train_wall": "52", "gb_free": "12.9", "wall": "74630"}
2021-10-11 16:23:54 | INFO | train_inner | {"epoch": 1, "update": 0.472, "loss": "1.599", "code_loss": "1.65", "value_loss_mse": "0.018", "code_ppl": "3.14", "wps": "18517.2", "ups": "0.08", "wpb": "245795", "bsz": "1024", "num_updates": "5340", "lr": "0.000267", "gnorm": "7.662", "loss_scale": "0.0625", "train_wall": "17", "gb_free": "12.9", "wall": "74763"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.00260162353515625, 0.0002415180206298828, 0.0002148151397705078, 0.0003199577331542969, 0.0001767873764038086]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.004055023193359375, 0.00041413307189941406, 0.00031495094299316406, 0.0004673004150390625, 0.00025725364685058594]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.03338623046875, 0.0008072853088378906, 0.0005931854248046875, 0.0009183883666992188, 0.0006093978881835938]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.07080078125, 0.0008559226989746094, 0.0008897781372070312, 0.0011692047119140625, 0.0007824897766113281]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.04840087890625, 0.0015544891357421875, 0.0012254714965820312, 0.0013723373413085938, 0.0029926300048828125]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte6 pred value: [0.0299835205078125, 0.003780364990234375, 0.00183868408203125, 0.002323150634765625, 0.00455474853515625]
byte7 tgt value: [0.09375, 0.0, 0.0, 0.0, 0.0]
byte7 pred value: [0.10821533203125, 0.035675048828125, 0.0083465576171875, 0.0100555419921875, 0.0374755859375]
byte8 tgt value: [0.04296875, 0.21875, 0.078125, 0.1875, 0.1875]
byte8 pred value: [0.56494140625, 0.23876953125, 0.2235107421875, 0.236328125, 0.2152099609375]
tgt code: rax rbp rip rdi mov
pred code: rax rbp rip rdi mov
2021-10-11 16:25:52 | INFO | train_inner | {"epoch": 1, "update": 0.473, "loss": "1.597", "code_loss": "1.612", "value_loss_mse": "0.018", "code_ppl": "3.06", "wps": "18299.8", "ups": "0.08", "wpb": "215926", "bsz": "1024", "num_updates": "5350", "lr": "0.0002675", "gnorm": "10.892", "loss_scale": "0.0625", "train_wall": "16", "gb_free": "12.9", "wall": "74881"}
2021-10-11 16:27:56 | INFO | train_inner | {"epoch": 1, "update": 0.474, "loss": "1.631", "code_loss": "1.656", "value_loss_mse": "0.018", "code_ppl": "3.15", "wps": "18568.8", "ups": "0.08", "wpb": "229492", "bsz": "1024", "num_updates": "5360", "lr": "0.000268", "gnorm": "8.425", "loss_scale": "0.0625", "train_wall": "52", "gb_free": "15.7", "wall": "75004"}
2021-10-11 16:30:08 | INFO | train_inner | {"epoch": 1, "update": 0.475, "loss": "1.621", "code_loss": "1.677", "value_loss_mse": "0.018", "code_ppl": "3.2", "wps": "18606.2", "ups": "0.08", "wpb": "246674", "bsz": "1024", "num_updates": "5370", "lr": "0.0002685", "gnorm": "8.111", "loss_scale": "0.0625", "train_wall": "103", "gb_free": "12.9", "wall": "75137"}
2021-10-11 16:32:19 | INFO | train_inner | {"epoch": 1, "update": 0.476, "loss": "1.613", "code_loss": "1.636", "value_loss_mse": "0.018", "code_ppl": "3.11", "wps": "18090.5", "ups": "0.08", "wpb": "236388", "bsz": "1024", "num_updates": "5380", "lr": "0.000269", "gnorm": "7.617", "loss_scale": "0.0625", "train_wall": "95", "gb_free": "20.6", "wall": "75268"}
2021-10-11 16:34:28 | INFO | train_inner | {"epoch": 1, "update": 0.476, "loss": "1.594", "code_loss": "1.648", "value_loss_mse": "0.018", "code_ppl": "3.13", "wps": "18829.7", "ups": "0.08", "wpb": "242600", "bsz": "1024", "num_updates": "5390", "lr": "0.0002695", "gnorm": "11.194", "loss_scale": "0.0625", "train_wall": "61", "gb_free": "12.9", "wall": "75396"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0002453327178955078, 0.0015192031860351562, 0.008544921875, 0.0008039474487304688, 0.005001068115234375]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0002892017364501953, 0.0014667510986328125, 0.00806427001953125, 0.0010480880737304688, 0.004520416259765625]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0006093978881835938, 0.0014781951904296875, 0.0074615478515625, 0.00128936767578125, 0.004329681396484375]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0008459091186523438, 0.0015306472778320312, 0.00948333740234375, 0.0013666152954101562, 0.005138397216796875]
byte5 tgt value: [0.0, 0.0, 0.99609375, 0.0, 0.99609375]
byte5 pred value: [0.00279998779296875, 0.254638671875, 0.239013671875, 0.0050201416015625, 0.2486572265625]
byte6 tgt value: [0.0, 0.0, 0.99609375, 0.0, 0.99609375]
byte6 pred value: [0.0028228759765625, 0.3291015625, 0.269775390625, 0.006744384765625, 0.292724609375]
byte7 tgt value: [0.0, 0.03125, 0.99609375, 0.0, 0.99609375]
byte7 pred value: [0.01094818115234375, 0.276611328125, 0.2391357421875, 0.01116180419921875, 0.2744140625]
byte8 tgt value: [0.0078125, 0.0, 0.5, 0.00390625, 0.99609375]
byte8 pred value: [0.049591064453125, 0.38916015625, 0.339599609375, 0.1131591796875, 0.359375]
tgt code: eax cmp al shr esi
pred code: edx and dl cmp edx
2021-10-11 16:36:40 | INFO | train_inner | {"epoch": 1, "update": 0.477, "loss": "1.596", "code_loss": "1.663", "value_loss_mse": "0.018", "code_ppl": "3.17", "wps": "18282.5", "ups": "0.08", "wpb": "241622", "bsz": "1024", "num_updates": "5400", "lr": "0.00027", "gnorm": "7.351", "loss_scale": "0.0625", "train_wall": "17", "gb_free": "12.9", "wall": "75529"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0010480880737304688, 0.0009398460388183594, 0.00021827220916748047, 0.0004124641418457031, 0.00016868114471435547]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0013246536254882812, 0.0010862350463867188, 0.00022876262664794922, 0.00043892860412597656, 0.0003077983856201172]
byte3 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte3 pred value: [0.0029010772705078125, 0.0012254714965820312, 0.0005974769592285156, 0.0006213188171386719, 0.01049041748046875]
byte4 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte4 pred value: [0.0032596588134765625, 0.0017681121826171875, 0.0009217262268066406, 0.0006313323974609375, 0.02276611328125]
byte5 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte5 pred value: [0.008514404296875, 0.00269317626953125, 0.0010690689086914062, 0.0009851455688476562, 0.0278472900390625]
byte6 tgt value: [0.0, 0.0, 0.0, 0.0, 0.00390625]
byte6 pred value: [0.00679779052734375, 0.002140045166015625, 0.00130462646484375, 0.0011034011840820312, 0.020172119140625]
byte7 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0234375]
byte7 pred value: [0.01267242431640625, 0.0028781890869140625, 0.0029811859130859375, 0.0030879974365234375, 0.1278076171875]
byte8 tgt value: [0.00390625, 0.24609375, 0.00390625, 0.03125, 0.25]
byte8 pred value: [0.06085205078125, 0.1358642578125, 0.08270263671875, 0.044921875, 0.45166015625]
tgt code: mov rbp rbp mov ^4
pred code: mov rbp rbx mov ^4
2021-10-11 16:38:46 | INFO | train_inner | {"epoch": 1, "update": 0.478, "loss": "1.589", "code_loss": "1.639", "value_loss_mse": "0.018", "code_ppl": "3.11", "wps": "19206.6", "ups": "0.08", "wpb": "241379", "bsz": "1024", "num_updates": "5410", "lr": "0.0002705", "gnorm": "7.382", "loss_scale": "0.0625", "train_wall": "23", "gb_free": "12.9", "wall": "75654"}
2021-10-11 16:40:55 | INFO | train_inner | {"epoch": 1, "update": 0.479, "loss": "1.59", "code_loss": "1.621", "value_loss_mse": "0.018", "code_ppl": "3.08", "wps": "18403.6", "ups": "0.08", "wpb": "238105", "bsz": "1024", "num_updates": "5420", "lr": "0.000271", "gnorm": "6.236", "loss_scale": "0.0625", "train_wall": "17", "gb_free": "12.9", "wall": "75784"}
2021-10-11 16:43:06 | INFO | train_inner | {"epoch": 1, "update": 0.48, "loss": "1.588", "code_loss": "1.613", "value_loss_mse": "0.018", "code_ppl": "3.06", "wps": "17638", "ups": "0.08", "wpb": "230550", "bsz": "1024", "num_updates": "5430", "lr": "0.0002715", "gnorm": "10.638", "loss_scale": "0.0625", "train_wall": "17", "gb_free": "12.9", "wall": "75914"}
byte1 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte1 pred value: [0.0014495849609375, 0.00042057037353515625, 0.001956939697265625, 0.00032258033752441406, 0.0009851455688476562]
byte2 tgt value: [0.0, 0.0, 0.0, 0.0, 0.0]
byte2 pred value: [0.0013513565063476562, 0.00040602684020996094, 0.0024051666259765625, 0.0004839897155761719, 0.0013246536254882812]
byte3 tgt value: [0.0, 0.0, 0.328125, 0.0, 0.0]
byte3 pred value: [0.0015611648559570312, 0.0004322528839111328, 0.2548828125, 0.0015363693237304688, 0.0013151168823242188]
byte4 tgt value: [0.0, 0.0, 0.359375, 0.0, 0.0]
byte4 pred value: [0.0015611648559570312, 0.0004172325134277344, 0.452880859375, 0.0006694793701171875, 0.0018177032470703125]
byte5 tgt value: [0.0, 0.0, 0.33203125, 0.0, 0.0]
byte5 pred value: [0.0018100738525390625, 0.0131683349609375, 0.47412109375, 0.0037078857421875, 0.024993896484375]
byte6 tgt value: [0.0, 0.0, 0.125, 0.1015625, 0.0]
byte6 pred value: [0.00183868408203125, 0.0116424560546875, 0.0703125, 0.0328369140625, 0.015777587890625]
byte7 tgt value: [0.0, 0.0, 0.63671875, 0.28125, 0.0]
byte7 pred value: [0.005641937255859375, 0.019989013671875, 0.65771484375, 0.42919921875, 0.059661865234375]
byte8 tgt value: [0.03125, 0.10546875, 0.6328125, 0.84375, 0.125]
byte8 pred value: [0.09234619140625, 0.13818359375, 0.486083984375, 0.54345703125, 0.115966796875]
tgt code: mov eax rdi eax rbx
pred code: mov al rdi eax rbx
2021-10-11 16:45:06 | INFO | train_inner | {"epoch": 1, "update": 0.48, "loss": "1.6", "code_loss": "1.632", "value_loss_mse": "0.018", "code_ppl": "3.1", "wps": "18745.6", "ups": "0.08", "wpb": "226156", "bsz": "1024", "num_updates": "5440", "lr": "0.000272", "gnorm": "7.235", "loss_scale": "0.0625", "train_wall": "15", "gb_free": "12.9", "wall": "76035"}
